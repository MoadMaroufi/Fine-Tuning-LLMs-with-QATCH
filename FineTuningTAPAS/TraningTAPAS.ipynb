{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9dda9f83fc9042f58888b8fd049465ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50c17e76f58941c3bc80a6dd77c4cdd0",
              "IPY_MODEL_65077d7e81ef4e46b67a6adc937eda01",
              "IPY_MODEL_cd283c2c4cd24e7cadbdc554503584e7"
            ],
            "layout": "IPY_MODEL_a5f68ed01aaf4c498b80d6d0f4e3860d"
          }
        },
        "50c17e76f58941c3bc80a6dd77c4cdd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7987f5c061d84547b988e3953ff2ef98",
            "placeholder": "​",
            "style": "IPY_MODEL_0416e1f6b3ea49af816e9a363eb15c52",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "65077d7e81ef4e46b67a6adc937eda01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d0dee406f4410b89e708b8ddbd7c3c",
            "max": 490,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b0c7535349e4c24a1105e73b1cef5a6",
            "value": 490
          }
        },
        "cd283c2c4cd24e7cadbdc554503584e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cfd845fecde4a48b2bdfa5d7085ff18",
            "placeholder": "​",
            "style": "IPY_MODEL_06ffd80d383445baa07eb5c12784db84",
            "value": " 490/490 [00:00&lt;00:00, 16.2kB/s]"
          }
        },
        "a5f68ed01aaf4c498b80d6d0f4e3860d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7987f5c061d84547b988e3953ff2ef98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0416e1f6b3ea49af816e9a363eb15c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73d0dee406f4410b89e708b8ddbd7c3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b0c7535349e4c24a1105e73b1cef5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3cfd845fecde4a48b2bdfa5d7085ff18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ffd80d383445baa07eb5c12784db84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "243a92d2ee134148877cce518f54e162": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1d0c2023c9a4111b15d3f818c81f29a",
              "IPY_MODEL_dd3918abf1c94870bdd8c4f654aa87a1",
              "IPY_MODEL_a4065811a7044bbab8003d64db38d8b5"
            ],
            "layout": "IPY_MODEL_ffe7794b4c194b569a38be5fc1a2b7c6"
          }
        },
        "d1d0c2023c9a4111b15d3f818c81f29a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a627f45ed74aa7ad8d356d24d1c618",
            "placeholder": "​",
            "style": "IPY_MODEL_a0bbb9993ee54c55afa3c1517496c06e",
            "value": "vocab.txt: 100%"
          }
        },
        "dd3918abf1c94870bdd8c4f654aa87a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6256cf5b4f4a99b798e5fe21f72155",
            "max": 262028,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3682585352654d41837f078da135eb03",
            "value": 262028
          }
        },
        "a4065811a7044bbab8003d64db38d8b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45c679e458654be4a1931f622cf6e7dd",
            "placeholder": "​",
            "style": "IPY_MODEL_6aec3bca0ae743b3bbb2b876dcdc8a12",
            "value": " 262k/262k [00:00&lt;00:00, 1.07MB/s]"
          }
        },
        "ffe7794b4c194b569a38be5fc1a2b7c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a627f45ed74aa7ad8d356d24d1c618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0bbb9993ee54c55afa3c1517496c06e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc6256cf5b4f4a99b798e5fe21f72155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3682585352654d41837f078da135eb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45c679e458654be4a1931f622cf6e7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aec3bca0ae743b3bbb2b876dcdc8a12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "daf0645145f54333816a1204b871a020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4cb78a95c934d08885fbaf12676d36a",
              "IPY_MODEL_922df59a8d144d18b0d391fb892ee8d2",
              "IPY_MODEL_60fb4f265deb46e5acc7cd3e6660a94d"
            ],
            "layout": "IPY_MODEL_ff916a1b3b0a4aa8b9b878eb03f97521"
          }
        },
        "c4cb78a95c934d08885fbaf12676d36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9e34b929ae24bf79e892bd74b92b119",
            "placeholder": "​",
            "style": "IPY_MODEL_ac481821d2634d3ab479df78859335b6",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "922df59a8d144d18b0d391fb892ee8d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e8c123186e45ac899c43e0eff44c8b",
            "max": 154,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_482829ac705842a3b3fae4781890b71d",
            "value": 154
          }
        },
        "60fb4f265deb46e5acc7cd3e6660a94d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c415a6af714a42428acacebb7bf6c39d",
            "placeholder": "​",
            "style": "IPY_MODEL_dc3c5642d1514ec88ac1b14eba1dc967",
            "value": " 154/154 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "ff916a1b3b0a4aa8b9b878eb03f97521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e34b929ae24bf79e892bd74b92b119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac481821d2634d3ab479df78859335b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7e8c123186e45ac899c43e0eff44c8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482829ac705842a3b3fae4781890b71d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c415a6af714a42428acacebb7bf6c39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc3c5642d1514ec88ac1b14eba1dc967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "774cbfea92ba472196fa1cffacfd047c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_829fdf4959d5409d9ce2e0c42b0089a3",
              "IPY_MODEL_99c93a0d4ca945e78d49a3e0fa2cb73b",
              "IPY_MODEL_da341fd30ab24160aecf98df7e9ee231"
            ],
            "layout": "IPY_MODEL_f89b99ad9c8f452ba163a33bc7cf5f17"
          }
        },
        "829fdf4959d5409d9ce2e0c42b0089a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df3f41ff281b4afda23cccceb51ffabe",
            "placeholder": "​",
            "style": "IPY_MODEL_cfc1da5c432e42ca92880163793d7e02",
            "value": "config.json: 100%"
          }
        },
        "99c93a0d4ca945e78d49a3e0fa2cb73b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a538c928c214d18bc561da0a000024b",
            "max": 1522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a5a8ed4a3e6454488643a1d28834b8b",
            "value": 1522
          }
        },
        "da341fd30ab24160aecf98df7e9ee231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b1c02604074707884bb10f4c7b1330",
            "placeholder": "​",
            "style": "IPY_MODEL_5843a738ef98417da7dbe3a02f2c16fd",
            "value": " 1.52k/1.52k [00:00&lt;00:00, 129kB/s]"
          }
        },
        "f89b99ad9c8f452ba163a33bc7cf5f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df3f41ff281b4afda23cccceb51ffabe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfc1da5c432e42ca92880163793d7e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a538c928c214d18bc561da0a000024b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5a8ed4a3e6454488643a1d28834b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52b1c02604074707884bb10f4c7b1330": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5843a738ef98417da7dbe3a02f2c16fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f169bbeda5f4a00a9ef92d0f46d249e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb78a3dc9994499594bb435fb0659d26",
              "IPY_MODEL_ce05880210e7446cad6c53ad6de4832f",
              "IPY_MODEL_6d2a58e431074bf4b7f992721a3a7b45"
            ],
            "layout": "IPY_MODEL_066c589839bd4688afc18f034c0f8e64"
          }
        },
        "bb78a3dc9994499594bb435fb0659d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea135fd266342ad8966bfe6335d817e",
            "placeholder": "​",
            "style": "IPY_MODEL_3f7edc5ecd0d43fd869ae6bb5be7e8ec",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "ce05880210e7446cad6c53ad6de4832f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a56a9a9090a449568be898b4af72ad2b",
            "max": 442768791,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64cf20a0bd004ca89495a8f575311451",
            "value": 442768791
          }
        },
        "6d2a58e431074bf4b7f992721a3a7b45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8280ea1393f4f528a035539af391a94",
            "placeholder": "​",
            "style": "IPY_MODEL_92f81ae8218d4c4e81923ae36c7a1bbf",
            "value": " 443M/443M [00:37&lt;00:00, 14.2MB/s]"
          }
        },
        "066c589839bd4688afc18f034c0f8e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ea135fd266342ad8966bfe6335d817e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f7edc5ecd0d43fd869ae6bb5be7e8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a56a9a9090a449568be898b4af72ad2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64cf20a0bd004ca89495a8f575311451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8280ea1393f4f528a035539af391a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f81ae8218d4c4e81923ae36c7a1bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet datasets\n",
        "!pip install --quiet frozendict\n",
        "!pip install --quiet transformers\n",
        "!pip install --quiet qatch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiKd8RnxOtST",
        "outputId": "ba2ffcf9-fa55-47d0-f81f-6965258d6197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import TapasTokenizer\n",
        "\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "from transformers import TapasConfig, TapasForQuestionAnswering\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from qatch import MetricEvaluator\n",
        "from qatch.database_reader import MultipleDatabases\n",
        "import logging\n",
        "\n",
        "# Set logging level to ERROR to suppress warnings\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
      ],
      "metadata": {
        "id": "c4wdrtH5rv9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amsLM7QgTLit",
        "outputId": "cdb10049-5439-4b72-8ac3-9996e1cfda3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The path to multiple databases\n",
        "db_save_path = '/content/drive/MyDrive/spider/test_database'\n",
        "databases = MultipleDatabases(db_save_path)\n",
        "evaluator = MetricEvaluator(databases=databases)"
      ],
      "metadata": {
        "id": "uZvi2B7e0hiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/spider/db_to_tables.pkl', 'rb') as file:\n",
        "    db_to_tables = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/spider/db_to_tables_constraint.pkl', 'rb') as file:\n",
        "    db_to_tables_constraint = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/spider/db_table_to_df.pkl', 'rb') as file:\n",
        "    db_table_to_df = pickle.load(file)"
      ],
      "metadata": {
        "id": "sb2uyCJcr1v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/spider/db_to_tables_valid.pkl', 'rb') as file:\n",
        "    db_to_tables_valid = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/spider/db_to_tables_constraint_valid.pkl', 'rb') as file:\n",
        "    db_to_tables_constraint_valid = pickle.load(file)\n",
        "\n",
        "with open('/content/drive/MyDrive/spider/db_table_to_df_valid.pkl', 'rb') as file:\n",
        "    db_table_to_df_valid = pickle.load(file)"
      ],
      "metadata": {
        "id": "Lrgo17-t6nIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the tokenizer\n",
        "tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "9dda9f83fc9042f58888b8fd049465ec",
            "50c17e76f58941c3bc80a6dd77c4cdd0",
            "65077d7e81ef4e46b67a6adc937eda01",
            "cd283c2c4cd24e7cadbdc554503584e7",
            "a5f68ed01aaf4c498b80d6d0f4e3860d",
            "7987f5c061d84547b988e3953ff2ef98",
            "0416e1f6b3ea49af816e9a363eb15c52",
            "73d0dee406f4410b89e708b8ddbd7c3c",
            "3b0c7535349e4c24a1105e73b1cef5a6",
            "3cfd845fecde4a48b2bdfa5d7085ff18",
            "06ffd80d383445baa07eb5c12784db84",
            "243a92d2ee134148877cce518f54e162",
            "d1d0c2023c9a4111b15d3f818c81f29a",
            "dd3918abf1c94870bdd8c4f654aa87a1",
            "a4065811a7044bbab8003d64db38d8b5",
            "ffe7794b4c194b569a38be5fc1a2b7c6",
            "58a627f45ed74aa7ad8d356d24d1c618",
            "a0bbb9993ee54c55afa3c1517496c06e",
            "dc6256cf5b4f4a99b798e5fe21f72155",
            "3682585352654d41837f078da135eb03",
            "45c679e458654be4a1931f622cf6e7dd",
            "6aec3bca0ae743b3bbb2b876dcdc8a12",
            "daf0645145f54333816a1204b871a020",
            "c4cb78a95c934d08885fbaf12676d36a",
            "922df59a8d144d18b0d391fb892ee8d2",
            "60fb4f265deb46e5acc7cd3e6660a94d",
            "ff916a1b3b0a4aa8b9b878eb03f97521",
            "d9e34b929ae24bf79e892bd74b92b119",
            "ac481821d2634d3ab479df78859335b6",
            "a7e8c123186e45ac899c43e0eff44c8b",
            "482829ac705842a3b3fae4781890b71d",
            "c415a6af714a42428acacebb7bf6c39d",
            "dc3c5642d1514ec88ac1b14eba1dc967",
            "774cbfea92ba472196fa1cffacfd047c",
            "829fdf4959d5409d9ce2e0c42b0089a3",
            "99c93a0d4ca945e78d49a3e0fa2cb73b",
            "da341fd30ab24160aecf98df7e9ee231",
            "f89b99ad9c8f452ba163a33bc7cf5f17",
            "df3f41ff281b4afda23cccceb51ffabe",
            "cfc1da5c432e42ca92880163793d7e02",
            "0a538c928c214d18bc561da0a000024b",
            "4a5a8ed4a3e6454488643a1d28834b8b",
            "52b1c02604074707884bb10f4c7b1330",
            "5843a738ef98417da7dbe3a02f2c16fd"
          ]
        },
        "id": "5GvO3Efqr670",
        "outputId": "756ffbea-46e6-4f95-b65c-aea659a5a2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/490 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dda9f83fc9042f58888b8fd049465ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/262k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "243a92d2ee134148877cce518f54e162"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/154 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "daf0645145f54333816a1204b871a020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "774cbfea92ba472196fa1cffacfd047c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TableDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.problematic_ids = []  # Initialize a list to store IDs of problematic questions\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.df.iloc[idx]\n",
        "        table_name = item['seq_id']\n",
        "        try:\n",
        "            table = db_table_to_df[table_name].astype(str)\n",
        "            encoding = self.tokenizer(\n",
        "                table=table,\n",
        "                queries=item.question,\n",
        "                answer_coordinates=item.answer_coordinates,\n",
        "                answer_text=item.answer_text,\n",
        "                truncation=True,\n",
        "                padding=\"max_length\",\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "            float_answer = torch.tensor(item.float_value)\n",
        "            encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
        "            encoding[\"float_answer\"] = float_answer\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing index {idx} (ID: {item['ID']}): {e}\")\n",
        "            self.problematic_ids.append(item.ID)  # Store the ID of the problematic question\n",
        "            encoding = None\n",
        "\n",
        "        return encoding\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def get_problematic_ids(self):\n",
        "        # Returns the list of problematic IDs\n",
        "        return self.problematic_ids\n",
        "\n",
        "# Custom collate function to filter out None values, if not already implemented\n",
        "def custom_collate_fn(batch):\n",
        "    batch = [item for item in batch if item is not None]  # Filter out None values\n",
        "    if not batch:\n",
        "        return None\n",
        "    return torch.utils.data.dataloader.default_collate(batch)"
      ],
      "metadata": {
        "id": "1W04vVMXsCn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spider_train_pd = pd.read_pickle('/content/drive/MyDrive/spider/SPIDER_Simple_cleaned_final.pkl')\n",
        "spider_train_pd=spider_train_pd.drop(columns=[\"query_toks\",\"query_toks_no_value\",\"question_toks\",\"operator\"])\n",
        "\n",
        "spider_valid_pd = pd.read_pickle('/content/drive/MyDrive/spider/SPIDER_Simple_cleaned_final_valid.pkl')\n",
        "\n",
        "\n",
        "qatch_pickle = pd.read_pickle('/content/drive/MyDrive/spider/QATCH_SPIDER.pkl')\n",
        "\n",
        "percentage = 0.1\n",
        "sampled_df = qatch_pickle.groupby('sql_tags', group_keys=False).apply(lambda x: x.sample(frac=percentage, random_state=42))\n",
        "\n",
        "sampled_df=sampled_df.drop(columns=[\"sql_tags\"])\n",
        "\n",
        "train_df = pd.concat([spider_train_pd, sampled_df], axis=0)\n",
        "# train_df=spider_train_pd.copy()\n",
        "\n",
        "train_df=train_df.drop(columns=[\"ID\"])\n",
        "train_df.reset_index(inplace=True)\n",
        "train_df.rename(columns={'index': 'ID'}, inplace=True)"
      ],
      "metadata": {
        "id": "hsiQT3UWsHMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c93e05b0-a716-4f4b-df53-8d0bd6349fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b6ccab1eba53>:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sampled_df = qatch_pickle.groupby('sql_tags', group_keys=False).apply(lambda x: x.sample(frac=percentage, random_state=42))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "id": "uc4IE0NwkyNh",
        "outputId": "5f2ce43a-d41b-443a-a6d8-dd41c309cea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID                                        answer_text  \\\n",
              "0         0                                                [5]   \n",
              "1         1  [Pádraig Harrington, Connecticut, 43.0, Stewar...   \n",
              "2         2  [1789, State, 9.96, 1789, Treasury, 11.1, 1947...   \n",
              "3         4  [Tiger Woods, K. J. Choi, Jeff Maggert, Stewar...   \n",
              "4         5                                       [California]   \n",
              "...     ...                                                ...   \n",
              "3582  10314  [2, 6, 1, advanced database, advanced database...   \n",
              "3583  13268  [1729, 1729, England Premier League, 4769, 476...   \n",
              "3584  21105  [1, 7, 3, 1978-04-15 04:49:18, None, None, 2, ...   \n",
              "3585   6501  [0.0, 2, leader, 1981-10-04 22:44:50, 1985-05-...   \n",
              "3586  20014  [3, Peacock, Jane, Sales Support Agent, 2, 197...   \n",
              "\n",
              "                             db_id  \\\n",
              "0            department_management   \n",
              "1            department_management   \n",
              "2            department_management   \n",
              "3            department_management   \n",
              "4            department_management   \n",
              "...                            ...   \n",
              "3582                    e_learning   \n",
              "3583                      soccer_1   \n",
              "3584           behavior_monitoring   \n",
              "3585  tracking_grants_for_research   \n",
              "3586                       store_1   \n",
              "\n",
              "                                                  query  \\\n",
              "0            SELECT count(*) FROM head WHERE age  >  56   \n",
              "1     SELECT name ,  born_state ,  age FROM head ORD...   \n",
              "2     SELECT creation ,  name ,  budget_in_billions ...   \n",
              "3     SELECT name FROM head WHERE born_state != 'Cal...   \n",
              "4     SELECT born_state FROM head GROUP BY born_stat...   \n",
              "...                                                 ...   \n",
              "3582      SELECT * FROM \"Courses\" WHERE \"course_id\" > 1   \n",
              "3583              SELECT * FROM \"League\" WHERE \"id\" > 1   \n",
              "3584  SELECT * FROM \"Assessment_Notes\" WHERE \"teache...   \n",
              "3585  SELECT * FROM \"Project_Staff\" WHERE \"project_i...   \n",
              "3586  SELECT * FROM \"employees\" WHERE \"reports_to\" >...   \n",
              "\n",
              "                                               question        table_used  \\\n",
              "0     How many heads of the departments are older th...              head   \n",
              "1     List the name, born state and age of the heads...              head   \n",
              "2     List the creation year, name and budget of eac...        department   \n",
              "3     What are the names of the heads who are born o...              head   \n",
              "4     What are the names of the states where at leas...              head   \n",
              "...                                                 ...               ...   \n",
              "3582  Show the data of the table \"Courses\" where \"co...           Courses   \n",
              "3583  Show the data of the table \"League\" where \"id\"...            League   \n",
              "3584  Show the data of the table \"Assessment_Notes\" ...  Assessment_Notes   \n",
              "3585  Show the data of the table \"Project_Staff\" whe...     Project_Staff   \n",
              "3586  Show the data of the table \"employees\" where \"...         employees   \n",
              "\n",
              "                                            seq_id  \\\n",
              "0                     department_management_X_head   \n",
              "1                     department_management_X_head   \n",
              "2               department_management_X_department   \n",
              "3                     department_management_X_head   \n",
              "4                     department_management_X_head   \n",
              "...                                            ...   \n",
              "3582                          e_learning_X_Courses   \n",
              "3583                             soccer_1_X_League   \n",
              "3584        behavior_monitoring_X_Assessment_Notes   \n",
              "3585  tracking_grants_for_research_X_Project_Staff   \n",
              "3586                           store_1_X_employees   \n",
              "\n",
              "                                     answer_coordinates  float_value  \n",
              "0                                              [(4, 0)]          5.0  \n",
              "1     [(8, 1), (8, 2), (8, 3), (6, 1), (6, 2), (6, 3...          NaN  \n",
              "2     [(0, 2), (0, 1), (0, 4), (1, 2), (1, 1), (1, 4...          NaN  \n",
              "3      [(0, 1), (2, 1), (4, 1), (6, 1), (8, 1), (9, 1)]          NaN  \n",
              "4                                              [(1, 2)]          NaN  \n",
              "...                                                 ...          ...  \n",
              "3582  [(1, 0), (1, 1), (0, 0), (1, 3), (1, 4), (2, 0...          NaN  \n",
              "3583  [(1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2...          NaN  \n",
              "3584  [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5...          NaN  \n",
              "3585  [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5...          NaN  \n",
              "3586  [(2, 0), (2, 1), (2, 2), (2, 3), (1, 0), (2, 5...          NaN  \n",
              "\n",
              "[3587 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fc01c44-c941-4e22-82e6-f3b323818d9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>db_id</th>\n",
              "      <th>query</th>\n",
              "      <th>question</th>\n",
              "      <th>table_used</th>\n",
              "      <th>seq_id</th>\n",
              "      <th>answer_coordinates</th>\n",
              "      <th>float_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>[5]</td>\n",
              "      <td>department_management</td>\n",
              "      <td>SELECT count(*) FROM head WHERE age  &gt;  56</td>\n",
              "      <td>How many heads of the departments are older th...</td>\n",
              "      <td>head</td>\n",
              "      <td>department_management_X_head</td>\n",
              "      <td>[(4, 0)]</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Pádraig Harrington, Connecticut, 43.0, Stewar...</td>\n",
              "      <td>department_management</td>\n",
              "      <td>SELECT name ,  born_state ,  age FROM head ORD...</td>\n",
              "      <td>List the name, born state and age of the heads...</td>\n",
              "      <td>head</td>\n",
              "      <td>department_management_X_head</td>\n",
              "      <td>[(8, 1), (8, 2), (8, 3), (6, 1), (6, 2), (6, 3...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[1789, State, 9.96, 1789, Treasury, 11.1, 1947...</td>\n",
              "      <td>department_management</td>\n",
              "      <td>SELECT creation ,  name ,  budget_in_billions ...</td>\n",
              "      <td>List the creation year, name and budget of eac...</td>\n",
              "      <td>department</td>\n",
              "      <td>department_management_X_department</td>\n",
              "      <td>[(0, 2), (0, 1), (0, 4), (1, 2), (1, 1), (1, 4...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>[Tiger Woods, K. J. Choi, Jeff Maggert, Stewar...</td>\n",
              "      <td>department_management</td>\n",
              "      <td>SELECT name FROM head WHERE born_state != 'Cal...</td>\n",
              "      <td>What are the names of the heads who are born o...</td>\n",
              "      <td>head</td>\n",
              "      <td>department_management_X_head</td>\n",
              "      <td>[(0, 1), (2, 1), (4, 1), (6, 1), (8, 1), (9, 1)]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>[California]</td>\n",
              "      <td>department_management</td>\n",
              "      <td>SELECT born_state FROM head GROUP BY born_stat...</td>\n",
              "      <td>What are the names of the states where at leas...</td>\n",
              "      <td>head</td>\n",
              "      <td>department_management_X_head</td>\n",
              "      <td>[(1, 2)]</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3582</th>\n",
              "      <td>10314</td>\n",
              "      <td>[2, 6, 1, advanced database, advanced database...</td>\n",
              "      <td>e_learning</td>\n",
              "      <td>SELECT * FROM \"Courses\" WHERE \"course_id\" &gt; 1</td>\n",
              "      <td>Show the data of the table \"Courses\" where \"co...</td>\n",
              "      <td>Courses</td>\n",
              "      <td>e_learning_X_Courses</td>\n",
              "      <td>[(1, 0), (1, 1), (0, 0), (1, 3), (1, 4), (2, 0...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3583</th>\n",
              "      <td>13268</td>\n",
              "      <td>[1729, 1729, England Premier League, 4769, 476...</td>\n",
              "      <td>soccer_1</td>\n",
              "      <td>SELECT * FROM \"League\" WHERE \"id\" &gt; 1</td>\n",
              "      <td>Show the data of the table \"League\" where \"id\"...</td>\n",
              "      <td>League</td>\n",
              "      <td>soccer_1_X_League</td>\n",
              "      <td>[(1, 0), (1, 1), (1, 2), (2, 0), (2, 1), (2, 2...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3584</th>\n",
              "      <td>21105</td>\n",
              "      <td>[1, 7, 3, 1978-04-15 04:49:18, None, None, 2, ...</td>\n",
              "      <td>behavior_monitoring</td>\n",
              "      <td>SELECT * FROM \"Assessment_Notes\" WHERE \"teache...</td>\n",
              "      <td>Show the data of the table \"Assessment_Notes\" ...</td>\n",
              "      <td>Assessment_Notes</td>\n",
              "      <td>behavior_monitoring_X_Assessment_Notes</td>\n",
              "      <td>[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3585</th>\n",
              "      <td>6501</td>\n",
              "      <td>[0.0, 2, leader, 1981-10-04 22:44:50, 1985-05-...</td>\n",
              "      <td>tracking_grants_for_research</td>\n",
              "      <td>SELECT * FROM \"Project_Staff\" WHERE \"project_i...</td>\n",
              "      <td>Show the data of the table \"Project_Staff\" whe...</td>\n",
              "      <td>Project_Staff</td>\n",
              "      <td>tracking_grants_for_research_X_Project_Staff</td>\n",
              "      <td>[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3586</th>\n",
              "      <td>20014</td>\n",
              "      <td>[3, Peacock, Jane, Sales Support Agent, 2, 197...</td>\n",
              "      <td>store_1</td>\n",
              "      <td>SELECT * FROM \"employees\" WHERE \"reports_to\" &gt;...</td>\n",
              "      <td>Show the data of the table \"employees\" where \"...</td>\n",
              "      <td>employees</td>\n",
              "      <td>store_1_X_employees</td>\n",
              "      <td>[(2, 0), (2, 1), (2, 2), (2, 3), (1, 0), (2, 5...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3587 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fc01c44-c941-4e22-82e6-f3b323818d9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fc01c44-c941-4e22-82e6-f3b323818d9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fc01c44-c941-4e22-82e6-f3b323818d9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e771068a-9c44-412f-ade0-3aebf96d2644\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e771068a-9c44-412f-ade0-3aebf96d2644')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e771068a-9c44-412f-ade0-3aebf96d2644 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 3587,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7908,\n        \"min\": 0,\n        \"max\": 24527,\n        \"num_unique_values\": 3460,\n        \"samples\": [\n          752,\n          448,\n          9835\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"db_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 129,\n        \"samples\": [\n          \"local_govt_mdm\",\n          \"products_for_hire\",\n          \"match_season\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2881,\n        \"samples\": [\n          \"SELECT name FROM program WHERE origin != 'Beijing'\",\n          \"SELECT \\\"Name\\\" FROM \\\"technician\\\" ORDER BY \\\"Name\\\" DESC\",\n          \"SELECT MIN(\\\"Vote_Percent\\\") FROM \\\"election\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3465,\n        \"samples\": [\n          \"Show the data of the table \\\"shop\\\" where \\\"Shop_Name\\\" is equal to ATnT\",\n          \"Show the name, street address, and number of floors for all buildings ordered by the number of floors.\",\n          \"Show the data of the table \\\"storm\\\" where \\\"Dates_active\\\" is not equal to August26\\u2013September2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"table_used\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 356,\n        \"samples\": [\n          \"Parties\",\n          \"country\",\n          \"dept_locations\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seq_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 466,\n        \"samples\": [\n          \"apartment_rentals_X_Guests\",\n          \"insurance_and_eClaims_X_Claims_Processing\",\n          \"coffee_shop_X_happy_hour\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_coordinates\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"float_value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8815114.965152673,\n        \"min\": 0.0,\n        \"max\": 207484122.2796,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          93191.0,\n          5.0,\n          45.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TableDataset(df=train_df, tokenizer=tokenizer)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, collate_fn=custom_collate_fn)\n",
        "\n",
        "for idx, batch in enumerate(train_dataloader):\n",
        "    if batch is not None:\n",
        "        continue\n",
        "    else:\n",
        "        print(f\"Batch {idx} skipped due to problematic data\")\n",
        "\n",
        "print(train_dataset.get_problematic_ids())\n",
        "\n",
        "\n",
        "prob=train_dataset.get_problematic_ids()\n",
        "train_df = train_df[~train_df['ID'].isin(prob)]\n",
        "train_dataset = TableDataset(df=train_df, tokenizer=tokenizer)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, collate_fn=custom_collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC18piDTsK3Q",
        "outputId": "a236cc41-710d-4f78-87fe-f067db947260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing index 769 (ID: 884): Couldn't find all answers\n",
            "Error processing index 770 (ID: 885): Couldn't find all answers\n",
            "Error processing index 771 (ID: 886): Couldn't find all answers\n",
            "Error processing index 772 (ID: 887): Couldn't find all answers\n",
            "Error processing index 781 (ID: 896): Couldn't find all answers\n",
            "Error processing index 782 (ID: 897): Couldn't find all answers\n",
            "Error processing index 839 (ID: 968): Couldn't find all answers\n",
            "Error processing index 840 (ID: 969): Couldn't find all answers\n",
            "Error processing index 847 (ID: 980): Couldn't find all answers\n",
            "Error processing index 848 (ID: 981): Couldn't find all answers\n",
            "Error processing index 1125 (ID: 1326): Couldn't find all answers\n",
            "Error processing index 1126 (ID: 1327): Couldn't find all answers\n",
            "Error processing index 1137 (ID: 1338): Couldn't find all answers\n",
            "Error processing index 1138 (ID: 1339): Couldn't find all answers\n",
            "Error processing index 1196 (ID: 1411): Couldn't find all answers\n",
            "Error processing index 2251 (ID: 6426): Couldn't find all answers\n",
            "Error processing index 2386 (ID: 16380): Couldn't find all answers\n",
            "Error processing index 2401 (ID: 10776): Couldn't find all answers\n",
            "Error processing index 2482 (ID: 20099): Couldn't find all answers\n",
            "Error processing index 2525 (ID: 2329): Couldn't find all answers\n",
            "Error processing index 2543 (ID: 4098): Couldn't find all answers\n",
            "Error processing index 2553 (ID: 7872): Couldn't find all answers\n",
            "Error processing index 2611 (ID: 16384): Couldn't find all answers\n",
            "Error processing index 2634 (ID: 10244): Couldn't find all answers\n",
            "Error processing index 2733 (ID: 2337): Couldn't find all answers\n",
            "Error processing index 2751 (ID: 10245): Couldn't find all answers\n",
            "Error processing index 2839 (ID: 7960): Couldn't find all answers\n",
            "Error processing index 3353 (ID: 6480): Couldn't find all answers\n",
            "Error processing index 3418 (ID: 7942): Couldn't find all answers\n",
            "Error processing index 3467 (ID: 6483): Couldn't find all answers\n",
            "[884, 885, 886, 887, 896, 897, 968, 969, 980, 981, 1326, 1327, 1338, 1339, 1411, 6426, 16380, 10776, 20099, 2329, 4098, 7872, 16384, 10244, 2337, 10245, 7960, 6480, 7942, 6483]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "131gpwxzOjSW"
      },
      "outputs": [],
      "source": [
        "# with open('/content/drive/MyDrive/spider/train_dataloader_spider_2000qatch.pkl', 'wb') as f:\n",
        "#     pickle.dump(train_dataloader, f)\n",
        "with open('/content/drive/MyDrive/spider/train_dataloader_spider_2000qatch.pkl', 'rb') as file:\n",
        "    train_dataloader = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spider_valid_pd = spider_valid_pd.reset_index().rename(columns={'table_used':'tbl_name'})"
      ],
      "metadata": {
        "id": "LbEKo4Ud7yPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Computing predictions\n",
        "def compute_prediction_sequence(model, data, device):\n",
        "  \"\"\"Computes predictions using model's answers to the previous questions.\"\"\"\n",
        "\n",
        "  # prepare data\n",
        "  input_ids = data[\"input_ids\"].to(device)\n",
        "  attention_mask = data[\"attention_mask\"].to(device)\n",
        "  token_type_ids = data[\"token_type_ids\"].to(device)\n",
        "\n",
        "  all_logits = []\n",
        "  prev_answers = None\n",
        "\n",
        "  num_batch = data[\"input_ids\"].shape[0]\n",
        "\n",
        "  for idx in range(num_batch):\n",
        "\n",
        "    if prev_answers is not None:\n",
        "        coords_to_answer = prev_answers[idx]\n",
        "        # Next, set the label ids predicted by the model\n",
        "        prev_label_ids_example = token_type_ids_example[:,3] # shape (seq_len,)\n",
        "        model_label_ids = np.zeros_like(prev_label_ids_example.cpu().numpy()) # shape (seq_len,)\n",
        "\n",
        "        # for each token in the sequence:\n",
        "        token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
        "        for i in range(model_label_ids.shape[0]):\n",
        "          segment_id = token_type_ids_example[:,0].tolist()[i]\n",
        "          col_id = token_type_ids_example[:,1].tolist()[i] - 1\n",
        "          row_id = token_type_ids_example[:,2].tolist()[i] - 1\n",
        "          if row_id >= 0 and col_id >= 0 and segment_id == 1:\n",
        "            model_label_ids[i] = int(coords_to_answer[(col_id, row_id)])\n",
        "\n",
        "        # set the prev label ids of the example (shape (1, seq_len) )\n",
        "        token_type_ids_example[:,3] = torch.from_numpy(model_label_ids).type(torch.long).to(device)\n",
        "\n",
        "    prev_answers = {}\n",
        "    # get the example\n",
        "    input_ids_example = input_ids[idx] # shape (seq_len,)\n",
        "    attention_mask_example = attention_mask[idx] # shape (seq_len,)\n",
        "    token_type_ids_example = token_type_ids[idx] # shape (seq_len, 7)\n",
        "    # forward pass to obtain the logits\n",
        "    outputs = model(input_ids=input_ids_example.unsqueeze(0),\n",
        "                    attention_mask=attention_mask_example.unsqueeze(0),\n",
        "                    token_type_ids=token_type_ids_example.unsqueeze(0))\n",
        "    logits = outputs.logits\n",
        "    all_logits.append(logits)\n",
        "\n",
        "    # convert logits to probabilities (which are of shape (1, seq_len))\n",
        "    dist_per_token = torch.distributions.Bernoulli(logits=logits)\n",
        "    probabilities = dist_per_token.probs * attention_mask_example.type(torch.float32).to(dist_per_token.probs.device)\n",
        "\n",
        "    # Compute average probability per cell, aggregating over tokens.\n",
        "    # Dictionary maps coordinates to a list of one or more probabilities\n",
        "    coords_to_probs = collections.defaultdict(list)\n",
        "    prev_answers = {}\n",
        "    for i, p in enumerate(probabilities.squeeze().tolist()):\n",
        "      segment_id = token_type_ids_example[:,0].tolist()[i]\n",
        "      col = token_type_ids_example[:,1].tolist()[i] - 1\n",
        "      row = token_type_ids_example[:,2].tolist()[i] - 1\n",
        "      if col >= 0 and row >= 0 and segment_id == 1:\n",
        "        coords_to_probs[(col, row)].append(p)\n",
        "\n",
        "    # Next, map cell coordinates to 1 or 0 (depending on whether the mean prob of all cell tokens is > 0.5)\n",
        "    coords_to_answer = {}\n",
        "    for key in coords_to_probs:\n",
        "      coords_to_answer[key] = np.array(coords_to_probs[key]).mean() > 0.5\n",
        "    prev_answers[idx+1] = coords_to_answer\n",
        "\n",
        "  logits_batch = torch.cat(tuple(all_logits), 0)\n",
        "\n",
        "  return logits_batch\n",
        "\n",
        "\n",
        "def getAnswer(row):\n",
        "    row_index = row['ID']\n",
        "    print(f\"Processing row {row_index}...\")\n",
        "\n",
        "    seq_id = row[\"db_id\"] + \"_X_\" + row[\"tbl_name\"]\n",
        "    if seq_id not in db_table_to_df or db_table_to_df[seq_id].empty:\n",
        "        print(f\"Row {row_index} skipped: table not found or empty.\")\n",
        "        return None\n",
        "\n",
        "    table = db_table_to_df[seq_id]\n",
        "    table = table.astype(str)\n",
        "    query_nl = [row[\"question\"]]\n",
        "\n",
        "    try:\n",
        "        inputs = tokenizer(table=table, queries=query_nl, padding='max_length', return_tensors=\"pt\", truncation=True)\n",
        "        logits = compute_prediction_sequence(model, inputs, 'cuda')\n",
        "        predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())\n",
        "        answers = []\n",
        "        for tbl_cords in predicted_answer_coordinates:\n",
        "            query_answer = defaultdict(list)\n",
        "            # For each coordinate set in the predicted query coordinates,\n",
        "            # construct a dictionary of row-wise query answers.\n",
        "            [query_answer[row].append(table.iat[(row, col)])\n",
        "             for row, col in tbl_cords]\n",
        "            answers.extend(list(query_answer.values()))\n",
        "        print(f\"Row {row_index} processed successfully.\")\n",
        "    except IndexError:\n",
        "        print(f\"Row {row_index} skipped due to IndexError.\")\n",
        "        return None\n",
        "\n",
        "    return answers\n",
        "\n",
        "def getAnswerValid(row):\n",
        "    row_index = row['ID']\n",
        "    # print(f\"Processing row {row_index}...\")\n",
        "\n",
        "    seq_id = row[\"db_id\"] + \"_X_\" + row[\"tbl_name\"]\n",
        "    if seq_id not in db_table_to_df_valid or db_table_to_df_valid[seq_id].empty:\n",
        "        print(f\"Row {row_index} skipped: table not found or empty.\")\n",
        "        return None\n",
        "\n",
        "    table = db_table_to_df_valid[seq_id]\n",
        "    table = table.astype(str)\n",
        "    query_nl = [row[\"question\"]]\n",
        "\n",
        "    try:\n",
        "        inputs = row['input']\n",
        "        logits = compute_prediction_sequence(model, inputs, 'cuda')\n",
        "        predicted_answer_coordinates, = tokenizer.convert_logits_to_predictions(inputs, logits.cpu().detach())\n",
        "        answers = []\n",
        "        for tbl_cords in predicted_answer_coordinates:\n",
        "            query_answer = defaultdict(list)\n",
        "            # For each coordinate set in the predicted query coordinates,\n",
        "            # construct a dictionary of row-wise query answers.\n",
        "            [query_answer[row].append(table.iat[(row, col)])\n",
        "             for row, col in tbl_cords]\n",
        "            answers.extend(list(query_answer.values()))\n",
        "        # print(f\"Row {row_index} processed successfully.\")\n",
        "    except IndexError:\n",
        "        # print(f\"Row {row_index} skipped due to IndexError.\")\n",
        "        return None\n",
        "\n",
        "    return answers\n",
        "\n",
        "def getInput(row):\n",
        "    row_index = row['ID']\n",
        "    print(f\"Processing row {row_index}...\")\n",
        "\n",
        "    seq_id = row[\"db_id\"] + \"_X_\" + row[\"tbl_name\"]\n",
        "    if seq_id not in db_table_to_df_valid or db_table_to_df_valid[seq_id].empty:\n",
        "        print(f\"Row {row_index} skipped: table not found or empty.\")\n",
        "        return None\n",
        "\n",
        "    table = db_table_to_df_valid[seq_id]\n",
        "    table = table.astype(str)\n",
        "    query_nl = [row[\"question\"]]\n",
        "\n",
        "    try:\n",
        "        inputs = tokenizer(table=table, queries=query_nl, padding='max_length', return_tensors=\"pt\", truncation=True)\n",
        "        print(f\"Row {row_index} processed successfully.\")\n",
        "    except IndexError:\n",
        "        print(f\"Row {row_index} skipped due to IndexError.\")\n",
        "        return None\n",
        "\n",
        "    return inputs\n"
      ],
      "metadata": {
        "id": "9paaTsSat528"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spider_valid_pd['input'] = spider_valid_pd.apply(getInput, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX6vk5VJup-0",
        "outputId": "01e872bf-628e-48ce-bf44-5019a9efd732"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 0...\n",
            "Row 0 processed successfully.\n",
            "Processing row 1...\n",
            "Row 1 processed successfully.\n",
            "Processing row 2...\n",
            "Row 2 processed successfully.\n",
            "Processing row 3...\n",
            "Row 3 processed successfully.\n",
            "Processing row 8...\n",
            "Row 8 processed successfully.\n",
            "Processing row 9...\n",
            "Row 9 processed successfully.\n",
            "Processing row 20...\n",
            "Row 20 processed successfully.\n",
            "Processing row 21...\n",
            "Row 21 processed successfully.\n",
            "Processing row 87...\n",
            "Row 87 processed successfully.\n",
            "Processing row 88...\n",
            "Row 88 processed successfully.\n",
            "Processing row 91...\n",
            "Row 91 processed successfully.\n",
            "Processing row 92...\n",
            "Row 92 processed successfully.\n",
            "Processing row 179...\n",
            "Row 179 processed successfully.\n",
            "Processing row 180...\n",
            "Row 180 processed successfully.\n",
            "Processing row 181...\n",
            "Row 181 processed successfully.\n",
            "Processing row 182...\n",
            "Row 182 processed successfully.\n",
            "Processing row 183...\n",
            "Row 183 processed successfully.\n",
            "Processing row 184...\n",
            "Row 184 processed successfully.\n",
            "Processing row 187...\n",
            "Row 187 processed successfully.\n",
            "Processing row 188...\n",
            "Row 188 processed successfully.\n",
            "Processing row 193...\n",
            "Row 193 processed successfully.\n",
            "Processing row 194...\n",
            "Row 194 processed successfully.\n",
            "Processing row 195...\n",
            "Row 195 processed successfully.\n",
            "Processing row 196...\n",
            "Row 196 processed successfully.\n",
            "Processing row 259...\n",
            "Row 259 processed successfully.\n",
            "Processing row 260...\n",
            "Row 260 processed successfully.\n",
            "Processing row 261...\n",
            "Row 261 processed successfully.\n",
            "Processing row 262...\n",
            "Row 262 processed successfully.\n",
            "Processing row 265...\n",
            "Row 265 processed successfully.\n",
            "Processing row 266...\n",
            "Row 266 processed successfully.\n",
            "Processing row 273...\n",
            "Row 273 processed successfully.\n",
            "Processing row 274...\n",
            "Row 274 processed successfully.\n",
            "Processing row 289...\n",
            "Row 289 processed successfully.\n",
            "Processing row 290...\n",
            "Row 290 processed successfully.\n",
            "Processing row 291...\n",
            "Row 291 processed successfully.\n",
            "Processing row 292...\n",
            "Row 292 processed successfully.\n",
            "Processing row 295...\n",
            "Row 295 processed successfully.\n",
            "Processing row 296...\n",
            "Row 296 processed successfully.\n",
            "Processing row 297...\n",
            "Row 297 processed successfully.\n",
            "Processing row 298...\n",
            "Row 298 processed successfully.\n",
            "Processing row 299...\n",
            "Row 299 processed successfully.\n",
            "Processing row 300...\n",
            "Row 300 processed successfully.\n",
            "Processing row 303...\n",
            "Row 303 processed successfully.\n",
            "Processing row 304...\n",
            "Row 304 processed successfully.\n",
            "Processing row 305...\n",
            "Row 305 processed successfully.\n",
            "Processing row 306...\n",
            "Row 306 processed successfully.\n",
            "Processing row 313...\n",
            "Row 313 processed successfully.\n",
            "Processing row 314...\n",
            "Row 314 processed successfully.\n",
            "Processing row 347...\n",
            "Row 347 processed successfully.\n",
            "Processing row 348...\n",
            "Row 348 processed successfully.\n",
            "Processing row 349...\n",
            "Row 349 processed successfully.\n",
            "Processing row 350...\n",
            "Row 350 processed successfully.\n",
            "Processing row 351...\n",
            "Row 351 processed successfully.\n",
            "Processing row 352...\n",
            "Row 352 processed successfully.\n",
            "Processing row 357...\n",
            "Row 357 processed successfully.\n",
            "Processing row 358...\n",
            "Row 358 processed successfully.\n",
            "Processing row 371...\n",
            "Row 371 processed successfully.\n",
            "Processing row 372...\n",
            "Row 372 processed successfully.\n",
            "Processing row 377...\n",
            "Row 377 processed successfully.\n",
            "Processing row 378...\n",
            "Row 378 processed successfully.\n",
            "Processing row 381...\n",
            "Row 381 processed successfully.\n",
            "Processing row 382...\n",
            "Row 382 processed successfully.\n",
            "Processing row 383...\n",
            "Row 383 processed successfully.\n",
            "Processing row 384...\n",
            "Row 384 processed successfully.\n",
            "Processing row 385...\n",
            "Row 385 processed successfully.\n",
            "Processing row 386...\n",
            "Row 386 processed successfully.\n",
            "Processing row 387...\n",
            "Row 387 processed successfully.\n",
            "Processing row 388...\n",
            "Row 388 processed successfully.\n",
            "Processing row 389...\n",
            "Row 389 processed successfully.\n",
            "Processing row 390...\n",
            "Row 390 processed successfully.\n",
            "Processing row 411...\n",
            "Row 411 processed successfully.\n",
            "Processing row 412...\n",
            "Row 412 processed successfully.\n",
            "Processing row 413...\n",
            "Row 413 processed successfully.\n",
            "Processing row 414...\n",
            "Row 414 processed successfully.\n",
            "Processing row 416...\n",
            "Row 416 processed successfully.\n",
            "Processing row 417...\n",
            "Row 417 processed successfully.\n",
            "Processing row 428...\n",
            "Row 428 processed successfully.\n",
            "Processing row 491...\n",
            "Row 491 processed successfully.\n",
            "Processing row 492...\n",
            "Row 492 processed successfully.\n",
            "Processing row 493...\n",
            "Row 493 processed successfully.\n",
            "Processing row 495...\n",
            "Row 495 processed successfully.\n",
            "Processing row 497...\n",
            "Row 497 processed successfully.\n",
            "Processing row 501...\n",
            "Row 501 processed successfully.\n",
            "Processing row 502...\n",
            "Row 502 processed successfully.\n",
            "Processing row 507...\n",
            "Row 507 processed successfully.\n",
            "Processing row 508...\n",
            "Row 508 processed successfully.\n",
            "Processing row 509...\n",
            "Row 509 processed successfully.\n",
            "Processing row 510...\n",
            "Row 510 processed successfully.\n",
            "Processing row 511...\n",
            "Row 511 processed successfully.\n",
            "Processing row 512...\n",
            "Row 512 processed successfully.\n",
            "Processing row 513...\n",
            "Row 513 processed successfully.\n",
            "Processing row 514...\n",
            "Row 514 processed successfully.\n",
            "Processing row 517...\n",
            "Row 517 processed successfully.\n",
            "Processing row 518...\n",
            "Row 518 processed successfully.\n",
            "Processing row 519...\n",
            "Row 519 processed successfully.\n",
            "Processing row 520...\n",
            "Row 520 processed successfully.\n",
            "Processing row 523...\n",
            "Row 523 processed successfully.\n",
            "Processing row 524...\n",
            "Row 524 processed successfully.\n",
            "Processing row 527...\n",
            "Row 527 processed successfully.\n",
            "Processing row 528...\n",
            "Row 528 processed successfully.\n",
            "Processing row 553...\n",
            "Row 553 processed successfully.\n",
            "Processing row 559...\n",
            "Row 559 processed successfully.\n",
            "Processing row 560...\n",
            "Row 560 processed successfully.\n",
            "Processing row 563...\n",
            "Row 563 processed successfully.\n",
            "Processing row 564...\n",
            "Row 564 processed successfully.\n",
            "Processing row 567...\n",
            "Row 567 processed successfully.\n",
            "Processing row 568...\n",
            "Row 568 processed successfully.\n",
            "Processing row 577...\n",
            "Row 577 processed successfully.\n",
            "Processing row 578...\n",
            "Row 578 processed successfully.\n",
            "Processing row 579...\n",
            "Row 579 processed successfully.\n",
            "Processing row 580...\n",
            "Row 580 processed successfully.\n",
            "Processing row 581...\n",
            "Row 581 processed successfully.\n",
            "Processing row 582...\n",
            "Row 582 processed successfully.\n",
            "Processing row 585...\n",
            "Row 585 processed successfully.\n",
            "Processing row 586...\n",
            "Row 586 processed successfully.\n",
            "Processing row 587...\n",
            "Row 587 processed successfully.\n",
            "Processing row 588...\n",
            "Row 588 processed successfully.\n",
            "Processing row 589...\n",
            "Row 589 processed successfully.\n",
            "Processing row 590...\n",
            "Row 590 processed successfully.\n",
            "Processing row 591...\n",
            "Row 591 processed successfully.\n",
            "Processing row 592...\n",
            "Row 592 processed successfully.\n",
            "Processing row 593...\n",
            "Row 593 processed successfully.\n",
            "Processing row 594...\n",
            "Row 594 processed successfully.\n",
            "Processing row 599...\n",
            "Row 599 processed successfully.\n",
            "Processing row 600...\n",
            "Row 600 processed successfully.\n",
            "Processing row 601...\n",
            "Row 601 processed successfully.\n",
            "Processing row 602...\n",
            "Row 602 processed successfully.\n",
            "Processing row 603...\n",
            "Row 603 processed successfully.\n",
            "Processing row 604...\n",
            "Row 604 processed successfully.\n",
            "Processing row 613...\n",
            "Row 613 processed successfully.\n",
            "Processing row 614...\n",
            "Row 614 processed successfully.\n",
            "Processing row 619...\n",
            "Row 619 processed successfully.\n",
            "Processing row 620...\n",
            "Row 620 processed successfully.\n",
            "Processing row 621...\n",
            "Row 621 processed successfully.\n",
            "Processing row 622...\n",
            "Row 622 processed successfully.\n",
            "Processing row 631...\n",
            "Row 631 processed successfully.\n",
            "Processing row 632...\n",
            "Row 632 processed successfully.\n",
            "Processing row 639...\n",
            "Row 639 processed successfully.\n",
            "Processing row 640...\n",
            "Row 640 processed successfully.\n",
            "Processing row 641...\n",
            "Row 641 processed successfully.\n",
            "Processing row 642...\n",
            "Row 642 processed successfully.\n",
            "Processing row 647...\n",
            "Row 647 processed successfully.\n",
            "Processing row 648...\n",
            "Row 648 processed successfully.\n",
            "Processing row 649...\n",
            "Row 649 processed successfully.\n",
            "Processing row 650...\n",
            "Row 650 processed successfully.\n",
            "Processing row 651...\n",
            "Row 651 processed successfully.\n",
            "Processing row 652...\n",
            "Row 652 processed successfully.\n",
            "Processing row 653...\n",
            "Row 653 processed successfully.\n",
            "Processing row 654...\n",
            "Row 654 processed successfully.\n",
            "Processing row 657...\n",
            "Row 657 processed successfully.\n",
            "Processing row 658...\n",
            "Row 658 processed successfully.\n",
            "Processing row 677...\n",
            "Row 677 processed successfully.\n",
            "Processing row 678...\n",
            "Row 678 processed successfully.\n",
            "Processing row 679...\n",
            "Row 679 processed successfully.\n",
            "Processing row 680...\n",
            "Row 680 processed successfully.\n",
            "Processing row 681...\n",
            "Row 681 processed successfully.\n",
            "Processing row 682...\n",
            "Row 682 processed successfully.\n",
            "Processing row 685...\n",
            "Row 685 processed successfully.\n",
            "Processing row 686...\n",
            "Row 686 processed successfully.\n",
            "Processing row 688...\n",
            "Row 688 processed successfully.\n",
            "Processing row 689...\n",
            "Row 689 processed successfully.\n",
            "Processing row 691...\n",
            "Row 691 processed successfully.\n",
            "Processing row 692...\n",
            "Row 692 processed successfully.\n",
            "Processing row 693...\n",
            "Row 693 processed successfully.\n",
            "Processing row 696...\n",
            "Row 696 processed successfully.\n",
            "Processing row 822...\n",
            "Row 822 processed successfully.\n",
            "Processing row 823...\n",
            "Row 823 processed successfully.\n",
            "Processing row 824...\n",
            "Row 824 processed successfully.\n",
            "Processing row 825...\n",
            "Row 825 processed successfully.\n",
            "Processing row 826...\n",
            "Row 826 processed successfully.\n",
            "Processing row 827...\n",
            "Row 827 processed successfully.\n",
            "Processing row 828...\n",
            "Row 828 processed successfully.\n",
            "Processing row 829...\n",
            "Row 829 processed successfully.\n",
            "Processing row 830...\n",
            "Row 830 processed successfully.\n",
            "Processing row 831...\n",
            "Row 831 processed successfully.\n",
            "Processing row 834...\n",
            "Row 834 processed successfully.\n",
            "Processing row 835...\n",
            "Row 835 processed successfully.\n",
            "Processing row 836...\n",
            "Row 836 processed successfully.\n",
            "Processing row 837...\n",
            "Row 837 processed successfully.\n",
            "Processing row 850...\n",
            "Row 850 processed successfully.\n",
            "Processing row 851...\n",
            "Row 851 processed successfully.\n",
            "Processing row 858...\n",
            "Row 858 processed successfully.\n",
            "Processing row 859...\n",
            "Row 859 processed successfully.\n",
            "Processing row 962...\n",
            "Row 962 processed successfully.\n",
            "Processing row 963...\n",
            "Row 963 processed successfully.\n",
            "Processing row 964...\n",
            "Row 964 processed successfully.\n",
            "Processing row 965...\n",
            "Row 965 processed successfully.\n",
            "Processing row 966...\n",
            "Row 966 processed successfully.\n",
            "Processing row 967...\n",
            "Row 967 processed successfully.\n",
            "Processing row 968...\n",
            "Row 968 processed successfully.\n",
            "Processing row 969...\n",
            "Row 969 processed successfully.\n",
            "Processing row 984...\n",
            "Row 984 processed successfully.\n",
            "Processing row 985...\n",
            "Row 985 processed successfully.\n",
            "Processing row 986...\n",
            "Row 986 processed successfully.\n",
            "Processing row 987...\n",
            "Row 987 processed successfully.\n",
            "Processing row 988...\n",
            "Row 988 processed successfully.\n",
            "Processing row 989...\n",
            "Row 989 processed successfully.\n",
            "Processing row 994...\n",
            "Row 994 processed successfully.\n",
            "Processing row 995...\n",
            "Row 995 processed successfully.\n",
            "Processing row 996...\n",
            "Row 996 processed successfully.\n",
            "Processing row 997...\n",
            "Row 997 processed successfully.\n",
            "Processing row 1000...\n",
            "Row 1000 processed successfully.\n",
            "Processing row 1001...\n",
            "Row 1001 processed successfully.\n",
            "Processing row 1002...\n",
            "Row 1002 processed successfully.\n",
            "Processing row 1003...\n",
            "Row 1003 processed successfully.\n",
            "Processing row 1004...\n",
            "Row 1004 processed successfully.\n",
            "Processing row 1005...\n",
            "Row 1005 processed successfully.\n",
            "Processing row 1006...\n",
            "Row 1006 processed successfully.\n",
            "Processing row 1007...\n",
            "Row 1007 processed successfully.\n",
            "Processing row 1008...\n",
            "Row 1008 processed successfully.\n",
            "Processing row 1009...\n",
            "Row 1009 processed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spider_valid_pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0-uQQdiR-MNm",
        "outputId": "a04698dc-5593-4369-b0e8-456b80dbef16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     index    ID                                        answer_text  \\\n",
              "0        0     0                                                [6]   \n",
              "1        1     1                                                [6]   \n",
              "2        2     2  [Joe Sharp, Netherlands, 52, John Nizinik, Fra...   \n",
              "3        3     3  [Joe Sharp, Netherlands, 52, John Nizinik, Fra...   \n",
              "4        4     8               [Netherlands, United States, France]   \n",
              "..     ...   ...                                                ...   \n",
              "206    211  1005  [1944.0, France, 1948.0, United States, 1949.0...   \n",
              "207    212  1006  [Christy Walton, Alice Walton, Iris Fontbona, ...   \n",
              "208    213  1007  [Christy Walton, Alice Walton, Iris Fontbona, ...   \n",
              "209    214  1008                     [Christy Walton, Alice Walton]   \n",
              "210    215  1009                     [Christy Walton, Alice Walton]   \n",
              "\n",
              "              db_id                                              query  \\\n",
              "0    concert_singer                        SELECT count(*) FROM singer   \n",
              "1    concert_singer                        SELECT count(*) FROM singer   \n",
              "2    concert_singer  SELECT name ,  country ,  age FROM singer ORDE...   \n",
              "3    concert_singer  SELECT name ,  country ,  age FROM singer ORDE...   \n",
              "4    concert_singer  SELECT DISTINCT country FROM singer WHERE age ...   \n",
              "..              ...                                                ...   \n",
              "206          singer       SELECT Birth_Year ,  Citizenship FROM singer   \n",
              "207          singer  SELECT Name FROM singer WHERE Citizenship != \"...   \n",
              "208          singer  SELECT Name FROM singer WHERE Citizenship != \"...   \n",
              "209          singer  SELECT Name FROM singer WHERE Birth_Year  =  1...   \n",
              "210          singer  SELECT Name FROM singer WHERE Birth_Year  =  1...   \n",
              "\n",
              "                                              question  \\\n",
              "0                         How many singers do we have?   \n",
              "1                 What is the total number of singers?   \n",
              "2    Show name, country, age for all singers ordere...   \n",
              "3    What are the names, countries, and ages for ev...   \n",
              "4    What are all distinct countries where singers ...   \n",
              "..                                                 ...   \n",
              "206  What are the birth years and citizenships of t...   \n",
              "207  List the name of singers whose citizenship is ...   \n",
              "208  What are the names of the singers who are not ...   \n",
              "209  Show the name of singers whose birth year is e...   \n",
              "210  What are the names of the singers whose birth ...   \n",
              "\n",
              "                                            query_toks  \\\n",
              "0               [SELECT, count, (, *, ), FROM, singer]   \n",
              "1               [SELECT, count, (, *, ), FROM, singer]   \n",
              "2    [SELECT, name, ,, country, ,, age, FROM, singe...   \n",
              "3    [SELECT, name, ,, country, ,, age, FROM, singe...   \n",
              "4    [SELECT, DISTINCT, country, FROM, singer, WHER...   \n",
              "..                                                 ...   \n",
              "206  [SELECT, Birth_Year, ,, Citizenship, FROM, sin...   \n",
              "207  [SELECT, Name, FROM, singer, WHERE, Citizenshi...   \n",
              "208  [SELECT, Name, FROM, singer, WHERE, Citizenshi...   \n",
              "209  [SELECT, Name, FROM, singer, WHERE, Birth_Year...   \n",
              "210  [SELECT, Name, FROM, singer, WHERE, Birth_Year...   \n",
              "\n",
              "                                   query_toks_no_value  \\\n",
              "0               [select, count, (, *, ), from, singer]   \n",
              "1               [select, count, (, *, ), from, singer]   \n",
              "2    [select, name, ,, country, ,, age, from, singe...   \n",
              "3    [select, name, ,, country, ,, age, from, singe...   \n",
              "4    [select, distinct, country, from, singer, wher...   \n",
              "..                                                 ...   \n",
              "206  [select, birth_year, ,, citizenship, from, sin...   \n",
              "207  [select, name, from, singer, where, citizenshi...   \n",
              "208  [select, name, from, singer, where, citizenshi...   \n",
              "209  [select, name, from, singer, where, birth_year...   \n",
              "210  [select, name, from, singer, where, birth_year...   \n",
              "\n",
              "                                         question_toks tbl_name operator  \\\n",
              "0                [How, many, singers, do, we, have, ?]   singer    count   \n",
              "1       [What, is, the, total, number, of, singers, ?]   singer    count   \n",
              "2    [Show, name, ,, country, ,, age, for, all, sin...   singer      NaN   \n",
              "3    [What, are, the, names, ,, countries, ,, and, ...   singer      NaN   \n",
              "4    [What, are, all, distinct, countries, where, s...   singer      NaN   \n",
              "..                                                 ...      ...      ...   \n",
              "206  [What, are, the, birth, years, and, citizenshi...   singer      NaN   \n",
              "207  [List, the, name, of, singers, whose, citizens...   singer      NaN   \n",
              "208  [What, are, the, names, of, the, singers, who,...   singer      NaN   \n",
              "209  [Show, the, name, of, singers, whose, birth, y...   singer      NaN   \n",
              "210  [What, are, the, names, of, the, singers, whos...   singer      NaN   \n",
              "\n",
              "                      seq_id                                        input  \n",
              "0    concert_singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "1    concert_singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "2    concert_singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "3    concert_singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "4    concert_singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "..                       ...                                          ...  \n",
              "206          singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "207          singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "208          singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "209          singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "210          singer_X_singer  [input_ids, token_type_ids, attention_mask]  \n",
              "\n",
              "[211 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b615836-0d32-4359-896f-b6bcae15855d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>ID</th>\n",
              "      <th>answer_text</th>\n",
              "      <th>db_id</th>\n",
              "      <th>query</th>\n",
              "      <th>question</th>\n",
              "      <th>query_toks</th>\n",
              "      <th>query_toks_no_value</th>\n",
              "      <th>question_toks</th>\n",
              "      <th>tbl_name</th>\n",
              "      <th>operator</th>\n",
              "      <th>seq_id</th>\n",
              "      <th>input</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[6]</td>\n",
              "      <td>concert_singer</td>\n",
              "      <td>SELECT count(*) FROM singer</td>\n",
              "      <td>How many singers do we have?</td>\n",
              "      <td>[SELECT, count, (, *, ), FROM, singer]</td>\n",
              "      <td>[select, count, (, *, ), from, singer]</td>\n",
              "      <td>[How, many, singers, do, we, have, ?]</td>\n",
              "      <td>singer</td>\n",
              "      <td>count</td>\n",
              "      <td>concert_singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[6]</td>\n",
              "      <td>concert_singer</td>\n",
              "      <td>SELECT count(*) FROM singer</td>\n",
              "      <td>What is the total number of singers?</td>\n",
              "      <td>[SELECT, count, (, *, ), FROM, singer]</td>\n",
              "      <td>[select, count, (, *, ), from, singer]</td>\n",
              "      <td>[What, is, the, total, number, of, singers, ?]</td>\n",
              "      <td>singer</td>\n",
              "      <td>count</td>\n",
              "      <td>concert_singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[Joe Sharp, Netherlands, 52, John Nizinik, Fra...</td>\n",
              "      <td>concert_singer</td>\n",
              "      <td>SELECT name ,  country ,  age FROM singer ORDE...</td>\n",
              "      <td>Show name, country, age for all singers ordere...</td>\n",
              "      <td>[SELECT, name, ,, country, ,, age, FROM, singe...</td>\n",
              "      <td>[select, name, ,, country, ,, age, from, singe...</td>\n",
              "      <td>[Show, name, ,, country, ,, age, for, all, sin...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>concert_singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>[Joe Sharp, Netherlands, 52, John Nizinik, Fra...</td>\n",
              "      <td>concert_singer</td>\n",
              "      <td>SELECT name ,  country ,  age FROM singer ORDE...</td>\n",
              "      <td>What are the names, countries, and ages for ev...</td>\n",
              "      <td>[SELECT, name, ,, country, ,, age, FROM, singe...</td>\n",
              "      <td>[select, name, ,, country, ,, age, from, singe...</td>\n",
              "      <td>[What, are, the, names, ,, countries, ,, and, ...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>concert_singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>[Netherlands, United States, France]</td>\n",
              "      <td>concert_singer</td>\n",
              "      <td>SELECT DISTINCT country FROM singer WHERE age ...</td>\n",
              "      <td>What are all distinct countries where singers ...</td>\n",
              "      <td>[SELECT, DISTINCT, country, FROM, singer, WHER...</td>\n",
              "      <td>[select, distinct, country, from, singer, wher...</td>\n",
              "      <td>[What, are, all, distinct, countries, where, s...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>concert_singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>211</td>\n",
              "      <td>1005</td>\n",
              "      <td>[1944.0, France, 1948.0, United States, 1949.0...</td>\n",
              "      <td>singer</td>\n",
              "      <td>SELECT Birth_Year ,  Citizenship FROM singer</td>\n",
              "      <td>What are the birth years and citizenships of t...</td>\n",
              "      <td>[SELECT, Birth_Year, ,, Citizenship, FROM, sin...</td>\n",
              "      <td>[select, birth_year, ,, citizenship, from, sin...</td>\n",
              "      <td>[What, are, the, birth, years, and, citizenshi...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>212</td>\n",
              "      <td>1006</td>\n",
              "      <td>[Christy Walton, Alice Walton, Iris Fontbona, ...</td>\n",
              "      <td>singer</td>\n",
              "      <td>SELECT Name FROM singer WHERE Citizenship != \"...</td>\n",
              "      <td>List the name of singers whose citizenship is ...</td>\n",
              "      <td>[SELECT, Name, FROM, singer, WHERE, Citizenshi...</td>\n",
              "      <td>[select, name, from, singer, where, citizenshi...</td>\n",
              "      <td>[List, the, name, of, singers, whose, citizens...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>213</td>\n",
              "      <td>1007</td>\n",
              "      <td>[Christy Walton, Alice Walton, Iris Fontbona, ...</td>\n",
              "      <td>singer</td>\n",
              "      <td>SELECT Name FROM singer WHERE Citizenship != \"...</td>\n",
              "      <td>What are the names of the singers who are not ...</td>\n",
              "      <td>[SELECT, Name, FROM, singer, WHERE, Citizenshi...</td>\n",
              "      <td>[select, name, from, singer, where, citizenshi...</td>\n",
              "      <td>[What, are, the, names, of, the, singers, who,...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>214</td>\n",
              "      <td>1008</td>\n",
              "      <td>[Christy Walton, Alice Walton]</td>\n",
              "      <td>singer</td>\n",
              "      <td>SELECT Name FROM singer WHERE Birth_Year  =  1...</td>\n",
              "      <td>Show the name of singers whose birth year is e...</td>\n",
              "      <td>[SELECT, Name, FROM, singer, WHERE, Birth_Year...</td>\n",
              "      <td>[select, name, from, singer, where, birth_year...</td>\n",
              "      <td>[Show, the, name, of, singers, whose, birth, y...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>215</td>\n",
              "      <td>1009</td>\n",
              "      <td>[Christy Walton, Alice Walton]</td>\n",
              "      <td>singer</td>\n",
              "      <td>SELECT Name FROM singer WHERE Birth_Year  =  1...</td>\n",
              "      <td>What are the names of the singers whose birth ...</td>\n",
              "      <td>[SELECT, Name, FROM, singer, WHERE, Birth_Year...</td>\n",
              "      <td>[select, name, from, singer, where, birth_year...</td>\n",
              "      <td>[What, are, the, names, of, the, singers, whos...</td>\n",
              "      <td>singer</td>\n",
              "      <td>NaN</td>\n",
              "      <td>singer_X_singer</td>\n",
              "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>211 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b615836-0d32-4359-896f-b6bcae15855d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b615836-0d32-4359-896f-b6bcae15855d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b615836-0d32-4359-896f-b6bcae15855d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d49ecc36-404c-498c-8699-c344525a259e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d49ecc36-404c-498c-8699-c344525a259e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d49ecc36-404c-498c-8699-c344525a259e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "spider_valid_pd",
              "summary": "{\n  \"name\": \"spider_valid_pd\",\n  \"rows\": 211,\n  \"fields\": [\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 62,\n        \"min\": 0,\n        \"max\": 215,\n        \"num_unique_values\": 211,\n        \"samples\": [\n          32,\n          178,\n          145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 1009,\n        \"num_unique_values\": 211,\n        \"samples\": [\n          273,\n          830,\n          642\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer_text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"db_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"tvshow\",\n          \"voter_1\",\n          \"concert_singer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 115,\n        \"samples\": [\n          \"SELECT avg(Earnings) FROM poker_player\",\n          \"SELECT count(*) FROM CONTINENTS;\",\n          \"SELECT Num_of_Staff ,  Open_Year FROM museum WHERE name  =  'Plaza Museum'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 211,\n        \"samples\": [\n          \"Return the name, location and district of all shops in descending order of number of products.\",\n          \"What is the average attendance of shows?\",\n          \"What are the ids of all tv channels that have more than 2 TV channels?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_toks\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_toks_no_value\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_toks\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tbl_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 37,\n        \"samples\": [\n          \"death\",\n          \"visitor\",\n          \"airlines\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"operator\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"sum\",\n          \"max\",\n          \"count\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seq_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 38,\n        \"samples\": [\n          \"orchestra_X_show\",\n          \"dog_kennels_X_Treatments\",\n          \"flight_2_X_airlines\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this is the default WTQ configuration\n",
        "config = TapasConfig(\n",
        "    num_aggregation_labels=4,# MAX MIN COUNT AVG\n",
        "    use_answer_as_supervision=True,\n",
        "    answer_loss_cutoff=0.664694,\n",
        "    cell_selection_preference=0.207951,\n",
        "    huber_loss_delta=0.121194,\n",
        "    init_cell_selection_weights_to_zero=True,\n",
        "    select_one_column=True,\n",
        "    allow_empty_column_selection=False,\n",
        "    temperature=0.0352513,\n",
        ")\n",
        "model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base\", config=config)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "model.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7f169bbeda5f4a00a9ef92d0f46d249e",
            "bb78a3dc9994499594bb435fb0659d26",
            "ce05880210e7446cad6c53ad6de4832f",
            "6d2a58e431074bf4b7f992721a3a7b45",
            "066c589839bd4688afc18f034c0f8e64",
            "2ea135fd266342ad8966bfe6335d817e",
            "3f7edc5ecd0d43fd869ae6bb5be7e8ec",
            "a56a9a9090a449568be898b4af72ad2b",
            "64cf20a0bd004ca89495a8f575311451",
            "a8280ea1393f4f528a035539af391a94",
            "92f81ae8218d4c4e81923ae36c7a1bbf"
          ]
        },
        "id": "ddNnWlD7scm2",
        "outputId": "055e7852-bbc3-48e4-b5f0-49696aa6748e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f169bbeda5f4a00a9ef92d0f46d249e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of TapasForQuestionAnswering were not initialized from the model checkpoint at google/tapas-base and are newly initialized: ['aggregation_classifier.bias', 'aggregation_classifier.weight', 'column_output_bias', 'column_output_weights', 'output_bias', 'output_weights']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TapasForQuestionAnswering(\n",
              "  (tapas): TapasModel(\n",
              "    (embeddings): TapasEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(1024, 768)\n",
              "      (token_type_embeddings_0): Embedding(3, 768)\n",
              "      (token_type_embeddings_1): Embedding(256, 768)\n",
              "      (token_type_embeddings_2): Embedding(256, 768)\n",
              "      (token_type_embeddings_3): Embedding(2, 768)\n",
              "      (token_type_embeddings_4): Embedding(256, 768)\n",
              "      (token_type_embeddings_5): Embedding(256, 768)\n",
              "      (token_type_embeddings_6): Embedding(10, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): TapasEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x TapasLayer(\n",
              "          (attention): TapasAttention(\n",
              "            (self): TapasSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): TapasSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): TapasIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): TapasOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): TapasPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (aggregation_classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats_columns = ['epoch', 'avg_loss', 'avg_cell_precision', 'avg_cell_recall', 'avg_tuple_cardinality', 'avg_tuple_constraint', 'avg_tuple_order']\n",
        "stats_df = pd.DataFrame(columns=stats_columns)\n",
        "# Create the scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
        "\n",
        "# model.train()\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "    print(\"Epoch:\", epoch)\n",
        "    epoch_loss = 0.0\n",
        "    for batch in train_dataloader:\n",
        "        # get the inputs;\n",
        "        input_ids = batch[\"input_ids\"].to('cuda')\n",
        "        attention_mask = batch[\"attention_mask\"].to('cuda')\n",
        "        token_type_ids = batch[\"token_type_ids\"].to('cuda')\n",
        "        labels = batch[\"labels\"].to('cuda')\n",
        "        numeric_values = batch[\"numeric_values\"].to('cuda')\n",
        "        numeric_values_scale = batch[\"numeric_values_scale\"].to('cuda')\n",
        "        float_answer = batch[\"float_answer\"].to('cuda')\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            labels=labels,\n",
        "            numeric_values=numeric_values,\n",
        "            numeric_values_scale=numeric_values_scale,\n",
        "            float_answer=float_answer,\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        print(\"Loss:\", loss.item())\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    avg_loss = epoch_loss / len(train_dataloader)\n",
        "\n",
        "    # Update the learning rate based on the average loss\n",
        "    scheduler.step(avg_loss)\n",
        "    spider_valid_pd['predictions_TAPAS'] = spider_valid_pd.apply(getAnswerValid, axis=1)\n",
        "    tests_df_results = evaluator.evaluate_with_df(spider_valid_pd,\n",
        "                                      prediction_col_name=f'predictions_TAPAS',\n",
        "                                      task=\"QA\")\n",
        "\n",
        "    mean_cell_precision = tests_df_results['cell_precision_predictions_TAPAS'].mean()\n",
        "    mean_cell_recall = tests_df_results['cell_recall_predictions_TAPAS'].mean()\n",
        "    mean_tuple_cardinality = tests_df_results['tuple_cardinality_predictions_TAPAS'].mean()\n",
        "    mean_tuple_constraint = tests_df_results['tuple_constraint_predictions_TAPAS'].mean()\n",
        "    mean_tuple_order = tests_df_results['tuple_order_predictions_TAPAS'].mean()\n",
        "\n",
        "    print(f\"Model Performance Metrics for epoch:{epoch}\")\n",
        "    print(\"----------------------------\")\n",
        "    print(\"Avg loss\",avg_loss)\n",
        "    print(\"Average Cell Precision:\", mean_cell_precision)\n",
        "    print(\"Average Cell Recall:\", mean_cell_recall)\n",
        "    print(\"Average Tuple Cardinality Accuracy:\", mean_tuple_cardinality)\n",
        "    print(\"Average Tuple Constraint Accuracy:\", mean_tuple_constraint)\n",
        "    print(\"Average Tuple Order Accuracy:\", mean_tuple_order)\n",
        "    print(\"----------------------------\")\n",
        "    # Append statistics for this epoch to the DataFrame\n",
        "    epoch_stats_df = pd.DataFrame([{\n",
        "        'epoch': epoch,\n",
        "        'avg_loss': avg_loss,\n",
        "        'avg_cell_precision': mean_cell_precision,\n",
        "        'avg_cell_recall': mean_cell_recall,\n",
        "        'avg_tuple_cardinality': mean_tuple_cardinality,\n",
        "        'avg_tuple_constraint': mean_tuple_constraint,\n",
        "        'avg_tuple_order': mean_tuple_order,\n",
        "    }])\n",
        "    stats_df = pd.concat([stats_df, epoch_stats_df], ignore_index=True)\n",
        "stats_df.to_csv('/content/drive/MyDrive/model_checkpoints/stats_model_spiderQatch2000', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZGlzWxrtmBs",
        "outputId": "fa2bf44d-0451-41a6-a097-44d656fa708b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "Loss: 0.4827987849712372\n",
            "Loss: 0.37681007385253906\n",
            "Loss: 0.2780929505825043\n",
            "Loss: 0.015282493084669113\n",
            "Loss: 0.20480428636074066\n",
            "Loss: 0.1590030938386917\n",
            "Loss: 0.1029558777809143\n",
            "Loss: 1.3068126440048218\n",
            "Loss: 0.3034680187702179\n",
            "Loss: 0.3014427721500397\n",
            "Loss: 0.7713432312011719\n",
            "Loss: 0.15446807444095612\n",
            "Loss: 0.3984731435775757\n",
            "Loss: 0.14416226744651794\n",
            "Loss: 0.0641130656003952\n",
            "Loss: 0.4175359904766083\n",
            "Loss: 0.17051322758197784\n",
            "Loss: 0.36167797446250916\n",
            "Loss: 0.5324742197990417\n",
            "Loss: 0.2484447956085205\n",
            "Loss: 0.16328707337379456\n",
            "Loss: 0.4947841763496399\n",
            "Loss: 0.2912781238555908\n",
            "Loss: 0.2091706097126007\n",
            "Loss: 0.27878156304359436\n",
            "Loss: 0.04884657263755798\n",
            "Loss: 0.20480778813362122\n",
            "Loss: 0.1571599841117859\n",
            "Loss: 0.18694321811199188\n",
            "Loss: 0.0775856226682663\n",
            "Loss: 0.19523897767066956\n",
            "Loss: 0.2796330153942108\n",
            "Loss: 0.20826172828674316\n",
            "Loss: 0.24966277182102203\n",
            "Loss: 0.14939840137958527\n",
            "Loss: 0.08269080519676208\n",
            "Loss: 0.1417185217142105\n",
            "Loss: 0.2992289662361145\n",
            "Loss: 0.07646604627370834\n",
            "Loss: 0.6031076312065125\n",
            "Loss: 0.3079189956188202\n",
            "Loss: 0.10269152373075485\n",
            "Loss: 0.15683500468730927\n",
            "Loss: 0.5053335428237915\n",
            "Loss: 0.19602084159851074\n",
            "Loss: 0.3488917052745819\n",
            "Loss: 0.10961249470710754\n",
            "Loss: 0.05713117867708206\n",
            "Loss: 0.05044892430305481\n",
            "Loss: 0.15714216232299805\n",
            "Loss: 0.29466134309768677\n",
            "Loss: 0.23685917258262634\n",
            "Loss: 0.08100464940071106\n",
            "Loss: 0.035964302718639374\n",
            "Loss: 0.2655658423900604\n",
            "Loss: 0.18122033774852753\n",
            "Loss: 0.09292927384376526\n",
            "Loss: 0.05088502913713455\n",
            "Loss: 0.14792270958423615\n",
            "Loss: 0.11491646617650986\n",
            "Loss: 0.0071450406685471535\n",
            "Loss: 0.14099334180355072\n",
            "Loss: 0.1073765903711319\n",
            "Loss: 0.15563815832138062\n",
            "Loss: 0.01364803034812212\n",
            "Loss: 0.02389194443821907\n",
            "Loss: 0.36571910977363586\n",
            "Loss: 0.12795835733413696\n",
            "Loss: 0.04444439709186554\n",
            "Loss: 0.07873664796352386\n",
            "Loss: 0.1109650656580925\n",
            "Loss: 0.17131924629211426\n",
            "Loss: 0.11751095950603485\n",
            "Loss: 0.014798721298575401\n",
            "Loss: 0.006477262359112501\n",
            "Loss: 0.1472611129283905\n",
            "Loss: 0.9862770438194275\n",
            "Loss: 0.16055922210216522\n",
            "Loss: 0.12509842216968536\n",
            "Loss: 0.1672849953174591\n",
            "Loss: 0.31387513875961304\n",
            "Loss: 0.1338653266429901\n",
            "Loss: 0.04626685380935669\n",
            "Loss: 0.16776420176029205\n",
            "Loss: 0.06264755874872208\n",
            "Loss: 0.11600314825773239\n",
            "Loss: 0.047563765197992325\n",
            "Loss: 0.03347541764378548\n",
            "Loss: 0.02367953397333622\n",
            "Loss: 0.23578239977359772\n",
            "Loss: 0.18429455161094666\n",
            "Loss: 0.022380879148840904\n",
            "Loss: 0.1027100682258606\n",
            "Loss: 0.18001972138881683\n",
            "Loss: 0.07481418550014496\n",
            "Loss: 0.2687482535839081\n",
            "Loss: 0.22651037573814392\n",
            "Loss: 0.014900102280080318\n",
            "Loss: 0.09795848280191422\n",
            "Loss: 0.05886811017990112\n",
            "Loss: 0.05773060768842697\n",
            "Loss: 0.01682932674884796\n",
            "Loss: 0.09806836396455765\n",
            "Loss: 0.31166359782218933\n",
            "Loss: 0.05612538382411003\n",
            "Loss: 0.015150700695812702\n",
            "Loss: 0.10704942792654037\n",
            "Loss: 0.16242380440235138\n",
            "Loss: 0.03357405960559845\n",
            "Loss: 0.2029949575662613\n",
            "Loss: 0.46117809414863586\n",
            "Loss: 0.07727671414613724\n",
            "Loss: 0.15883095562458038\n",
            "Loss: 0.06009374558925629\n",
            "Loss: 0.034827541559934616\n",
            "Loss: 0.0808597207069397\n",
            "Loss: 0.017196856439113617\n",
            "Loss: 0.0467747263610363\n",
            "Loss: 0.19487765431404114\n",
            "Loss: 0.22079616785049438\n",
            "Loss: 0.23719893395900726\n",
            "Loss: 0.10162131488323212\n",
            "Loss: 0.13292863965034485\n",
            "Loss: 0.08926083892583847\n",
            "Loss: 0.3589481711387634\n",
            "Loss: 0.1774538904428482\n",
            "Loss: 0.18321044743061066\n",
            "Loss: 0.08977484703063965\n",
            "Loss: 0.08905397355556488\n",
            "Loss: 0.056957826018333435\n",
            "Loss: 0.052475444972515106\n",
            "Loss: 0.13304035365581512\n",
            "Loss: 0.11362969875335693\n",
            "Loss: 0.20028601586818695\n",
            "Loss: 0.2605627775192261\n",
            "Loss: 0.22064907848834991\n",
            "Loss: 0.04913019388914108\n",
            "Loss: 0.09646269679069519\n",
            "Loss: 0.2478761076927185\n",
            "Loss: 0.05098467320203781\n",
            "Loss: 0.10464998334646225\n",
            "Loss: 0.17259114980697632\n",
            "Loss: 0.01705518737435341\n",
            "Loss: 0.12439651787281036\n",
            "Loss: 0.25784239172935486\n",
            "Loss: 0.06256698071956635\n",
            "Loss: 0.014271784573793411\n",
            "Loss: 0.12827599048614502\n",
            "Loss: 0.13182242214679718\n",
            "Loss: 0.1556837558746338\n",
            "Loss: 0.059636279940605164\n",
            "Loss: 0.35644271969795227\n",
            "Loss: 0.0954226478934288\n",
            "Loss: 0.13868612051010132\n",
            "Loss: 0.5197067856788635\n",
            "Loss: 0.14077579975128174\n",
            "Loss: 0.1519680917263031\n",
            "Loss: 0.07719649374485016\n",
            "Loss: 0.06698714196681976\n",
            "Loss: 0.10441318899393082\n",
            "Loss: 0.030740153044462204\n",
            "Loss: 0.0276134442538023\n",
            "Loss: 0.07007262855768204\n",
            "Loss: 0.1058797612786293\n",
            "Loss: 0.181168794631958\n",
            "Loss: 0.059626415371894836\n",
            "Loss: 0.14341570436954498\n",
            "Loss: 0.010581284761428833\n",
            "Loss: 0.07562722265720367\n",
            "Loss: 0.053292419761419296\n",
            "Loss: 0.05036495253443718\n",
            "Loss: 0.05162135511636734\n",
            "Loss: 0.07275492697954178\n",
            "Loss: 0.07964692264795303\n",
            "Loss: 0.20005269348621368\n",
            "Loss: 0.3115764558315277\n",
            "Loss: 0.044316086918115616\n",
            "Loss: 0.16307441890239716\n",
            "Loss: 0.004706316161900759\n",
            "Loss: 0.0011190288932994008\n",
            "Loss: 0.04511139541864395\n",
            "Loss: 0.13916298747062683\n",
            "Loss: 0.06675361096858978\n",
            "Loss: 0.013148674741387367\n",
            "Loss: 0.11411969363689423\n",
            "Loss: 0.0061781033873558044\n",
            "Loss: 0.06303153932094574\n",
            "Loss: 0.0498841255903244\n",
            "Loss: 0.01990516297519207\n",
            "Loss: 0.008528301492333412\n",
            "Loss: 0.03182988986372948\n",
            "Loss: 0.0046213725581765175\n",
            "Loss: 0.08197244256734848\n",
            "Loss: 0.3219013810157776\n",
            "Loss: 0.18285736441612244\n",
            "Loss: 0.13175994157791138\n",
            "Loss: 0.11857493221759796\n",
            "Loss: 0.1133977398276329\n",
            "Loss: 0.0029401397332549095\n",
            "Loss: 0.1286037266254425\n",
            "Loss: 0.05307493731379509\n",
            "Loss: 0.07683009654283524\n",
            "Loss: 0.03853560984134674\n",
            "Loss: 0.008955464698374271\n",
            "Loss: 0.07758162915706635\n",
            "Loss: 0.10169252753257751\n",
            "Loss: 0.20492376387119293\n",
            "Loss: 0.14066703617572784\n",
            "Loss: 0.3900908827781677\n",
            "Loss: 0.05235883221030235\n",
            "Loss: 0.013529781252145767\n",
            "Loss: 0.2079237401485443\n",
            "Loss: 0.44407975673675537\n",
            "Loss: 0.5863765478134155\n",
            "Loss: 0.43599751591682434\n",
            "Loss: 0.39410579204559326\n",
            "Loss: 0.5660862922668457\n",
            "Loss: 0.3862621486186981\n",
            "Loss: 0.445558100938797\n",
            "Loss: 0.3604300320148468\n",
            "Loss: 0.373874306678772\n",
            "Loss: 0.43751874566078186\n",
            "Loss: 0.2585323750972748\n",
            "Loss: 0.3685203790664673\n",
            "Loss: 0.6430363655090332\n",
            "Loss: 0.4449462294578552\n",
            "Loss: 0.433493435382843\n",
            "Loss: 0.4115828275680542\n",
            "Loss: 0.4520140588283539\n",
            "Loss: 0.30620425939559937\n",
            "Loss: 0.15830975770950317\n",
            "Loss: 0.1842249482870102\n",
            "Loss: 0.2137470245361328\n",
            "Loss: 0.031224515289068222\n",
            "Loss: 0.0942731723189354\n",
            "Loss: 0.05361618474125862\n",
            "Loss: 0.05429673194885254\n",
            "Loss: 0.16116739809513092\n",
            "Loss: 0.0416623018682003\n",
            "Loss: 0.08441153168678284\n",
            "Loss: 0.06906789541244507\n",
            "Loss: 0.05341588705778122\n",
            "Loss: 0.0234629288315773\n",
            "Loss: 0.029059238731861115\n",
            "Loss: 0.026072297245264053\n",
            "Loss: 0.07899367064237595\n",
            "Loss: 0.06263189017772675\n",
            "Loss: 0.03694421052932739\n",
            "Loss: 0.11146619915962219\n",
            "Loss: 0.285150408744812\n",
            "Loss: 0.25846508145332336\n",
            "Loss: 0.10161922127008438\n",
            "Loss: 0.23120927810668945\n",
            "Loss: 0.07675004005432129\n",
            "Loss: 0.057555221021175385\n",
            "Loss: 0.07050631940364838\n",
            "Loss: 0.00611135084182024\n",
            "Loss: 0.001110877376049757\n",
            "Loss: 0.064825639128685\n",
            "Loss: 0.0754760354757309\n",
            "Loss: 0.12016865611076355\n",
            "Loss: 0.30758246779441833\n",
            "Loss: 0.09626864641904831\n",
            "Loss: 0.0055772531777620316\n",
            "Loss: 0.07958292961120605\n",
            "Loss: 0.08252021670341492\n",
            "Loss: 0.05336079001426697\n",
            "Loss: 0.1952267438173294\n",
            "Loss: 0.36317747831344604\n",
            "Loss: 0.10120674967765808\n",
            "Loss: 0.18125320971012115\n",
            "Loss: 0.001216593198478222\n",
            "Loss: 0.005014965310692787\n",
            "Loss: 0.0031618252396583557\n",
            "Loss: 0.0036880967672914267\n",
            "Loss: 0.024025551974773407\n",
            "Loss: 0.005588163156062365\n",
            "Loss: 0.001169244758784771\n",
            "Loss: 0.00204825634136796\n",
            "Loss: 0.0019850926473736763\n",
            "Loss: 0.0013407173100858927\n",
            "Loss: 0.0008456473588012159\n",
            "Loss: 0.0024430090561509132\n",
            "Loss: 0.0008096236851997674\n",
            "Loss: 0.0010232292115688324\n",
            "Loss: 0.0005066485609859228\n",
            "Loss: 0.0015592467971146107\n",
            "Loss: 0.0008308810647577047\n",
            "Loss: 0.0007224857690744102\n",
            "Loss: 0.0014041638933122158\n",
            "Loss: 0.0012202406069263816\n",
            "Loss: 0.06860145181417465\n",
            "Loss: 0.08217616379261017\n",
            "Loss: 0.021268703043460846\n",
            "Loss: 0.31240177154541016\n",
            "Loss: 0.45999959111213684\n",
            "Loss: 0.05686037614941597\n",
            "Loss: 0.05489690601825714\n",
            "Loss: 0.015614867210388184\n",
            "Loss: 0.0015705061377957463\n",
            "Loss: 0.03046560473740101\n",
            "Loss: 0.03212963789701462\n",
            "Loss: 0.0103367380797863\n",
            "Loss: 0.019672036170959473\n",
            "Loss: 0.03107261098921299\n",
            "Loss: 0.04030325263738632\n",
            "Loss: 0.3239437937736511\n",
            "Loss: 0.38454195857048035\n",
            "Loss: 0.006760088726878166\n",
            "Loss: 1.0707340240478516\n",
            "Loss: 0.02913900837302208\n",
            "Loss: 0.061351027339696884\n",
            "Loss: 0.007014350965619087\n",
            "Loss: 0.0714605376124382\n",
            "Loss: 0.016085738316178322\n",
            "Loss: 0.0020354583393782377\n",
            "Loss: 0.02054794877767563\n",
            "Loss: 0.03979851305484772\n",
            "Loss: 0.0020362786017358303\n",
            "Loss: 0.03916049748659134\n",
            "Loss: 0.02307851053774357\n",
            "Loss: 0.33055323362350464\n",
            "Loss: 0.1901794672012329\n",
            "Loss: 0.02355286478996277\n",
            "Loss: 0.3297748863697052\n",
            "Loss: 0.2815066874027252\n",
            "Loss: 0.023533349856734276\n",
            "Loss: 0.03280605748295784\n",
            "Loss: 0.0201287679374218\n",
            "Loss: 0.01343922782689333\n",
            "Loss: 0.06231502443552017\n",
            "Loss: 0.037197861820459366\n",
            "Loss: 0.03341006860136986\n",
            "Loss: 0.42953574657440186\n",
            "Loss: 0.016804667189717293\n",
            "Loss: 0.030941762030124664\n",
            "Loss: 0.0037804681342095137\n",
            "Loss: 0.34646129608154297\n",
            "Loss: 0.002322167158126831\n",
            "Loss: 0.04492685943841934\n",
            "Loss: 0.010228297673165798\n",
            "Loss: 0.09792451560497284\n",
            "Loss: 0.0013234361540526152\n",
            "Loss: 0.06897244602441788\n",
            "Loss: 0.001131063443608582\n",
            "Loss: 0.037438470870256424\n",
            "Loss: 0.06411112844944\n",
            "Loss: 0.06859344989061356\n",
            "Loss: 0.010746730491518974\n",
            "Loss: 0.293761670589447\n",
            "Loss: 0.0897807702422142\n",
            "Loss: 0.10973912477493286\n",
            "Loss: 0.13677918910980225\n",
            "Loss: 0.09406110644340515\n",
            "Loss: 0.25844550132751465\n",
            "Loss: 0.25257307291030884\n",
            "Loss: 0.26232844591140747\n",
            "Loss: 0.3540455102920532\n",
            "Loss: 0.18343165516853333\n",
            "Loss: 0.2545892000198364\n",
            "Loss: 0.1421935260295868\n",
            "Loss: 0.1178024411201477\n",
            "Loss: 0.04552595689892769\n",
            "Loss: 0.04223078489303589\n",
            "Loss: 0.20341457426548004\n",
            "Loss: 0.6925181746482849\n",
            "Loss: 0.11560560017824173\n",
            "Loss: 0.07717228680849075\n",
            "Loss: 0.27687108516693115\n",
            "Loss: 0.13072313368320465\n",
            "Loss: 0.13274352252483368\n",
            "Loss: 0.0418114960193634\n",
            "Loss: 0.06780096143484116\n",
            "Loss: 0.4841834008693695\n",
            "Loss: 0.07846571505069733\n",
            "Loss: 0.21257077157497406\n",
            "Loss: 0.08983557671308517\n",
            "Loss: 0.31710726022720337\n",
            "Loss: 0.23449483513832092\n",
            "Loss: 0.24975243210792542\n",
            "Loss: 0.1751154065132141\n",
            "Loss: 0.14409835636615753\n",
            "Loss: 0.40212929248809814\n",
            "Loss: 0.11291076242923737\n",
            "Loss: 0.14047136902809143\n",
            "Loss: 1.0042721033096313\n",
            "Loss: 0.11116313934326172\n",
            "Loss: 0.1624920517206192\n",
            "Loss: 0.23114852607250214\n",
            "Loss: 0.09255102276802063\n",
            "Loss: 0.06087889522314072\n",
            "Loss: 0.6424059271812439\n",
            "Loss: 0.463332861661911\n",
            "Loss: 0.04125851392745972\n",
            "Loss: 0.15258149802684784\n",
            "Loss: 0.023602012544870377\n",
            "Loss: 0.11617805063724518\n",
            "Loss: 0.09969916939735413\n",
            "Loss: 0.4354313910007477\n",
            "Loss: 0.07519324868917465\n",
            "Loss: 0.6221869587898254\n",
            "Loss: 0.41630396246910095\n",
            "Loss: 0.26067495346069336\n",
            "Loss: 0.5854192972183228\n",
            "Loss: 0.21585015952587128\n",
            "Loss: 0.36085161566734314\n",
            "Loss: 0.3812195062637329\n",
            "Loss: 0.5710723400115967\n",
            "Loss: 0.17285798490047455\n",
            "Loss: 1.40318763256073\n",
            "Loss: 0.32779890298843384\n",
            "Loss: 0.3073404133319855\n",
            "Loss: 0.6085688471794128\n",
            "Loss: 0.13462834060192108\n",
            "Loss: 0.40306004881858826\n",
            "Loss: 0.23376689851284027\n",
            "Loss: 0.13041764497756958\n",
            "Loss: 0.29554522037506104\n",
            "Loss: 0.0778563916683197\n",
            "Loss: 0.21755331754684448\n",
            "Loss: 0.11551433801651001\n",
            "Loss: 0.5286799669265747\n",
            "Loss: 0.6236122846603394\n",
            "Loss: 0.6786206364631653\n",
            "Loss: 0.5684261322021484\n",
            "Loss: 0.3588552474975586\n",
            "Loss: 0.45323678851127625\n",
            "Loss: 0.40630194544792175\n",
            "Loss: 0.5555062294006348\n",
            "Loss: 0.6067651510238647\n",
            "Loss: 0.3065512478351593\n",
            "Loss: 0.4772515892982483\n",
            "Loss: 0.7173048853874207\n",
            "Loss: 0.2539195716381073\n",
            "Loss: 0.8149144053459167\n",
            "Loss: 0.24176767468452454\n",
            "Loss: 0.7215383648872375\n",
            "Loss: 0.18080297112464905\n",
            "Loss: 0.28755632042884827\n",
            "Loss: 0.14295987784862518\n",
            "Loss: 0.076847605407238\n",
            "Loss: 0.11609943211078644\n",
            "Loss: 0.10149654746055603\n",
            "Loss: 0.08885055780410767\n",
            "Loss: 0.16396464407444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating QA tests:   0%|          | 0/211 [00:00<?, ?it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:   9%|▉         | 19/211 [00:00<00:01, 182.14it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  19%|█▉        | 41/211 [00:00<00:00, 203.17it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  29%|██▉       | 62/211 [00:00<00:00, 190.88it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  39%|███▉      | 82/211 [00:00<00:00, 185.58it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  48%|████▊     | 102/211 [00:00<00:00, 186.90it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  66%|██████▋   | 140/211 [00:00<00:00, 164.47it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  75%|███████▍  | 158/211 [00:00<00:00, 167.64it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  84%|████████▍ | 177/211 [00:00<00:00, 173.85it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  94%|█████████▍| 198/211 [00:01<00:00, 182.39it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests: 100%|██████████| 211/211 [00:01<00:00, 177.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Metrics for epoch:0\n",
            "----------------------------\n",
            "Avg loss 0.17829052548988963\n",
            "Average Cell Precision: 0.4940521327014217\n",
            "Average Cell Recall: 0.46686255924170617\n",
            "Average Tuple Cardinality Accuracy: 0.5622654028436018\n",
            "Average Tuple Constraint Accuracy: 0.3462132701421801\n",
            "Average Tuple Order Accuracy: 0.1919186046511628\n",
            "----------------------------\n",
            "Epoch: 1\n",
            "Loss: 0.31104400753974915\n",
            "Loss: 0.1766645610332489\n",
            "Loss: 0.25600484013557434\n",
            "Loss: 0.3075356185436249\n",
            "Loss: 0.11786364018917084\n",
            "Loss: 0.07012173533439636\n",
            "Loss: 0.06811198592185974\n",
            "Loss: 0.1704719066619873\n",
            "Loss: 0.1965348869562149\n",
            "Loss: 0.23852695524692535\n",
            "Loss: 1.1572271585464478\n",
            "Loss: 0.9371020793914795\n",
            "Loss: 0.196760356426239\n",
            "Loss: 0.040910374373197556\n",
            "Loss: 0.08518311381340027\n",
            "Loss: 0.2805955410003662\n",
            "Loss: 0.28919267654418945\n",
            "Loss: 0.9577988386154175\n",
            "Loss: 0.3055041432380676\n",
            "Loss: 0.21446006000041962\n",
            "Loss: 0.14052298665046692\n",
            "Loss: 0.13969476521015167\n",
            "Loss: 0.41955265402793884\n",
            "Loss: 0.22854328155517578\n",
            "Loss: 0.2553326189517975\n",
            "Loss: 0.09813033789396286\n",
            "Loss: 0.18184810876846313\n",
            "Loss: 0.21465885639190674\n",
            "Loss: 0.12292708456516266\n",
            "Loss: 0.015108853578567505\n",
            "Loss: 0.19326746463775635\n",
            "Loss: 0.28335797786712646\n",
            "Loss: 0.17517895996570587\n",
            "Loss: 0.136649489402771\n",
            "Loss: 0.13930588960647583\n",
            "Loss: 0.092246875166893\n",
            "Loss: 0.12583065032958984\n",
            "Loss: 0.38718345761299133\n",
            "Loss: 0.016165716573596\n",
            "Loss: 0.5464107990264893\n",
            "Loss: 0.06564613431692123\n",
            "Loss: 0.22011233866214752\n",
            "Loss: 0.07369939237833023\n",
            "Loss: 0.2726114094257355\n",
            "Loss: 0.5485309362411499\n",
            "Loss: 0.10913268476724625\n",
            "Loss: 0.12796370685100555\n",
            "Loss: 0.03890867903828621\n",
            "Loss: 0.051041509956121445\n",
            "Loss: 0.1407807618379593\n",
            "Loss: 0.1453484147787094\n",
            "Loss: 0.2562635838985443\n",
            "Loss: 0.2778564393520355\n",
            "Loss: 0.018430914729833603\n",
            "Loss: 0.19635261595249176\n",
            "Loss: 0.055372633039951324\n",
            "Loss: 0.06419464200735092\n",
            "Loss: 0.1463032066822052\n",
            "Loss: 0.0624554380774498\n",
            "Loss: 0.03060922771692276\n",
            "Loss: 0.0032072875183075666\n",
            "Loss: 0.5817909836769104\n",
            "Loss: 0.06536746770143509\n",
            "Loss: 0.09742765873670578\n",
            "Loss: 0.0031144036911427975\n",
            "Loss: 0.03384365141391754\n",
            "Loss: 0.08706828951835632\n",
            "Loss: 0.05270227789878845\n",
            "Loss: 0.012866351753473282\n",
            "Loss: 0.2576215863227844\n",
            "Loss: 0.15583749115467072\n",
            "Loss: 0.12700502574443817\n",
            "Loss: 0.027076616883277893\n",
            "Loss: 0.017893575131893158\n",
            "Loss: 0.011606987565755844\n",
            "Loss: 0.14946414530277252\n",
            "Loss: 0.7286189794540405\n",
            "Loss: 0.24410519003868103\n",
            "Loss: 0.15829232335090637\n",
            "Loss: 0.17202959954738617\n",
            "Loss: 0.23372448980808258\n",
            "Loss: 0.2112058848142624\n",
            "Loss: 0.12757492065429688\n",
            "Loss: 1.108209490776062\n",
            "Loss: 0.15835846960544586\n",
            "Loss: 0.07734102010726929\n",
            "Loss: 0.041387349367141724\n",
            "Loss: 0.02715633437037468\n",
            "Loss: 0.03238943591713905\n",
            "Loss: 0.2471042424440384\n",
            "Loss: 0.1686403751373291\n",
            "Loss: 0.04839424043893814\n",
            "Loss: 0.043088700622320175\n",
            "Loss: 0.21419353783130646\n",
            "Loss: 0.09280449151992798\n",
            "Loss: 0.28599509596824646\n",
            "Loss: 0.10150390863418579\n",
            "Loss: 0.05163633078336716\n",
            "Loss: 0.13719336688518524\n",
            "Loss: 0.033164843916893005\n",
            "Loss: 0.05964140594005585\n",
            "Loss: 0.012875872664153576\n",
            "Loss: 0.08343150466680527\n",
            "Loss: 0.32210028171539307\n",
            "Loss: 0.11374027281999588\n",
            "Loss: 0.01115606352686882\n",
            "Loss: 0.12377486377954483\n",
            "Loss: 0.15769407153129578\n",
            "Loss: 0.10115594416856766\n",
            "Loss: 0.14060650765895844\n",
            "Loss: 0.5550594925880432\n",
            "Loss: 0.06361174583435059\n",
            "Loss: 0.06357244402170181\n",
            "Loss: 0.036732446402311325\n",
            "Loss: 0.03532857447862625\n",
            "Loss: 0.08826334774494171\n",
            "Loss: 0.01649579592049122\n",
            "Loss: 0.049211736768484116\n",
            "Loss: 0.24404336512088776\n",
            "Loss: 0.16510987281799316\n",
            "Loss: 0.22043302655220032\n",
            "Loss: 0.09889735281467438\n",
            "Loss: 0.18824151158332825\n",
            "Loss: 0.08086279779672623\n",
            "Loss: 0.08961249142885208\n",
            "Loss: 0.03930148109793663\n",
            "Loss: 0.11670314520597458\n",
            "Loss: 0.08917811512947083\n",
            "Loss: 0.10814899206161499\n",
            "Loss: 0.02928328514099121\n",
            "Loss: 0.060557082295417786\n",
            "Loss: 0.08973575383424759\n",
            "Loss: 0.08273394405841827\n",
            "Loss: 0.21394482254981995\n",
            "Loss: 0.46915632486343384\n",
            "Loss: 1.1208748817443848\n",
            "Loss: 0.04725479707121849\n",
            "Loss: 0.08904881775379181\n",
            "Loss: 0.263154536485672\n",
            "Loss: 0.04168252646923065\n",
            "Loss: 0.11317721009254456\n",
            "Loss: 0.1872357279062271\n",
            "Loss: 0.06576915085315704\n",
            "Loss: 0.17524294555187225\n",
            "Loss: 0.13233284652233124\n",
            "Loss: 0.12148690223693848\n",
            "Loss: 0.022377466782927513\n",
            "Loss: 0.36560317873954773\n",
            "Loss: 0.3169151544570923\n",
            "Loss: 0.16149522364139557\n",
            "Loss: 0.031837765127420425\n",
            "Loss: 0.2989652454853058\n",
            "Loss: 0.087567038834095\n",
            "Loss: 0.1459994912147522\n",
            "Loss: 0.4428872764110565\n",
            "Loss: 0.05290362983942032\n",
            "Loss: 0.18802142143249512\n",
            "Loss: 0.11484846472740173\n",
            "Loss: 0.11440733075141907\n",
            "Loss: 0.08715637028217316\n",
            "Loss: 0.021844808012247086\n",
            "Loss: 0.05425921827554703\n",
            "Loss: 0.08082126826047897\n",
            "Loss: 0.0947369635105133\n",
            "Loss: 0.18937911093235016\n",
            "Loss: 0.26346084475517273\n",
            "Loss: 0.1397102028131485\n",
            "Loss: 0.026737598702311516\n",
            "Loss: 0.09589599072933197\n",
            "Loss: 0.020749850198626518\n",
            "Loss: 0.06040969863533974\n",
            "Loss: 0.5877576470375061\n",
            "Loss: 0.10437304526567459\n",
            "Loss: 0.1993853747844696\n",
            "Loss: 0.4349007308483124\n",
            "Loss: 0.409353107213974\n",
            "Loss: 0.023988822475075722\n",
            "Loss: 0.1297522634267807\n",
            "Loss: 0.0897829458117485\n",
            "Loss: 0.0004918935592286289\n",
            "Loss: 0.045005664229393005\n",
            "Loss: 0.07046256214380264\n",
            "Loss: 0.055691562592983246\n",
            "Loss: 0.002277576830238104\n",
            "Loss: 0.09314896166324615\n",
            "Loss: 0.006973248906433582\n",
            "Loss: 0.10734663903713226\n",
            "Loss: 0.25459423661231995\n",
            "Loss: 0.004901972133666277\n",
            "Loss: 0.0591173954308033\n",
            "Loss: 0.01180795207619667\n",
            "Loss: 0.011873424984514713\n",
            "Loss: 0.10112078487873077\n",
            "Loss: 0.10235559940338135\n",
            "Loss: 0.26874783635139465\n",
            "Loss: 0.09891612827777863\n",
            "Loss: 0.19542819261550903\n",
            "Loss: 0.07412280887365341\n",
            "Loss: 0.0022126222029328346\n",
            "Loss: 0.06880295276641846\n",
            "Loss: 0.026952076703310013\n",
            "Loss: 0.07477904856204987\n",
            "Loss: 0.06597035378217697\n",
            "Loss: 0.06673851609230042\n",
            "Loss: 0.04400946944952011\n",
            "Loss: 0.033133938908576965\n",
            "Loss: 0.014441643841564655\n",
            "Loss: 0.0913451537489891\n",
            "Loss: 0.06376203894615173\n",
            "Loss: 0.06042862311005592\n",
            "Loss: 0.03467628359794617\n",
            "Loss: 0.15369786322116852\n",
            "Loss: 0.37287968397140503\n",
            "Loss: 0.1707209199666977\n",
            "Loss: 0.36970657110214233\n",
            "Loss: 0.34953808784484863\n",
            "Loss: 0.24774040281772614\n",
            "Loss: 0.2232722043991089\n",
            "Loss: 0.2519274055957794\n",
            "Loss: 0.2704804539680481\n",
            "Loss: 0.09261266887187958\n",
            "Loss: 0.40992411971092224\n",
            "Loss: 0.21703045070171356\n",
            "Loss: 0.20670460164546967\n",
            "Loss: 0.19379492104053497\n",
            "Loss: 0.11190702766180038\n",
            "Loss: 0.422207236289978\n",
            "Loss: 0.21156086027622223\n",
            "Loss: 0.07589834928512573\n",
            "Loss: 0.1374448835849762\n",
            "Loss: 0.11289896070957184\n",
            "Loss: 0.09456206113100052\n",
            "Loss: 0.09912528097629547\n",
            "Loss: 0.04369184747338295\n",
            "Loss: 0.11474806815385818\n",
            "Loss: 0.06521870940923691\n",
            "Loss: 0.020255308598279953\n",
            "Loss: 0.10060837119817734\n",
            "Loss: 0.037557173520326614\n",
            "Loss: 0.01933492347598076\n",
            "Loss: 0.031745970249176025\n",
            "Loss: 0.09908229857683182\n",
            "Loss: 0.07678613066673279\n",
            "Loss: 0.044821836054325104\n",
            "Loss: 0.09629745781421661\n",
            "Loss: 0.054031796753406525\n",
            "Loss: 0.04059895500540733\n",
            "Loss: 0.03031178005039692\n",
            "Loss: 0.4064360558986664\n",
            "Loss: 0.6832050085067749\n",
            "Loss: 0.20699603855609894\n",
            "Loss: 0.1316303014755249\n",
            "Loss: 0.13807415962219238\n",
            "Loss: 0.021057093515992165\n",
            "Loss: 0.045276280492544174\n",
            "Loss: 0.10467729717493057\n",
            "Loss: 0.007475507445633411\n",
            "Loss: 0.014358121901750565\n",
            "Loss: 0.03104909136891365\n",
            "Loss: 0.14872269332408905\n",
            "Loss: 0.1561795026063919\n",
            "Loss: 0.07115709781646729\n",
            "Loss: 0.1781950742006302\n",
            "Loss: 0.029258400201797485\n",
            "Loss: 0.07034087181091309\n",
            "Loss: 0.2986351251602173\n",
            "Loss: 0.08442901074886322\n",
            "Loss: 0.7222403287887573\n",
            "Loss: 0.17084932327270508\n",
            "Loss: 0.11516600102186203\n",
            "Loss: 0.27792659401893616\n",
            "Loss: 0.001419478445313871\n",
            "Loss: 0.0028115706518292427\n",
            "Loss: 0.002796236891299486\n",
            "Loss: 0.0053600468672811985\n",
            "Loss: 0.016362907364964485\n",
            "Loss: 0.004297565668821335\n",
            "Loss: 0.01908774860203266\n",
            "Loss: 0.05317199230194092\n",
            "Loss: 0.00396838178858161\n",
            "Loss: 0.033033184707164764\n",
            "Loss: 0.001593948109075427\n",
            "Loss: 0.005637635011225939\n",
            "Loss: 0.0017944034188985825\n",
            "Loss: 0.001736385514959693\n",
            "Loss: 0.0012042727321386337\n",
            "Loss: 0.001989972312003374\n",
            "Loss: 0.0037336302921175957\n",
            "Loss: 0.0020401114597916603\n",
            "Loss: 0.0021616641897708178\n",
            "Loss: 0.004640036262571812\n",
            "Loss: 0.052673835307359695\n",
            "Loss: 0.035745128989219666\n",
            "Loss: 0.0042496114037930965\n",
            "Loss: 0.016593163833022118\n",
            "Loss: 0.03537685424089432\n",
            "Loss: 0.042737867683172226\n",
            "Loss: 0.021118994802236557\n",
            "Loss: 0.3365073800086975\n",
            "Loss: 0.023002685979008675\n",
            "Loss: 0.023834649473428726\n",
            "Loss: 0.03657732158899307\n",
            "Loss: 0.00846974179148674\n",
            "Loss: 0.7050356268882751\n",
            "Loss: 0.006361417472362518\n",
            "Loss: 0.030706074088811874\n",
            "Loss: 0.0050800396129488945\n",
            "Loss: 0.9112226366996765\n",
            "Loss: 0.010149148292839527\n",
            "Loss: 0.04122006893157959\n",
            "Loss: 0.07678548991680145\n",
            "Loss: 0.18802911043167114\n",
            "Loss: 0.005686360411345959\n",
            "Loss: 0.08220360428094864\n",
            "Loss: 0.060384176671504974\n",
            "Loss: 0.01846294105052948\n",
            "Loss: 0.004044911824166775\n",
            "Loss: 0.013896667398512363\n",
            "Loss: 0.0014497351367026567\n",
            "Loss: 0.0027689349371939898\n",
            "Loss: 0.0025445979554206133\n",
            "Loss: 0.06765061616897583\n",
            "Loss: 0.07194545120000839\n",
            "Loss: 0.00041370352846570313\n",
            "Loss: 0.08497822284698486\n",
            "Loss: 0.0554080605506897\n",
            "Loss: 0.33912694454193115\n",
            "Loss: 0.012543011456727982\n",
            "Loss: 0.03039306215941906\n",
            "Loss: 0.0010887314565479755\n",
            "Loss: 0.09552343934774399\n",
            "Loss: 0.10486731678247452\n",
            "Loss: 0.03162690997123718\n",
            "Loss: 0.007623155601322651\n",
            "Loss: 0.42754778265953064\n",
            "Loss: 0.05133010447025299\n",
            "Loss: 0.02297361195087433\n",
            "Loss: 0.1717970222234726\n",
            "Loss: 0.02847989648580551\n",
            "Loss: 0.04058634117245674\n",
            "Loss: 0.020868893712759018\n",
            "Loss: 0.06632160395383835\n",
            "Loss: 0.04752841219305992\n",
            "Loss: 0.16557474434375763\n",
            "Loss: 0.04625275731086731\n",
            "Loss: 0.029169049113988876\n",
            "Loss: 0.025204390287399292\n",
            "Loss: 0.001848445856012404\n",
            "Loss: 0.05014000087976456\n",
            "Loss: 0.17830699682235718\n",
            "Loss: 0.5302259922027588\n",
            "Loss: 0.6241476535797119\n",
            "Loss: 0.28105637431144714\n",
            "Loss: 0.15813659131526947\n",
            "Loss: 0.22825996577739716\n",
            "Loss: 0.3180786669254303\n",
            "Loss: 0.21381914615631104\n",
            "Loss: 0.297855943441391\n",
            "Loss: 0.15787766873836517\n",
            "Loss: 0.21470056474208832\n",
            "Loss: 0.154569610953331\n",
            "Loss: 0.29316121339797974\n",
            "Loss: 0.06394143402576447\n",
            "Loss: 0.22526010870933533\n",
            "Loss: 0.12273599952459335\n",
            "Loss: 0.2880344092845917\n",
            "Loss: 0.11479166895151138\n",
            "Loss: 0.07942065596580505\n",
            "Loss: 0.09267160296440125\n",
            "Loss: 0.15977102518081665\n",
            "Loss: 0.04864715784788132\n",
            "Loss: 0.01630358397960663\n",
            "Loss: 0.0894995778799057\n",
            "Loss: 0.3465912342071533\n",
            "Loss: 0.016103314235806465\n",
            "Loss: 0.17478743195533752\n",
            "Loss: 0.06019144132733345\n",
            "Loss: 0.0942123532295227\n",
            "Loss: 0.3142680823802948\n",
            "Loss: 0.2110477238893509\n",
            "Loss: 0.06359796971082687\n",
            "Loss: 0.0902429074048996\n",
            "Loss: 0.07092581689357758\n",
            "Loss: 0.06522203236818314\n",
            "Loss: 0.39931541681289673\n",
            "Loss: 0.22503146529197693\n",
            "Loss: 0.04761769622564316\n",
            "Loss: 0.5561195611953735\n",
            "Loss: 0.43739521503448486\n",
            "Loss: 0.08300710469484329\n",
            "Loss: 0.020382089540362358\n",
            "Loss: 0.16028550267219543\n",
            "Loss: 0.21133442223072052\n",
            "Loss: 0.03502481430768967\n",
            "Loss: 0.3251273036003113\n",
            "Loss: 0.041915468871593475\n",
            "Loss: 0.026096012443304062\n",
            "Loss: 0.1964898407459259\n",
            "Loss: 0.11501528322696686\n",
            "Loss: 0.07067687064409256\n",
            "Loss: 0.30218321084976196\n",
            "Loss: 0.33073726296424866\n",
            "Loss: 0.19016630947589874\n",
            "Loss: 0.43031176924705505\n",
            "Loss: 0.11954370141029358\n",
            "Loss: 0.23488828539848328\n",
            "Loss: 0.34491029381752014\n",
            "Loss: 0.18328754603862762\n",
            "Loss: 0.11297684907913208\n",
            "Loss: 0.9425703883171082\n",
            "Loss: 0.10718659311532974\n",
            "Loss: 0.3227660655975342\n",
            "Loss: 0.5515406131744385\n",
            "Loss: 0.10408823937177658\n",
            "Loss: 0.4191479980945587\n",
            "Loss: 0.18431463837623596\n",
            "Loss: 0.05182000994682312\n",
            "Loss: 0.29743528366088867\n",
            "Loss: 0.02924170158803463\n",
            "Loss: 0.15657837688922882\n",
            "Loss: 0.02835317701101303\n",
            "Loss: 0.3390267491340637\n",
            "Loss: 0.4269287586212158\n",
            "Loss: 0.4027092754840851\n",
            "Loss: 0.38819822669029236\n",
            "Loss: 0.181902676820755\n",
            "Loss: 0.26210319995880127\n",
            "Loss: 0.2196502834558487\n",
            "Loss: 0.3640628457069397\n",
            "Loss: 0.3179156184196472\n",
            "Loss: 0.12756989896297455\n",
            "Loss: 0.3059656322002411\n",
            "Loss: 0.599245011806488\n",
            "Loss: 0.2030005156993866\n",
            "Loss: 0.38548582792282104\n",
            "Loss: 0.2070169299840927\n",
            "Loss: 0.13807249069213867\n",
            "Loss: 0.1670699417591095\n",
            "Loss: 0.2381446808576584\n",
            "Loss: 0.3566943109035492\n",
            "Loss: 0.028620358556509018\n",
            "Loss: 0.12102732807397842\n",
            "Loss: 0.09326933324337006\n",
            "Loss: 0.13250410556793213\n",
            "Loss: 0.08188241720199585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating QA tests:  32%|███▏      | 68/211 [00:00<00:00, 166.05it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  49%|████▉     | 103/211 [00:00<00:00, 166.73it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  89%|████████▉ | 188/211 [00:01<00:00, 162.35it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests: 100%|██████████| 211/211 [00:01<00:00, 162.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Metrics for epoch:1\n",
            "----------------------------\n",
            "Avg loss 0.15699500036314706\n",
            "Average Cell Precision: 0.6290521327014218\n",
            "Average Cell Recall: 0.59860663507109\n",
            "Average Tuple Cardinality Accuracy: 0.7439620853080569\n",
            "Average Tuple Constraint Accuracy: 0.4673554502369668\n",
            "Average Tuple Order Accuracy: 0.37509090909090914\n",
            "----------------------------\n",
            "Epoch: 2\n",
            "Loss: 0.2782859206199646\n",
            "Loss: 0.4253111779689789\n",
            "Loss: 0.06521284580230713\n",
            "Loss: 0.04179390147328377\n",
            "Loss: 0.0722353458404541\n",
            "Loss: 0.02642040327191353\n",
            "Loss: 0.02937132865190506\n",
            "Loss: 0.06142410263419151\n",
            "Loss: 0.17880885303020477\n",
            "Loss: 0.20535621047019958\n",
            "Loss: 0.23624497652053833\n",
            "Loss: 1.8868064880371094\n",
            "Loss: 1.289427638053894\n",
            "Loss: 0.05006544291973114\n",
            "Loss: 0.03317505866289139\n",
            "Loss: 0.09699366986751556\n",
            "Loss: 0.7115162014961243\n",
            "Loss: 0.4231478273868561\n",
            "Loss: 1.0435608625411987\n",
            "Loss: 0.09071899950504303\n",
            "Loss: 0.04813266173005104\n",
            "Loss: 0.15194781124591827\n",
            "Loss: 0.3312718868255615\n",
            "Loss: 0.11781250685453415\n",
            "Loss: 0.2047952562570572\n",
            "Loss: 0.015403980389237404\n",
            "Loss: 0.05603441968560219\n",
            "Loss: 0.15357854962348938\n",
            "Loss: 0.108434297144413\n",
            "Loss: 0.22965218126773834\n",
            "Loss: 0.14226944744586945\n",
            "Loss: 0.21216438710689545\n",
            "Loss: 0.06983017176389694\n",
            "Loss: 0.07405902445316315\n",
            "Loss: 0.0858713835477829\n",
            "Loss: 0.14326918125152588\n",
            "Loss: 0.08116795122623444\n",
            "Loss: 0.29568201303482056\n",
            "Loss: 0.03522002696990967\n",
            "Loss: 0.48640376329421997\n",
            "Loss: 0.34741899371147156\n",
            "Loss: 0.20186732709407806\n",
            "Loss: 0.08748222887516022\n",
            "Loss: 0.17846882343292236\n",
            "Loss: 0.2200205773115158\n",
            "Loss: 0.11635923385620117\n",
            "Loss: 0.08262930810451508\n",
            "Loss: 0.01764671504497528\n",
            "Loss: 0.059326447546482086\n",
            "Loss: 0.06491222232580185\n",
            "Loss: 0.12540192902088165\n",
            "Loss: 0.19090159237384796\n",
            "Loss: 0.48490795493125916\n",
            "Loss: 0.021695483475923538\n",
            "Loss: 0.14214074611663818\n",
            "Loss: 0.05760755389928818\n",
            "Loss: 0.05761001631617546\n",
            "Loss: 0.11969846487045288\n",
            "Loss: 0.1865236759185791\n",
            "Loss: 0.12114125490188599\n",
            "Loss: 0.008747078478336334\n",
            "Loss: 0.05577927827835083\n",
            "Loss: 0.17027424275875092\n",
            "Loss: 0.1665150225162506\n",
            "Loss: 0.005362897180020809\n",
            "Loss: 0.021743204444646835\n",
            "Loss: 0.03686476871371269\n",
            "Loss: 0.0200667604804039\n",
            "Loss: 0.009422441944479942\n",
            "Loss: 0.2331039011478424\n",
            "Loss: 0.03792404383420944\n",
            "Loss: 0.1496802270412445\n",
            "Loss: 0.6510423421859741\n",
            "Loss: 0.007341509219259024\n",
            "Loss: 0.0027765713166445494\n",
            "Loss: 0.12897761166095734\n",
            "Loss: 0.16990520060062408\n",
            "Loss: 0.06044783070683479\n",
            "Loss: 0.07623643428087234\n",
            "Loss: 0.048975057899951935\n",
            "Loss: 0.13990291953086853\n",
            "Loss: 0.982216477394104\n",
            "Loss: 0.021143320947885513\n",
            "Loss: 0.5510178804397583\n",
            "Loss: 0.12536872923374176\n",
            "Loss: 0.17965292930603027\n",
            "Loss: 0.047777436673641205\n",
            "Loss: 0.04209320247173309\n",
            "Loss: 0.013393486849963665\n",
            "Loss: 0.1384713500738144\n",
            "Loss: 0.21939222514629364\n",
            "Loss: 0.01060133520513773\n",
            "Loss: 0.03881686180830002\n",
            "Loss: 0.11014171689748764\n",
            "Loss: 0.10254215449094772\n",
            "Loss: 0.25880327820777893\n",
            "Loss: 0.205479696393013\n",
            "Loss: 0.03855709731578827\n",
            "Loss: 0.06826981157064438\n",
            "Loss: 0.12049024552106857\n",
            "Loss: 0.024994783103466034\n",
            "Loss: 0.011297265067696571\n",
            "Loss: 0.021717332303524017\n",
            "Loss: 0.2906128168106079\n",
            "Loss: 0.003182676387950778\n",
            "Loss: 0.007839255966246128\n",
            "Loss: 0.026635847985744476\n",
            "Loss: 0.07395192980766296\n",
            "Loss: 0.01664663851261139\n",
            "Loss: 0.1753763109445572\n",
            "Loss: 0.4884136915206909\n",
            "Loss: 0.05204145610332489\n",
            "Loss: 0.06097402051091194\n",
            "Loss: 0.042799726128578186\n",
            "Loss: 0.04045158624649048\n",
            "Loss: 0.05153084173798561\n",
            "Loss: 0.023189442232251167\n",
            "Loss: 0.07049030810594559\n",
            "Loss: 0.19908607006072998\n",
            "Loss: 0.14399729669094086\n",
            "Loss: 0.29318735003471375\n",
            "Loss: 0.10186020284891129\n",
            "Loss: 0.08965689688920975\n",
            "Loss: 0.2120666652917862\n",
            "Loss: 0.20901674032211304\n",
            "Loss: 0.03497758507728577\n",
            "Loss: 0.13303452730178833\n",
            "Loss: 0.03582753241062164\n",
            "Loss: 0.10202580690383911\n",
            "Loss: 0.0363372266292572\n",
            "Loss: 0.03678259998559952\n",
            "Loss: 0.09193138778209686\n",
            "Loss: 0.043536555022001266\n",
            "Loss: 0.17041167616844177\n",
            "Loss: 0.2053423970937729\n",
            "Loss: 2.0362937450408936\n",
            "Loss: 0.04330846667289734\n",
            "Loss: 0.07215527445077896\n",
            "Loss: 0.13971170783042908\n",
            "Loss: 0.024256659671664238\n",
            "Loss: 0.12524612247943878\n",
            "Loss: 0.15150976181030273\n",
            "Loss: 0.011768222786486149\n",
            "Loss: 0.09712295979261398\n",
            "Loss: 0.13609960675239563\n",
            "Loss: 0.08909585326910019\n",
            "Loss: 0.012557346373796463\n",
            "Loss: 0.10667786002159119\n",
            "Loss: 0.1440068781375885\n",
            "Loss: 0.3577338457107544\n",
            "Loss: 0.052307672798633575\n",
            "Loss: 0.2807874083518982\n",
            "Loss: 0.0795338898897171\n",
            "Loss: 0.22820310294628143\n",
            "Loss: 0.4058428108692169\n",
            "Loss: 0.152253195643425\n",
            "Loss: 0.15545998513698578\n",
            "Loss: 0.10131298005580902\n",
            "Loss: 0.11308600753545761\n",
            "Loss: 0.1383356750011444\n",
            "Loss: 0.05069783702492714\n",
            "Loss: 0.11931347846984863\n",
            "Loss: 0.07995881140232086\n",
            "Loss: 0.09205454587936401\n",
            "Loss: 0.29792141914367676\n",
            "Loss: 0.12168148159980774\n",
            "Loss: 0.2649940550327301\n",
            "Loss: 0.013888800516724586\n",
            "Loss: 0.19781158864498138\n",
            "Loss: 0.047204338014125824\n",
            "Loss: 0.043069906532764435\n",
            "Loss: 0.05227936431765556\n",
            "Loss: 1.1992316246032715\n",
            "Loss: 0.08723340928554535\n",
            "Loss: 0.26739659905433655\n",
            "Loss: 0.2601921856403351\n",
            "Loss: 0.019064633175730705\n",
            "Loss: 0.08085782080888748\n",
            "Loss: 0.03705974668264389\n",
            "Loss: 0.0037188923452049494\n",
            "Loss: 0.07566894590854645\n",
            "Loss: 0.09395346790552139\n",
            "Loss: 0.08324558287858963\n",
            "Loss: 0.007530010771006346\n",
            "Loss: 0.1342080682516098\n",
            "Loss: 0.054245222359895706\n",
            "Loss: 0.12383653223514557\n",
            "Loss: 0.046436138451099396\n",
            "Loss: 0.020229903981089592\n",
            "Loss: 0.009196008555591106\n",
            "Loss: 0.009752919897437096\n",
            "Loss: 0.07310108840465546\n",
            "Loss: 0.08671414107084274\n",
            "Loss: 0.28222528100013733\n",
            "Loss: 0.16063179075717926\n",
            "Loss: 0.1050972193479538\n",
            "Loss: 0.1445392668247223\n",
            "Loss: 0.09782986342906952\n",
            "Loss: 0.007278977427631617\n",
            "Loss: 0.15350568294525146\n",
            "Loss: 0.052705466747283936\n",
            "Loss: 0.054506704211235046\n",
            "Loss: 0.04645559936761856\n",
            "Loss: 0.011943714693188667\n",
            "Loss: 0.026636654511094093\n",
            "Loss: 0.021447712555527687\n",
            "Loss: 0.0024815956130623817\n",
            "Loss: 0.008055556565523148\n",
            "Loss: 0.04011115804314613\n",
            "Loss: 0.058607302606105804\n",
            "Loss: 0.002971505746245384\n",
            "Loss: 0.04359482601284981\n",
            "Loss: 0.26167672872543335\n",
            "Loss: 0.1288839727640152\n",
            "Loss: 0.15234768390655518\n",
            "Loss: 0.20935115218162537\n",
            "Loss: 0.29223889112472534\n",
            "Loss: 0.12863312661647797\n",
            "Loss: 0.06304977089166641\n",
            "Loss: 0.14176826179027557\n",
            "Loss: 0.09612378478050232\n",
            "Loss: 0.13358967006206512\n",
            "Loss: 0.2000826746225357\n",
            "Loss: 0.2078445851802826\n",
            "Loss: 0.06559997797012329\n",
            "Loss: 0.090137779712677\n",
            "Loss: 0.37732863426208496\n",
            "Loss: 0.1819785237312317\n",
            "Loss: 0.03130396455526352\n",
            "Loss: 0.14781929552555084\n",
            "Loss: 0.10568901151418686\n",
            "Loss: 0.04013577848672867\n",
            "Loss: 0.2208368331193924\n",
            "Loss: 0.024479296058416367\n",
            "Loss: 0.06637465208768845\n",
            "Loss: 0.028931284323334694\n",
            "Loss: 0.02653231844305992\n",
            "Loss: 0.02692066878080368\n",
            "Loss: 0.007349194027483463\n",
            "Loss: 0.012598715722560883\n",
            "Loss: 0.03181558847427368\n",
            "Loss: 0.029421944171190262\n",
            "Loss: 0.1010720431804657\n",
            "Loss: 0.009443660266697407\n",
            "Loss: 0.09064401686191559\n",
            "Loss: 0.02740493044257164\n",
            "Loss: 0.018118850886821747\n",
            "Loss: 0.08017799258232117\n",
            "Loss: 0.12532702088356018\n",
            "Loss: 0.14077763259410858\n",
            "Loss: 0.11796923726797104\n",
            "Loss: 0.07549451291561127\n",
            "Loss: 0.1186446025967598\n",
            "Loss: 0.003081942442804575\n",
            "Loss: 0.1402539759874344\n",
            "Loss: 0.017831454053521156\n",
            "Loss: 0.001799118472263217\n",
            "Loss: 0.0007211368065327406\n",
            "Loss: 0.08593416959047318\n",
            "Loss: 0.059472717344760895\n",
            "Loss: 0.5948356986045837\n",
            "Loss: 0.21360717713832855\n",
            "Loss: 0.1602010577917099\n",
            "Loss: 0.01216130144894123\n",
            "Loss: 0.0937257707118988\n",
            "Loss: 0.04906182736158371\n",
            "Loss: 0.11509787291288376\n",
            "Loss: 0.13899558782577515\n",
            "Loss: 0.1809239536523819\n",
            "Loss: 0.06627213954925537\n",
            "Loss: 0.23293480277061462\n",
            "Loss: 0.2571702301502228\n",
            "Loss: 0.0946776419878006\n",
            "Loss: 0.011122263967990875\n",
            "Loss: 0.02071032114326954\n",
            "Loss: 0.01907316967844963\n",
            "Loss: 0.009482046589255333\n",
            "Loss: 0.1613943874835968\n",
            "Loss: 0.03279787302017212\n",
            "Loss: 0.0020919269882142544\n",
            "Loss: 0.00880742259323597\n",
            "Loss: 0.004478419665247202\n",
            "Loss: 0.014177479781210423\n",
            "Loss: 0.01339198648929596\n",
            "Loss: 0.0016661908011883497\n",
            "Loss: 0.0008446660358458757\n",
            "Loss: 0.005760448984801769\n",
            "Loss: 0.0016987263225018978\n",
            "Loss: 0.11011955142021179\n",
            "Loss: 0.0022777493577450514\n",
            "Loss: 0.0005014679045416415\n",
            "Loss: 0.012757420539855957\n",
            "Loss: 0.030090801417827606\n",
            "Loss: 0.0015421495772898197\n",
            "Loss: 0.045367348939180374\n",
            "Loss: 0.0012040676083415747\n",
            "Loss: 0.07403761893510818\n",
            "Loss: 0.011428479105234146\n",
            "Loss: 0.002987355925142765\n",
            "Loss: 0.015817129984498024\n",
            "Loss: 0.005771079566329718\n",
            "Loss: 0.02910626493394375\n",
            "Loss: 0.004792111460119486\n",
            "Loss: 0.0017274697311222553\n",
            "Loss: 0.0019176509231328964\n",
            "Loss: 0.3990260064601898\n",
            "Loss: 0.0025435949210077524\n",
            "Loss: 0.13241685926914215\n",
            "Loss: 0.001394528429955244\n",
            "Loss: 0.0047084069810807705\n",
            "Loss: 0.03728828579187393\n",
            "Loss: 0.0038577939849346876\n",
            "Loss: 0.006390609312802553\n",
            "Loss: 0.011381912045180798\n",
            "Loss: 0.49117353558540344\n",
            "Loss: 0.001696489518508315\n",
            "Loss: 0.0027622925117611885\n",
            "Loss: 0.008850211277604103\n",
            "Loss: 0.004627671558409929\n",
            "Loss: 0.058344848453998566\n",
            "Loss: 0.009126634337008\n",
            "Loss: 0.010799085721373558\n",
            "Loss: 0.010980185121297836\n",
            "Loss: 0.0028230752795934677\n",
            "Loss: 0.015611173585057259\n",
            "Loss: 0.21281671524047852\n",
            "Loss: 0.05039091408252716\n",
            "Loss: 0.01117021031677723\n",
            "Loss: 0.016091380268335342\n",
            "Loss: 0.14351285994052887\n",
            "Loss: 0.17801117897033691\n",
            "Loss: 0.020618954673409462\n",
            "Loss: 0.010681023821234703\n",
            "Loss: 0.011229430325329304\n",
            "Loss: 0.01559787429869175\n",
            "Loss: 0.03310959413647652\n",
            "Loss: 0.0006758248200640082\n",
            "Loss: 0.06369650363922119\n",
            "Loss: 0.001066952827386558\n",
            "Loss: 0.07742889970541\n",
            "Loss: 0.00045325211249291897\n",
            "Loss: 0.14178960025310516\n",
            "Loss: 0.0036448738537728786\n",
            "Loss: 0.0019906391389667988\n",
            "Loss: 0.004598612897098064\n",
            "Loss: 0.01451486349105835\n",
            "Loss: 0.04636954143643379\n",
            "Loss: 0.0022436317522078753\n",
            "Loss: 0.039398495107889175\n",
            "Loss: 0.028406266123056412\n",
            "Loss: 0.07924205809831619\n",
            "Loss: 0.2282373607158661\n",
            "Loss: 0.055780552327632904\n",
            "Loss: 0.052459344267845154\n",
            "Loss: 0.20273907482624054\n",
            "Loss: 0.1673745959997177\n",
            "Loss: 0.12914921343326569\n",
            "Loss: 0.40758147835731506\n",
            "Loss: 0.06663614511489868\n",
            "Loss: 0.19410210847854614\n",
            "Loss: 0.22957970201969147\n",
            "Loss: 0.1330762654542923\n",
            "Loss: 0.04735340178012848\n",
            "Loss: 0.049693766981363297\n",
            "Loss: 0.039294254034757614\n",
            "Loss: 0.13842487335205078\n",
            "Loss: 0.08264616131782532\n",
            "Loss: 0.02215322107076645\n",
            "Loss: 0.05729156732559204\n",
            "Loss: 0.040492355823516846\n",
            "Loss: 0.18256919085979462\n",
            "Loss: 0.046925559639930725\n",
            "Loss: 0.05321762338280678\n",
            "Loss: 0.21317940950393677\n",
            "Loss: 0.012747250497341156\n",
            "Loss: 0.11055656522512436\n",
            "Loss: 0.011113181710243225\n",
            "Loss: 0.047742489725351334\n",
            "Loss: 0.2119094878435135\n",
            "Loss: 0.09069051593542099\n",
            "Loss: 0.09414324164390564\n",
            "Loss: 0.05875891447067261\n",
            "Loss: 0.17053353786468506\n",
            "Loss: 0.02555275522172451\n",
            "Loss: 0.035466086119413376\n",
            "Loss: 0.07012426108121872\n",
            "Loss: 0.00813246425241232\n",
            "Loss: 0.13102494180202484\n",
            "Loss: 0.12022606283426285\n",
            "Loss: 0.39928850531578064\n",
            "Loss: 0.005804094485938549\n",
            "Loss: 0.07468518614768982\n",
            "Loss: 0.16494739055633545\n",
            "Loss: 0.03099713660776615\n",
            "Loss: 0.059392426162958145\n",
            "Loss: 0.020688030868768692\n",
            "Loss: 0.0050894576124846935\n",
            "Loss: 0.2873817980289459\n",
            "Loss: 0.02563396841287613\n",
            "Loss: 0.01514472346752882\n",
            "Loss: 0.15860477089881897\n",
            "Loss: 0.21407034993171692\n",
            "Loss: 0.08190159499645233\n",
            "Loss: 0.2862606644630432\n",
            "Loss: 0.14489604532718658\n",
            "Loss: 0.1731969565153122\n",
            "Loss: 0.16032402217388153\n",
            "Loss: 0.08350180834531784\n",
            "Loss: 0.03440433368086815\n",
            "Loss: 0.47123482823371887\n",
            "Loss: 0.09000451117753983\n",
            "Loss: 0.28995126485824585\n",
            "Loss: 0.08592179417610168\n",
            "Loss: 0.14807723462581635\n",
            "Loss: 0.4871067404747009\n",
            "Loss: 0.33933553099632263\n",
            "Loss: 0.15670739114284515\n",
            "Loss: 0.26705077290534973\n",
            "Loss: 0.04211631417274475\n",
            "Loss: 0.16330686211585999\n",
            "Loss: 0.4784623086452484\n",
            "Loss: 0.07678292691707611\n",
            "Loss: 0.2032894492149353\n",
            "Loss: 0.1665036380290985\n",
            "Loss: 0.29345703125\n",
            "Loss: 0.16595236957073212\n",
            "Loss: 0.21245309710502625\n",
            "Loss: 0.1577952653169632\n",
            "Loss: 0.34350740909576416\n",
            "Loss: 0.14127978682518005\n",
            "Loss: 0.1836579591035843\n",
            "Loss: 0.6506310701370239\n",
            "Loss: 0.34487274289131165\n",
            "Loss: 0.20429836213588715\n",
            "Loss: 0.3831945061683655\n",
            "Loss: 0.04835672676563263\n",
            "Loss: 0.12901124358177185\n",
            "Loss: 0.15189796686172485\n",
            "Loss: 0.26307880878448486\n",
            "Loss: 0.24427616596221924\n",
            "Loss: 0.027352117002010345\n",
            "Loss: 0.08262111991643906\n",
            "Loss: 0.06892333179712296\n",
            "Loss: 0.07647157460451126\n",
            "Loss: 0.10006050765514374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating QA tests:   0%|          | 0/211 [00:00<?, ?it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:   8%|▊         | 16/211 [00:00<00:01, 159.75it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  15%|█▌        | 32/211 [00:00<00:01, 156.45it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  30%|██▉       | 63/211 [00:00<00:01, 145.54it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  44%|████▍     | 93/211 [00:00<00:00, 137.34it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  51%|█████     | 107/211 [00:00<00:00, 137.67it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  78%|███████▊  | 165/211 [00:01<00:00, 139.58it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  86%|████████▌ | 181/211 [00:01<00:00, 142.82it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests: 100%|██████████| 211/211 [00:01<00:00, 138.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Metrics for epoch:2\n",
            "----------------------------\n",
            "Avg loss 0.12862986614155908\n",
            "Average Cell Precision: 0.5695260663507108\n",
            "Average Cell Recall: 0.5389715639810426\n",
            "Average Tuple Cardinality Accuracy: 0.7173744075829385\n",
            "Average Tuple Constraint Accuracy: 0.4132464454976303\n",
            "Average Tuple Order Accuracy: 0.3777872340425532\n",
            "----------------------------\n",
            "Epoch: 3\n",
            "Loss: 0.0790642499923706\n",
            "Loss: 0.1709599494934082\n",
            "Loss: 0.0916530191898346\n",
            "Loss: 0.0968795120716095\n",
            "Loss: 0.07069537043571472\n",
            "Loss: 0.0758436769247055\n",
            "Loss: 0.05669151619076729\n",
            "Loss: 0.08795515447854996\n",
            "Loss: 0.13661795854568481\n",
            "Loss: 0.3160078525543213\n",
            "Loss: 0.2962087094783783\n",
            "Loss: 1.2873340845108032\n",
            "Loss: 1.7157717943191528\n",
            "Loss: 0.04090167582035065\n",
            "Loss: 0.026247959583997726\n",
            "Loss: 0.8403841853141785\n",
            "Loss: 0.1001235619187355\n",
            "Loss: 0.592146635055542\n",
            "Loss: 0.14729760587215424\n",
            "Loss: 0.05205288529396057\n",
            "Loss: 0.16492082178592682\n",
            "Loss: 0.33467087149620056\n",
            "Loss: 0.22546738386154175\n",
            "Loss: 0.13006098568439484\n",
            "Loss: 0.07568517327308655\n",
            "Loss: 0.0066263326443731785\n",
            "Loss: 0.06067882850766182\n",
            "Loss: 0.21205748617649078\n",
            "Loss: 0.08702176064252853\n",
            "Loss: 0.045373111963272095\n",
            "Loss: 0.09289252758026123\n",
            "Loss: 0.159804105758667\n",
            "Loss: 0.07619918882846832\n",
            "Loss: 0.07023534923791885\n",
            "Loss: 0.07171636819839478\n",
            "Loss: 0.049894850701093674\n",
            "Loss: 0.19216923415660858\n",
            "Loss: 0.2274756282567978\n",
            "Loss: 0.022403493523597717\n",
            "Loss: 0.40933898091316223\n",
            "Loss: 0.07685783505439758\n",
            "Loss: 0.08856920152902603\n",
            "Loss: 0.1871648132801056\n",
            "Loss: 0.1902465522289276\n",
            "Loss: 0.1328009068965912\n",
            "Loss: 0.1104421466588974\n",
            "Loss: 0.08310934901237488\n",
            "Loss: 0.014305291697382927\n",
            "Loss: 0.005311581771820784\n",
            "Loss: 0.03940745070576668\n",
            "Loss: 0.07288824766874313\n",
            "Loss: 0.051744505763053894\n",
            "Loss: 0.5268428921699524\n",
            "Loss: 0.038709644228219986\n",
            "Loss: 0.08582667261362076\n",
            "Loss: 0.16131144762039185\n",
            "Loss: 0.10430768132209778\n",
            "Loss: 0.0733693391084671\n",
            "Loss: 0.0563739649951458\n",
            "Loss: 0.04646920785307884\n",
            "Loss: 0.0010410575196146965\n",
            "Loss: 0.06895808130502701\n",
            "Loss: 0.01949499547481537\n",
            "Loss: 0.12381435930728912\n",
            "Loss: 0.00761036342009902\n",
            "Loss: 0.02268943004310131\n",
            "Loss: 0.02119036763906479\n",
            "Loss: 0.43432703614234924\n",
            "Loss: 0.10355889797210693\n",
            "Loss: 0.15476995706558228\n",
            "Loss: 0.10434652119874954\n",
            "Loss: 0.06378515809774399\n",
            "Loss: 0.05927272140979767\n",
            "Loss: 0.03482087701559067\n",
            "Loss: 0.008943237364292145\n",
            "Loss: 0.09162166714668274\n",
            "Loss: 0.025279508903622627\n",
            "Loss: 0.03416847437620163\n",
            "Loss: 0.029078390449285507\n",
            "Loss: 0.021005507558584213\n",
            "Loss: 0.8261215090751648\n",
            "Loss: 0.45949965715408325\n",
            "Loss: 0.011940069496631622\n",
            "Loss: 0.11904455721378326\n",
            "Loss: 0.16153161227703094\n",
            "Loss: 0.07915817201137543\n",
            "Loss: 0.025897834450006485\n",
            "Loss: 0.04541882127523422\n",
            "Loss: 0.02468305453658104\n",
            "Loss: 0.1357136368751526\n",
            "Loss: 0.14594052731990814\n",
            "Loss: 0.012357274070382118\n",
            "Loss: 0.28178128600120544\n",
            "Loss: 0.10200414061546326\n",
            "Loss: 0.06191582605242729\n",
            "Loss: 0.0994158610701561\n",
            "Loss: 0.03986924886703491\n",
            "Loss: 0.004337383899837732\n",
            "Loss: 0.07911624014377594\n",
            "Loss: 0.04012851044535637\n",
            "Loss: 0.030449071899056435\n",
            "Loss: 0.011758391745388508\n",
            "Loss: 0.049778521060943604\n",
            "Loss: 0.13457843661308289\n",
            "Loss: 0.004777098074555397\n",
            "Loss: 0.0026186308823525906\n",
            "Loss: 0.009069986641407013\n",
            "Loss: 0.07059280574321747\n",
            "Loss: 0.058001965284347534\n",
            "Loss: 0.07439235597848892\n",
            "Loss: 0.16924327611923218\n",
            "Loss: 0.02296743169426918\n",
            "Loss: 0.029092539101839066\n",
            "Loss: 0.016992218792438507\n",
            "Loss: 0.017078343778848648\n",
            "Loss: 0.04675361514091492\n",
            "Loss: 0.008474723435938358\n",
            "Loss: 0.10381824523210526\n",
            "Loss: 0.41666504740715027\n",
            "Loss: 0.08624523878097534\n",
            "Loss: 0.1522633135318756\n",
            "Loss: 0.06886009126901627\n",
            "Loss: 0.0330127477645874\n",
            "Loss: 0.05003773421049118\n",
            "Loss: 0.35754379630088806\n",
            "Loss: 0.01615924760699272\n",
            "Loss: 0.12889111042022705\n",
            "Loss: 0.03715280443429947\n",
            "Loss: 0.04131203889846802\n",
            "Loss: 0.01755160465836525\n",
            "Loss: 0.013948657549917698\n",
            "Loss: 0.024334553629159927\n",
            "Loss: 0.021784022450447083\n",
            "Loss: 0.17695719003677368\n",
            "Loss: 0.11011560261249542\n",
            "Loss: 0.38365817070007324\n",
            "Loss: 0.06665366142988205\n",
            "Loss: 0.051759082823991776\n",
            "Loss: 0.06539107859134674\n",
            "Loss: 0.005971063859760761\n",
            "Loss: 0.06451017409563065\n",
            "Loss: 0.09726020693778992\n",
            "Loss: 0.20930026471614838\n",
            "Loss: 0.1517680138349533\n",
            "Loss: 0.07362332940101624\n",
            "Loss: 0.03848138079047203\n",
            "Loss: 0.002700202399864793\n",
            "Loss: 0.020665083080530167\n",
            "Loss: 0.15545229613780975\n",
            "Loss: 0.07394105195999146\n",
            "Loss: 0.05625222995877266\n",
            "Loss: 0.30739298462867737\n",
            "Loss: 0.0434257835149765\n",
            "Loss: 0.2538806200027466\n",
            "Loss: 0.219480961561203\n",
            "Loss: 0.03736810013651848\n",
            "Loss: 0.1433049440383911\n",
            "Loss: 0.0351618267595768\n",
            "Loss: 0.017288338392972946\n",
            "Loss: 0.04716666042804718\n",
            "Loss: 0.012037815526127815\n",
            "Loss: 0.4449925422668457\n",
            "Loss: 0.06928115338087082\n",
            "Loss: 0.08740082383155823\n",
            "Loss: 0.17850129306316376\n",
            "Loss: 0.04529252275824547\n",
            "Loss: 0.028207268565893173\n",
            "Loss: 0.01302195806056261\n",
            "Loss: 0.13299202919006348\n",
            "Loss: 0.3405216336250305\n",
            "Loss: 0.07364104688167572\n",
            "Loss: 0.0963824987411499\n",
            "Loss: 0.1954554319381714\n",
            "Loss: 0.181205153465271\n",
            "Loss: 0.16802078485488892\n",
            "Loss: 0.17283973097801208\n",
            "Loss: 0.03782183304429054\n",
            "Loss: 0.09039768576622009\n",
            "Loss: 0.016784891486167908\n",
            "Loss: 0.0015441335272043943\n",
            "Loss: 0.0895322859287262\n",
            "Loss: 0.26180335879325867\n",
            "Loss: 0.10047636926174164\n",
            "Loss: 0.0010477968025952578\n",
            "Loss: 0.19344961643218994\n",
            "Loss: 0.006743343081325293\n",
            "Loss: 0.018310222774744034\n",
            "Loss: 0.056116264313459396\n",
            "Loss: 0.005446945782750845\n",
            "Loss: 0.043589893728494644\n",
            "Loss: 0.00625281548127532\n",
            "Loss: 0.0022315485402941704\n",
            "Loss: 0.26445311307907104\n",
            "Loss: 0.08647144585847855\n",
            "Loss: 0.16839486360549927\n",
            "Loss: 0.10463058948516846\n",
            "Loss: 0.0912572517991066\n",
            "Loss: 0.11644243448972702\n",
            "Loss: 0.0034233317710459232\n",
            "Loss: 0.07190143316984177\n",
            "Loss: 0.019826553761959076\n",
            "Loss: 0.03424493223428726\n",
            "Loss: 0.16498912870883942\n",
            "Loss: 0.06858338415622711\n",
            "Loss: 0.010699000209569931\n",
            "Loss: 0.09581661969423294\n",
            "Loss: 0.10032691061496735\n",
            "Loss: 0.012316390872001648\n",
            "Loss: 0.05409088730812073\n",
            "Loss: 0.027055369690060616\n",
            "Loss: 0.006489983759820461\n",
            "Loss: 0.045186273753643036\n",
            "Loss: 0.1144082099199295\n",
            "Loss: 0.13285508751869202\n",
            "Loss: 0.1862267106771469\n",
            "Loss: 0.15659277141094208\n",
            "Loss: 0.04622074216604233\n",
            "Loss: 0.06301872432231903\n",
            "Loss: 0.08180207014083862\n",
            "Loss: 0.11996883153915405\n",
            "Loss: 0.08543197065591812\n",
            "Loss: 0.05347738787531853\n",
            "Loss: 0.06467784941196442\n",
            "Loss: 0.10744839161634445\n",
            "Loss: 0.036119863390922546\n",
            "Loss: 0.03750470280647278\n",
            "Loss: 0.14848822355270386\n",
            "Loss: 0.0645720362663269\n",
            "Loss: 0.03190253674983978\n",
            "Loss: 0.11158059537410736\n",
            "Loss: 0.0935792326927185\n",
            "Loss: 0.02041829749941826\n",
            "Loss: 0.18511609733104706\n",
            "Loss: 0.003248879685997963\n",
            "Loss: 0.04765871539711952\n",
            "Loss: 0.027894217520952225\n",
            "Loss: 0.00899908784776926\n",
            "Loss: 0.07762621343135834\n",
            "Loss: 0.02327054738998413\n",
            "Loss: 0.001923711271956563\n",
            "Loss: 0.04893271252512932\n",
            "Loss: 0.004201924428343773\n",
            "Loss: 0.01796838454902172\n",
            "Loss: 0.011200865730643272\n",
            "Loss: 0.029208075255155563\n",
            "Loss: 0.035893287509679794\n",
            "Loss: 0.017227400094270706\n",
            "Loss: 0.030850328505039215\n",
            "Loss: 0.15524251759052277\n",
            "Loss: 0.19933034479618073\n",
            "Loss: 0.18121033906936646\n",
            "Loss: 0.14327315986156464\n",
            "Loss: 0.15057052671909332\n",
            "Loss: 0.004534694831818342\n",
            "Loss: 0.030420716851949692\n",
            "Loss: 0.05608702450990677\n",
            "Loss: 0.0004125335835851729\n",
            "Loss: 0.0010154374176636338\n",
            "Loss: 0.026135608553886414\n",
            "Loss: 0.041841134428977966\n",
            "Loss: 0.025747187435626984\n",
            "Loss: 0.06972376257181168\n",
            "Loss: 0.11691111326217651\n",
            "Loss: 0.03789987415075302\n",
            "Loss: 0.058536309748888016\n",
            "Loss: 0.04538918286561966\n",
            "Loss: 0.026543112471699715\n",
            "Loss: 0.1293761134147644\n",
            "Loss: 0.14524289965629578\n",
            "Loss: 0.06803576648235321\n",
            "Loss: 0.16846534609794617\n",
            "Loss: 0.0016600359231233597\n",
            "Loss: 0.06083950027823448\n",
            "Loss: 0.00495849410071969\n",
            "Loss: 0.04197283834218979\n",
            "Loss: 0.04996693879365921\n",
            "Loss: 0.0035029922146350145\n",
            "Loss: 0.73560631275177\n",
            "Loss: 0.0015065009938552976\n",
            "Loss: 0.07220225781202316\n",
            "Loss: 0.027232620865106583\n",
            "Loss: 0.060468483716249466\n",
            "Loss: 0.07644753903150558\n",
            "Loss: 0.04811272770166397\n",
            "Loss: 0.007129009813070297\n",
            "Loss: 0.0036518042907118797\n",
            "Loss: 0.006658999249339104\n",
            "Loss: 0.022540194913744926\n",
            "Loss: 0.0444546602666378\n",
            "Loss: 0.02212698757648468\n",
            "Loss: 0.003603450022637844\n",
            "Loss: 0.39319154620170593\n",
            "Loss: 0.13123710453510284\n",
            "Loss: 0.0008400167571380734\n",
            "Loss: 0.020617982372641563\n",
            "Loss: 0.004987961146980524\n",
            "Loss: 0.0819268450140953\n",
            "Loss: 0.09707361459732056\n",
            "Loss: 0.001105602364987135\n",
            "Loss: 0.01544983685016632\n",
            "Loss: 0.13209843635559082\n",
            "Loss: 0.03489573672413826\n",
            "Loss: 0.04220094904303551\n",
            "Loss: 0.0042494977824389935\n",
            "Loss: 0.01174166239798069\n",
            "Loss: 0.7651151418685913\n",
            "Loss: 0.021388372406363487\n",
            "Loss: 0.1183047890663147\n",
            "Loss: 0.017347747460007668\n",
            "Loss: 0.02079988270998001\n",
            "Loss: 0.023513205349445343\n",
            "Loss: 0.011278849095106125\n",
            "Loss: 0.0022048745304346085\n",
            "Loss: 0.042032815515995026\n",
            "Loss: 0.01265396736562252\n",
            "Loss: 0.0011420280206948519\n",
            "Loss: 0.003891610074788332\n",
            "Loss: 0.007627337239682674\n",
            "Loss: 0.0007587289437651634\n",
            "Loss: 0.002010281663388014\n",
            "Loss: 0.01121121272444725\n",
            "Loss: 0.016662560403347015\n",
            "Loss: 0.0030395821668207645\n",
            "Loss: 0.0009867126354947686\n",
            "Loss: 0.06313774734735489\n",
            "Loss: 0.06067270040512085\n",
            "Loss: 0.03315868228673935\n",
            "Loss: 0.00752088101580739\n",
            "Loss: 0.005802343599498272\n",
            "Loss: 0.0034816048573702574\n",
            "Loss: 0.012175792828202248\n",
            "Loss: 0.011582430452108383\n",
            "Loss: 0.012225276790559292\n",
            "Loss: 0.011404773220419884\n",
            "Loss: 0.02311919629573822\n",
            "Loss: 0.03892212361097336\n",
            "Loss: 0.008031465113162994\n",
            "Loss: 0.03219245746731758\n",
            "Loss: 0.00767103023827076\n",
            "Loss: 0.014819455333054066\n",
            "Loss: 0.0020158407278358936\n",
            "Loss: 0.000869377632625401\n",
            "Loss: 0.004889757372438908\n",
            "Loss: 0.007979081943631172\n",
            "Loss: 0.024478668347001076\n",
            "Loss: 0.004429328721016645\n",
            "Loss: 0.013819963671267033\n",
            "Loss: 0.0017973429057747126\n",
            "Loss: 0.003751890966668725\n",
            "Loss: 0.012678295373916626\n",
            "Loss: 0.028579382225871086\n",
            "Loss: 0.11580097675323486\n",
            "Loss: 0.030407633632421494\n",
            "Loss: 0.034639086574316025\n",
            "Loss: 0.07223108410835266\n",
            "Loss: 0.19106170535087585\n",
            "Loss: 0.11163151264190674\n",
            "Loss: 0.20371279120445251\n",
            "Loss: 0.13495661318302155\n",
            "Loss: 0.06886333227157593\n",
            "Loss: 0.06413523852825165\n",
            "Loss: 0.05045023560523987\n",
            "Loss: 0.03856915608048439\n",
            "Loss: 0.016501152887940407\n",
            "Loss: 0.014961563050746918\n",
            "Loss: 0.60393887758255\n",
            "Loss: 0.020642079412937164\n",
            "Loss: 0.011078311130404472\n",
            "Loss: 0.06206715479493141\n",
            "Loss: 0.009081370197236538\n",
            "Loss: 0.005283850710839033\n",
            "Loss: 0.008008253760635853\n",
            "Loss: 0.065085768699646\n",
            "Loss: 0.4104625880718231\n",
            "Loss: 0.022101078182458878\n",
            "Loss: 0.1407165229320526\n",
            "Loss: 0.0034875753335654736\n",
            "Loss: 0.034239768981933594\n",
            "Loss: 0.5043624043464661\n",
            "Loss: 0.04093881696462631\n",
            "Loss: 0.08459780365228653\n",
            "Loss: 0.024426080286502838\n",
            "Loss: 0.10809046030044556\n",
            "Loss: 0.031834591180086136\n",
            "Loss: 0.10189063847064972\n",
            "Loss: 0.19603823125362396\n",
            "Loss: 0.009084961377084255\n",
            "Loss: 0.031888123601675034\n",
            "Loss: 0.055230334401130676\n",
            "Loss: 0.007745268288999796\n",
            "Loss: 0.0044872453436255455\n",
            "Loss: 0.028188001364469528\n",
            "Loss: 0.03338215872645378\n",
            "Loss: 0.007125310134142637\n",
            "Loss: 0.029308900237083435\n",
            "Loss: 0.005889455787837505\n",
            "Loss: 0.05658169463276863\n",
            "Loss: 0.09482722729444504\n",
            "Loss: 0.046379752457141876\n",
            "Loss: 0.013065047562122345\n",
            "Loss: 0.3257790803909302\n",
            "Loss: 0.06029341742396355\n",
            "Loss: 0.014121674932539463\n",
            "Loss: 0.3546096980571747\n",
            "Loss: 0.041169021278619766\n",
            "Loss: 0.1491815149784088\n",
            "Loss: 0.04596748948097229\n",
            "Loss: 0.057836662977933884\n",
            "Loss: 0.013945627957582474\n",
            "Loss: 1.036487102508545\n",
            "Loss: 0.054173145443201065\n",
            "Loss: 0.06385824084281921\n",
            "Loss: 0.06988562643527985\n",
            "Loss: 0.08527189493179321\n",
            "Loss: 0.24624140560626984\n",
            "Loss: 0.17087621986865997\n",
            "Loss: 0.06467291712760925\n",
            "Loss: 0.23476779460906982\n",
            "Loss: 0.0538976676762104\n",
            "Loss: 0.10142838954925537\n",
            "Loss: 0.07936687022447586\n",
            "Loss: 0.06884419173002243\n",
            "Loss: 0.1565665900707245\n",
            "Loss: 0.2758778929710388\n",
            "Loss: 0.0818486362695694\n",
            "Loss: 0.020922822877764702\n",
            "Loss: 0.0878143459558487\n",
            "Loss: 0.1392485350370407\n",
            "Loss: 0.20506316423416138\n",
            "Loss: 0.12006845325231552\n",
            "Loss: 0.01375345978885889\n",
            "Loss: 0.16244380176067352\n",
            "Loss: 0.2666376829147339\n",
            "Loss: 0.13202261924743652\n",
            "Loss: 0.36388108134269714\n",
            "Loss: 0.02344091236591339\n",
            "Loss: 0.14652922749519348\n",
            "Loss: 0.42629316449165344\n",
            "Loss: 0.1447567641735077\n",
            "Loss: 0.10552710294723511\n",
            "Loss: 0.053423427045345306\n",
            "Loss: 0.07155124098062515\n",
            "Loss: 0.053103167563676834\n",
            "Loss: 0.053796812891960144\n",
            "Loss: 0.11048580706119537\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating QA tests:  33%|███▎      | 70/211 [00:00<00:00, 154.66it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  86%|████████▋ | 182/211 [00:01<00:00, 133.13it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests: 100%|██████████| 211/211 [00:01<00:00, 144.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Metrics for epoch:3\n",
            "----------------------------\n",
            "Avg loss 0.09877846795696703\n",
            "Average Cell Precision: 0.6298862559241707\n",
            "Average Cell Recall: 0.5867440758293838\n",
            "Average Tuple Cardinality Accuracy: 0.7818625592417061\n",
            "Average Tuple Constraint Accuracy: 0.4499620853080569\n",
            "Average Tuple Order Accuracy: 0.4232051282051283\n",
            "----------------------------\n",
            "Epoch: 4\n",
            "Loss: 0.16605469584465027\n",
            "Loss: 0.4564093053340912\n",
            "Loss: 0.14514847099781036\n",
            "Loss: 0.11454199999570847\n",
            "Loss: 0.04300885647535324\n",
            "Loss: 0.04206852987408638\n",
            "Loss: 0.04071690887212753\n",
            "Loss: 0.023148544132709503\n",
            "Loss: 0.08495932817459106\n",
            "Loss: 0.2567107081413269\n",
            "Loss: 0.28128084540367126\n",
            "Loss: 0.056539952754974365\n",
            "Loss: 0.27164334058761597\n",
            "Loss: 0.04348409175872803\n",
            "Loss: 0.06394781172275543\n",
            "Loss: 0.10109410434961319\n",
            "Loss: 0.4189787209033966\n",
            "Loss: 0.10071291029453278\n",
            "Loss: 0.31732064485549927\n",
            "Loss: 0.053131211549043655\n",
            "Loss: 0.053133439272642136\n",
            "Loss: 0.046051274985075\n",
            "Loss: 0.24045774340629578\n",
            "Loss: 0.01575149968266487\n",
            "Loss: 0.1125757247209549\n",
            "Loss: 0.02680002525448799\n",
            "Loss: 0.007530343718826771\n",
            "Loss: 0.1295587420463562\n",
            "Loss: 0.06066849082708359\n",
            "Loss: 0.030985454097390175\n",
            "Loss: 0.042178280651569366\n",
            "Loss: 0.3272799849510193\n",
            "Loss: 0.05200127512216568\n",
            "Loss: 0.01509288139641285\n",
            "Loss: 0.057292163372039795\n",
            "Loss: 0.00428192550316453\n",
            "Loss: 0.031597692519426346\n",
            "Loss: 0.12484206259250641\n",
            "Loss: 0.013482790440320969\n",
            "Loss: 0.9901348352432251\n",
            "Loss: 0.03989505022764206\n",
            "Loss: 0.06725255399942398\n",
            "Loss: 0.019578492268919945\n",
            "Loss: 0.08682843297719955\n",
            "Loss: 0.0758441835641861\n",
            "Loss: 0.08907568454742432\n",
            "Loss: 0.044127143919467926\n",
            "Loss: 0.003800011705607176\n",
            "Loss: 0.021058568730950356\n",
            "Loss: 0.03727962449193001\n",
            "Loss: 0.03901379555463791\n",
            "Loss: 0.021437538787722588\n",
            "Loss: 0.07536936551332474\n",
            "Loss: 0.3740856349468231\n",
            "Loss: 0.13811522722244263\n",
            "Loss: 0.0982971042394638\n",
            "Loss: 0.03898363560438156\n",
            "Loss: 0.05518152564764023\n",
            "Loss: 0.014458381570875645\n",
            "Loss: 0.021860644221305847\n",
            "Loss: 0.043501827865839005\n",
            "Loss: 0.05102413892745972\n",
            "Loss: 0.01174279022961855\n",
            "Loss: 0.26702338457107544\n",
            "Loss: 0.21571728587150574\n",
            "Loss: 0.014201704412698746\n",
            "Loss: 0.03857096657156944\n",
            "Loss: 0.1415063440799713\n",
            "Loss: 0.14821334183216095\n",
            "Loss: 0.08501403033733368\n",
            "Loss: 0.1367211937904358\n",
            "Loss: 0.1023242324590683\n",
            "Loss: 0.010672914795577526\n",
            "Loss: 0.03736107051372528\n",
            "Loss: 0.01825447380542755\n",
            "Loss: 0.031396619975566864\n",
            "Loss: 0.030201949179172516\n",
            "Loss: 0.029572950676083565\n",
            "Loss: 0.0035043112002313137\n",
            "Loss: 0.012573029845952988\n",
            "Loss: 0.08670857548713684\n",
            "Loss: 0.05458495765924454\n",
            "Loss: 0.024300022050738335\n",
            "Loss: 0.07788996398448944\n",
            "Loss: 0.03845280408859253\n",
            "Loss: 0.0685197040438652\n",
            "Loss: 0.008070413023233414\n",
            "Loss: 0.011461930349469185\n",
            "Loss: 0.00700522493571043\n",
            "Loss: 0.0894833356142044\n",
            "Loss: 0.056790124624967575\n",
            "Loss: 0.004122196231037378\n",
            "Loss: 0.06785453855991364\n",
            "Loss: 0.023614738136529922\n",
            "Loss: 0.02798909693956375\n",
            "Loss: 0.16237077116966248\n",
            "Loss: 0.02418416552245617\n",
            "Loss: 0.0003365403099451214\n",
            "Loss: 0.10289987176656723\n",
            "Loss: 0.006233207881450653\n",
            "Loss: 0.004502012860029936\n",
            "Loss: 0.013863624073565006\n",
            "Loss: 0.0025147302076220512\n",
            "Loss: 0.06547832489013672\n",
            "Loss: 0.0005656046560034156\n",
            "Loss: 0.00035217375261709094\n",
            "Loss: 0.028534727171063423\n",
            "Loss: 0.1680465042591095\n",
            "Loss: 0.017615826800465584\n",
            "Loss: 0.03918978571891785\n",
            "Loss: 0.15514810383319855\n",
            "Loss: 0.006577775813639164\n",
            "Loss: 0.015198084525763988\n",
            "Loss: 0.014971045777201653\n",
            "Loss: 0.022901548072695732\n",
            "Loss: 0.011393505148589611\n",
            "Loss: 0.008504987694323063\n",
            "Loss: 0.028161168098449707\n",
            "Loss: 0.1996339112520218\n",
            "Loss: 0.08367633819580078\n",
            "Loss: 0.08558507263660431\n",
            "Loss: 0.1444610059261322\n",
            "Loss: 0.015805596485733986\n",
            "Loss: 0.013088665902614594\n",
            "Loss: 0.6902968883514404\n",
            "Loss: 0.04181098937988281\n",
            "Loss: 0.06016398221254349\n",
            "Loss: 0.11273883283138275\n",
            "Loss: 0.10753997415304184\n",
            "Loss: 0.033127348870038986\n",
            "Loss: 0.05628960207104683\n",
            "Loss: 0.0168168805539608\n",
            "Loss: 0.08959420025348663\n",
            "Loss: 0.21008579432964325\n",
            "Loss: 0.9649710655212402\n",
            "Loss: 0.3611082434654236\n",
            "Loss: 0.04200064390897751\n",
            "Loss: 0.2797689735889435\n",
            "Loss: 0.17382660508155823\n",
            "Loss: 0.06005420535802841\n",
            "Loss: 0.11335659772157669\n",
            "Loss: 0.14584733545780182\n",
            "Loss: 0.18177157640457153\n",
            "Loss: 0.07909843325614929\n",
            "Loss: 0.11324181407690048\n",
            "Loss: 0.0536113865673542\n",
            "Loss: 0.0036642414052039385\n",
            "Loss: 0.07398911565542221\n",
            "Loss: 0.20190750062465668\n",
            "Loss: 0.032208044081926346\n",
            "Loss: 0.14250881969928741\n",
            "Loss: 0.2154831886291504\n",
            "Loss: 0.062276244163513184\n",
            "Loss: 0.18056046962738037\n",
            "Loss: 0.19724823534488678\n",
            "Loss: 0.00536702573299408\n",
            "Loss: 0.20135220885276794\n",
            "Loss: 0.025976814329624176\n",
            "Loss: 0.02364681288599968\n",
            "Loss: 0.13497532904148102\n",
            "Loss: 0.025451738387346268\n",
            "Loss: 0.5576448440551758\n",
            "Loss: 0.046706538647413254\n",
            "Loss: 0.05993016064167023\n",
            "Loss: 0.11833739280700684\n",
            "Loss: 0.01718064397573471\n",
            "Loss: 0.01949775032699108\n",
            "Loss: 0.026705684140324593\n",
            "Loss: 0.10957225412130356\n",
            "Loss: 0.03771407902240753\n",
            "Loss: 0.05168888717889786\n",
            "Loss: 0.019609440118074417\n",
            "Loss: 0.05814916640520096\n",
            "Loss: 0.019189469516277313\n",
            "Loss: 0.37753090262413025\n",
            "Loss: 0.1937476247549057\n",
            "Loss: 0.01900111511349678\n",
            "Loss: 0.11776474863290787\n",
            "Loss: 0.12104165554046631\n",
            "Loss: 0.08717931807041168\n",
            "Loss: 0.026318306103348732\n",
            "Loss: 0.17442163825035095\n",
            "Loss: 0.06416262686252594\n",
            "Loss: 0.002968619577586651\n",
            "Loss: 0.024331023916602135\n",
            "Loss: 0.00863608717918396\n",
            "Loss: 0.04008255526423454\n",
            "Loss: 0.020761903375387192\n",
            "Loss: 0.08945129066705704\n",
            "Loss: 0.02745486982166767\n",
            "Loss: 0.02303393930196762\n",
            "Loss: 0.002342762891203165\n",
            "Loss: 0.15777261555194855\n",
            "Loss: 0.04857826977968216\n",
            "Loss: 0.14924411475658417\n",
            "Loss: 0.10335250943899155\n",
            "Loss: 0.22058796882629395\n",
            "Loss: 0.05757685378193855\n",
            "Loss: 0.09180549532175064\n",
            "Loss: 0.0689576119184494\n",
            "Loss: 0.16536079347133636\n",
            "Loss: 0.04057592898607254\n",
            "Loss: 0.09229855984449387\n",
            "Loss: 0.005995613988488913\n",
            "Loss: 0.053090427070856094\n",
            "Loss: 0.04685250669717789\n",
            "Loss: 0.0034843257162719965\n",
            "Loss: 0.05405786633491516\n",
            "Loss: 0.026408912613987923\n",
            "Loss: 0.0073380982503294945\n",
            "Loss: 0.010512622073292732\n",
            "Loss: 0.08702358603477478\n",
            "Loss: 0.08735343813896179\n",
            "Loss: 0.08151548355817795\n",
            "Loss: 0.12002763152122498\n",
            "Loss: 0.10705718398094177\n",
            "Loss: 0.1182723268866539\n",
            "Loss: 0.12162305414676666\n",
            "Loss: 0.02773110568523407\n",
            "Loss: 0.18414513766765594\n",
            "Loss: 0.10003741085529327\n",
            "Loss: 0.12795014679431915\n",
            "Loss: 0.15299338102340698\n",
            "Loss: 0.1036698967218399\n",
            "Loss: 0.05012013390660286\n",
            "Loss: 0.0031032017432153225\n",
            "Loss: 0.17134617269039154\n",
            "Loss: 0.041082121431827545\n",
            "Loss: 0.0593523271381855\n",
            "Loss: 0.15476126968860626\n",
            "Loss: 0.04793476313352585\n",
            "Loss: 0.23687788844108582\n",
            "Loss: 0.30746373534202576\n",
            "Loss: 0.0050351256504654884\n",
            "Loss: 0.08659952133893967\n",
            "Loss: 0.07998191565275192\n",
            "Loss: 0.0037062568590044975\n",
            "Loss: 0.03973982483148575\n",
            "Loss: 0.006811659783124924\n",
            "Loss: 0.0012511787936091423\n",
            "Loss: 0.0721931904554367\n",
            "Loss: 0.03893408179283142\n",
            "Loss: 0.02421143464744091\n",
            "Loss: 0.0032017554622143507\n",
            "Loss: 0.02417941391468048\n",
            "Loss: 0.013887477107346058\n",
            "Loss: 0.011440126225352287\n",
            "Loss: 0.018564661964774132\n",
            "Loss: 0.3615334630012512\n",
            "Loss: 0.06844639778137207\n",
            "Loss: 0.05530686676502228\n",
            "Loss: 0.02075689658522606\n",
            "Loss: 0.0587436705827713\n",
            "Loss: 0.008324254304170609\n",
            "Loss: 0.1175413653254509\n",
            "Loss: 0.05306851118803024\n",
            "Loss: 0.0007399331079795957\n",
            "Loss: 0.0026352284476161003\n",
            "Loss: 0.03308866173028946\n",
            "Loss: 0.09933663159608841\n",
            "Loss: 0.0814153179526329\n",
            "Loss: 0.058905139565467834\n",
            "Loss: 0.09691318869590759\n",
            "Loss: 0.03416387364268303\n",
            "Loss: 0.06570190191268921\n",
            "Loss: 0.06881870329380035\n",
            "Loss: 0.06446067988872528\n",
            "Loss: 0.22898054122924805\n",
            "Loss: 0.3070969581604004\n",
            "Loss: 0.03555142879486084\n",
            "Loss: 0.08295505493879318\n",
            "Loss: 0.0008986967150121927\n",
            "Loss: 0.032044343650341034\n",
            "Loss: 0.0026014805771410465\n",
            "Loss: 0.011225606314837933\n",
            "Loss: 0.021478766575455666\n",
            "Loss: 0.016686487942934036\n",
            "Loss: 0.003981419838964939\n",
            "Loss: 0.02199481427669525\n",
            "Loss: 0.0035116274375468493\n",
            "Loss: 0.0032577835954725742\n",
            "Loss: 0.0017702021868899465\n",
            "Loss: 0.0026881436351686716\n",
            "Loss: 0.0010146511485800147\n",
            "Loss: 0.00156557431910187\n",
            "Loss: 0.0010675800731405616\n",
            "Loss: 0.001993746031075716\n",
            "Loss: 0.0010968137066811323\n",
            "Loss: 0.0015415481757372618\n",
            "Loss: 0.003876014146953821\n",
            "Loss: 0.005403170827776194\n",
            "Loss: 0.06275996565818787\n",
            "Loss: 0.04375883936882019\n",
            "Loss: 0.005658329464495182\n",
            "Loss: 0.03422669693827629\n",
            "Loss: 0.018850332126021385\n",
            "Loss: 0.10778355598449707\n",
            "Loss: 0.06069398671388626\n",
            "Loss: 0.0891810730099678\n",
            "Loss: 0.014762071892619133\n",
            "Loss: 0.023958463221788406\n",
            "Loss: 0.07152693718671799\n",
            "Loss: 0.4572891891002655\n",
            "Loss: 0.013597417622804642\n",
            "Loss: 0.0008147078333422542\n",
            "Loss: 0.015875279903411865\n",
            "Loss: 0.0008306959643959999\n",
            "Loss: 0.11393162608146667\n",
            "Loss: 0.003638138063251972\n",
            "Loss: 0.038673076778650284\n",
            "Loss: 0.03358118608593941\n",
            "Loss: 0.009983083233237267\n",
            "Loss: 0.0015740649541839957\n",
            "Loss: 0.019811570644378662\n",
            "Loss: 0.00613761879503727\n",
            "Loss: 0.0006591712590306997\n",
            "Loss: 0.010782929137349129\n",
            "Loss: 0.003124992363154888\n",
            "Loss: 0.006071869283914566\n",
            "Loss: 0.005880957935005426\n",
            "Loss: 0.0054950835183262825\n",
            "Loss: 0.000938839977607131\n",
            "Loss: 0.02774094231426716\n",
            "Loss: 0.00034802366280928254\n",
            "Loss: 0.008744996972382069\n",
            "Loss: 0.04134011268615723\n",
            "Loss: 0.014830886386334896\n",
            "Loss: 0.001689887372776866\n",
            "Loss: 0.003799173980951309\n",
            "Loss: 0.0004488096456043422\n",
            "Loss: 0.009319785982370377\n",
            "Loss: 0.013652371242642403\n",
            "Loss: 0.060983218252658844\n",
            "Loss: 0.001550680841319263\n",
            "Loss: 0.004443699959665537\n",
            "Loss: 0.0031562044750899076\n",
            "Loss: 0.4270085096359253\n",
            "Loss: 0.06534139066934586\n",
            "Loss: 0.0016926638782024384\n",
            "Loss: 0.025720063596963882\n",
            "Loss: 0.002747180638834834\n",
            "Loss: 0.014550566673278809\n",
            "Loss: 0.009613605216145515\n",
            "Loss: 0.0026363511569797993\n",
            "Loss: 0.0021389529574662447\n",
            "Loss: 0.4124739170074463\n",
            "Loss: 0.019312409684062004\n",
            "Loss: 0.013342102989554405\n",
            "Loss: 0.0025435704737901688\n",
            "Loss: 0.032434385269880295\n",
            "Loss: 0.02695149928331375\n",
            "Loss: 0.03415583446621895\n",
            "Loss: 0.04413371533155441\n",
            "Loss: 0.0801754742860794\n",
            "Loss: 0.13912111520767212\n",
            "Loss: 0.28480973839759827\n",
            "Loss: 0.12444953620433807\n",
            "Loss: 0.25769272446632385\n",
            "Loss: 0.02341579645872116\n",
            "Loss: 0.08539178967475891\n",
            "Loss: 0.07841324061155319\n",
            "Loss: 0.012227733619511127\n",
            "Loss: 0.02900633029639721\n",
            "Loss: 0.003903735429048538\n",
            "Loss: 0.24629783630371094\n",
            "Loss: 0.27263450622558594\n",
            "Loss: 0.018098752945661545\n",
            "Loss: 0.05427297577261925\n",
            "Loss: 0.12313689291477203\n",
            "Loss: 0.0662788674235344\n",
            "Loss: 0.08622141182422638\n",
            "Loss: 0.0060629528015851974\n",
            "Loss: 0.034841641783714294\n",
            "Loss: 0.16961483657360077\n",
            "Loss: 0.0064029330387711525\n",
            "Loss: 0.10161183029413223\n",
            "Loss: 0.002769865794107318\n",
            "Loss: 0.0038186220917850733\n",
            "Loss: 0.03054933436214924\n",
            "Loss: 0.061918292194604874\n",
            "Loss: 0.0065290858037769794\n",
            "Loss: 0.06180785223841667\n",
            "Loss: 0.04070096090435982\n",
            "Loss: 0.0606062076985836\n",
            "Loss: 0.024365199729800224\n",
            "Loss: 0.04477771371603012\n",
            "Loss: 0.0009617166360840201\n",
            "Loss: 0.018326319754123688\n",
            "Loss: 0.12768247723579407\n",
            "Loss: 0.0021564816124737263\n",
            "Loss: 0.0034384378232061863\n",
            "Loss: 0.02639628015458584\n",
            "Loss: 0.005545726045966148\n",
            "Loss: 0.0198861975222826\n",
            "Loss: 0.025576379150152206\n",
            "Loss: 0.05152346193790436\n",
            "Loss: 0.006372489035129547\n",
            "Loss: 0.007823841646313667\n",
            "Loss: 0.0013645528815686703\n",
            "Loss: 0.03423077613115311\n",
            "Loss: 0.11249808222055435\n",
            "Loss: 0.07769303768873215\n",
            "Loss: 0.0042265793308615685\n",
            "Loss: 0.07679974287748337\n",
            "Loss: 0.04594807326793671\n",
            "Loss: 0.1963234394788742\n",
            "Loss: 0.0619291216135025\n",
            "Loss: 0.04261993244290352\n",
            "Loss: 0.0032882001250982285\n",
            "Loss: 0.1526997685432434\n",
            "Loss: 0.11320853233337402\n",
            "Loss: 0.039148569107055664\n",
            "Loss: 0.06431367248296738\n",
            "Loss: 0.024938255548477173\n",
            "Loss: 0.09132801741361618\n",
            "Loss: 0.11413033306598663\n",
            "Loss: 0.04319031164050102\n",
            "Loss: 0.07558970898389816\n",
            "Loss: 0.15371596813201904\n",
            "Loss: 0.04428543522953987\n",
            "Loss: 0.021266043186187744\n",
            "Loss: 0.04811697080731392\n",
            "Loss: 0.13082532584667206\n",
            "Loss: 0.23074376583099365\n",
            "Loss: 0.074173703789711\n",
            "Loss: 0.02080647461116314\n",
            "Loss: 0.18545100092887878\n",
            "Loss: 0.2504708468914032\n",
            "Loss: 0.3012993037700653\n",
            "Loss: 0.08488476276397705\n",
            "Loss: 0.09739203751087189\n",
            "Loss: 0.12408386170864105\n",
            "Loss: 0.2868316173553467\n",
            "Loss: 0.041246894747018814\n",
            "Loss: 0.2961534559726715\n",
            "Loss: 0.053780436515808105\n",
            "Loss: 0.03408258780837059\n",
            "Loss: 0.05035858601331711\n",
            "Loss: 0.1482999473810196\n",
            "Loss: 0.09372146427631378\n",
            "Loss: 0.025860637426376343\n",
            "Loss: 0.04685233533382416\n",
            "Loss: 0.15909551084041595\n",
            "Loss: 0.051919497549533844\n",
            "Loss: 0.006814467255026102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating QA tests:  16%|█▌        | 34/211 [00:00<00:01, 155.71it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  32%|███▏      | 67/211 [00:00<00:00, 151.36it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  39%|███▉      | 83/211 [00:00<00:00, 151.41it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  47%|████▋     | 100/211 [00:00<00:00, 155.14it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  55%|█████▍    | 116/211 [00:00<00:00, 151.19it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  70%|███████   | 148/211 [00:00<00:00, 148.28it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  86%|████████▌ | 181/211 [00:01<00:00, 153.90it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests: 100%|██████████| 211/211 [00:01<00:00, 152.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Metrics for epoch:4\n",
            "----------------------------\n",
            "Avg loss 0.07836697370702077\n",
            "Average Cell Precision: 0.6337345971563982\n",
            "Average Cell Recall: 0.5805308056872037\n",
            "Average Tuple Cardinality Accuracy: 0.7539241706161137\n",
            "Average Tuple Constraint Accuracy: 0.4607298578199052\n",
            "Average Tuple Order Accuracy: 0.3511702127659575\n",
            "----------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wiRQsbQxV10x",
        "outputId": "5965dd82-0bd6-40a9-f416-226ac2eaea2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  epoch  avg_loss  avg_cell_precision  avg_cell_recall  avg_tuple_cardinality  \\\n",
              "0     0  0.178291            0.494052         0.466863               0.562265   \n",
              "1     1  0.156995            0.629052         0.598607               0.743962   \n",
              "2     2  0.128630            0.569526         0.538972               0.717374   \n",
              "3     3  0.098778            0.629886         0.586744               0.781863   \n",
              "4     4  0.078367            0.633735         0.580531               0.753924   \n",
              "\n",
              "   avg_tuple_constraint  avg_tuple_order  \n",
              "0              0.346213         0.191919  \n",
              "1              0.467355         0.375091  \n",
              "2              0.413246         0.377787  \n",
              "3              0.449962         0.423205  \n",
              "4              0.460730         0.351170  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-565558ff-502d-4ae8-b804-4652a5957ba1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>avg_loss</th>\n",
              "      <th>avg_cell_precision</th>\n",
              "      <th>avg_cell_recall</th>\n",
              "      <th>avg_tuple_cardinality</th>\n",
              "      <th>avg_tuple_constraint</th>\n",
              "      <th>avg_tuple_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.178291</td>\n",
              "      <td>0.494052</td>\n",
              "      <td>0.466863</td>\n",
              "      <td>0.562265</td>\n",
              "      <td>0.346213</td>\n",
              "      <td>0.191919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.156995</td>\n",
              "      <td>0.629052</td>\n",
              "      <td>0.598607</td>\n",
              "      <td>0.743962</td>\n",
              "      <td>0.467355</td>\n",
              "      <td>0.375091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.128630</td>\n",
              "      <td>0.569526</td>\n",
              "      <td>0.538972</td>\n",
              "      <td>0.717374</td>\n",
              "      <td>0.413246</td>\n",
              "      <td>0.377787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.098778</td>\n",
              "      <td>0.629886</td>\n",
              "      <td>0.586744</td>\n",
              "      <td>0.781863</td>\n",
              "      <td>0.449962</td>\n",
              "      <td>0.423205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.078367</td>\n",
              "      <td>0.633735</td>\n",
              "      <td>0.580531</td>\n",
              "      <td>0.753924</td>\n",
              "      <td>0.460730</td>\n",
              "      <td>0.351170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-565558ff-502d-4ae8-b804-4652a5957ba1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-565558ff-502d-4ae8-b804-4652a5957ba1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-565558ff-502d-4ae8-b804-4652a5957ba1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-002bdab2-9413-4936-87f1-6da0708008c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-002bdab2-9413-4936-87f1-6da0708008c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-002bdab2-9413-4936-87f1-6da0708008c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stats_df",
              "summary": "{\n  \"name\": \"stats_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"epoch\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040888121416236996,\n        \"min\": 0.07836697370702077,\n        \"max\": 0.17829052548988963,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.15699500036314706,\n          0.07836697370702077,\n          0.12862986614155908\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_cell_precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06051044786742483,\n        \"min\": 0.4940521327014217,\n        \"max\": 0.6337345971563982,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6290521327014218,\n          0.6337345971563982,\n          0.5695260663507108\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_cell_recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.053814516702715164,\n        \"min\": 0.46686255924170617,\n        \"max\": 0.59860663507109,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.59860663507109,\n          0.5805308056872037,\n          0.5389715639810426\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_tuple_cardinality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08676008190638791,\n        \"min\": 0.5622654028436018,\n        \"max\": 0.7818625592417061,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7439620853080569,\n          0.7539241706161137,\n          0.7173744075829385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_tuple_constraint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050019800823102784,\n        \"min\": 0.3462132701421801,\n        \"max\": 0.4673554502369668,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4673554502369668,\n          0.4607298578199052,\n          0.4132464454976303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_tuple_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08882806400750974,\n        \"min\": 0.1919186046511628,\n        \"max\": 0.4232051282051283,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.37509090909090914,\n          0.3511702127659575,\n          0.3777872340425532\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Saving the model\n",
        "save_path = '/content/drive/MyDrive/model_checkpoints'\n",
        "\n",
        "# Save the model and optimizer state at the end of training\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "checkpoint_path = os.path.join(save_path, \"model_spiderQatch2000.pt\")\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "}, checkpoint_path)\n",
        "print(f\"Final checkpoint saved to {checkpoint_path}\")"
      ],
      "metadata": {
        "id": "adEGEyibs_47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7af01f-1750-47fb-d1b2-142742e29f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final checkpoint saved to /content/drive/MyDrive/model_checkpoints/Spider100prctFinal.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Loading an existing model\n",
        "import torch\n",
        "import os\n",
        "\n",
        "\n",
        "save_path = '/content/drive/MyDrive/model_checkpoints'\n",
        "checkpoint_path = os.path.join(save_path, \"100prct_spider_checkpoint4.pt\")\n",
        "# checkpoint_path = os.path.join(save_path,\"qatch_spider_checkpoint6000.pt\")\n",
        "\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    # Load the checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path)#,map_location=torch.device('cpu')\n",
        "\n",
        "    # Restore the model and optimizer states\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(\"Checkpoint loaded successfully.\")\n",
        "else:\n",
        "    print(f\"No checkpoint found at {checkpoint_path}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Pu2pxKCltGkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spider_valid_pd['predictions_TAPAS'] = spider_valid_pd.apply(getAnswerValid, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBP_oqZj1GpB",
        "outputId": "6da39755-bf5e-4b41-c985-cf7d3980d5f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing row 0...\n",
            "Row 0 processed successfully.\n",
            "Processing row 1...\n",
            "Row 1 processed successfully.\n",
            "Processing row 2...\n",
            "Row 2 processed successfully.\n",
            "Processing row 3...\n",
            "Row 3 processed successfully.\n",
            "Processing row 8...\n",
            "Row 8 processed successfully.\n",
            "Processing row 9...\n",
            "Row 9 processed successfully.\n",
            "Processing row 14...\n",
            "Row 14 processed successfully.\n",
            "Processing row 15...\n",
            "Row 15 processed successfully.\n",
            "Processing row 20...\n",
            "Row 20 processed successfully.\n",
            "Processing row 21...\n",
            "Row 21 processed successfully.\n",
            "Processing row 87...\n",
            "Row 87 processed successfully.\n",
            "Processing row 88...\n",
            "Row 88 processed successfully.\n",
            "Processing row 91...\n",
            "Row 91 processed successfully.\n",
            "Processing row 92...\n",
            "Row 92 processed successfully.\n",
            "Processing row 179...\n",
            "Row 179 processed successfully.\n",
            "Processing row 180...\n",
            "Row 180 processed successfully.\n",
            "Processing row 181...\n",
            "Row 181 processed successfully.\n",
            "Processing row 182...\n",
            "Row 182 processed successfully.\n",
            "Processing row 183...\n",
            "Row 183 processed successfully.\n",
            "Processing row 184...\n",
            "Row 184 processed successfully.\n",
            "Processing row 187...\n",
            "Row 187 processed successfully.\n",
            "Processing row 188...\n",
            "Row 188 processed successfully.\n",
            "Processing row 193...\n",
            "Row 193 processed successfully.\n",
            "Processing row 194...\n",
            "Row 194 processed successfully.\n",
            "Processing row 195...\n",
            "Row 195 processed successfully.\n",
            "Processing row 196...\n",
            "Row 196 processed successfully.\n",
            "Processing row 259...\n",
            "Row 259 processed successfully.\n",
            "Processing row 260...\n",
            "Row 260 processed successfully.\n",
            "Processing row 261...\n",
            "Row 261 processed successfully.\n",
            "Processing row 262...\n",
            "Row 262 processed successfully.\n",
            "Processing row 265...\n",
            "Row 265 processed successfully.\n",
            "Processing row 266...\n",
            "Row 266 processed successfully.\n",
            "Processing row 273...\n",
            "Row 273 processed successfully.\n",
            "Processing row 274...\n",
            "Row 274 processed successfully.\n",
            "Processing row 289...\n",
            "Row 289 processed successfully.\n",
            "Processing row 290...\n",
            "Row 290 processed successfully.\n",
            "Processing row 291...\n",
            "Row 291 processed successfully.\n",
            "Processing row 292...\n",
            "Row 292 processed successfully.\n",
            "Processing row 295...\n",
            "Row 295 processed successfully.\n",
            "Processing row 296...\n",
            "Row 296 processed successfully.\n",
            "Processing row 297...\n",
            "Row 297 processed successfully.\n",
            "Processing row 298...\n",
            "Row 298 processed successfully.\n",
            "Processing row 299...\n",
            "Row 299 processed successfully.\n",
            "Processing row 300...\n",
            "Row 300 processed successfully.\n",
            "Processing row 303...\n",
            "Row 303 processed successfully.\n",
            "Processing row 304...\n",
            "Row 304 processed successfully.\n",
            "Processing row 305...\n",
            "Row 305 processed successfully.\n",
            "Processing row 306...\n",
            "Row 306 processed successfully.\n",
            "Processing row 313...\n",
            "Row 313 processed successfully.\n",
            "Processing row 314...\n",
            "Row 314 processed successfully.\n",
            "Processing row 347...\n",
            "Row 347 processed successfully.\n",
            "Processing row 348...\n",
            "Row 348 processed successfully.\n",
            "Processing row 349...\n",
            "Row 349 processed successfully.\n",
            "Processing row 350...\n",
            "Row 350 processed successfully.\n",
            "Processing row 351...\n",
            "Row 351 processed successfully.\n",
            "Processing row 352...\n",
            "Row 352 processed successfully.\n",
            "Processing row 357...\n",
            "Row 357 processed successfully.\n",
            "Processing row 358...\n",
            "Row 358 processed successfully.\n",
            "Processing row 371...\n",
            "Row 371 processed successfully.\n",
            "Processing row 372...\n",
            "Row 372 processed successfully.\n",
            "Processing row 377...\n",
            "Row 377 processed successfully.\n",
            "Processing row 378...\n",
            "Row 378 processed successfully.\n",
            "Processing row 381...\n",
            "Row 381 processed successfully.\n",
            "Processing row 382...\n",
            "Row 382 processed successfully.\n",
            "Processing row 383...\n",
            "Row 383 processed successfully.\n",
            "Processing row 384...\n",
            "Row 384 processed successfully.\n",
            "Processing row 385...\n",
            "Row 385 processed successfully.\n",
            "Processing row 386...\n",
            "Row 386 processed successfully.\n",
            "Processing row 387...\n",
            "Row 387 processed successfully.\n",
            "Processing row 388...\n",
            "Row 388 processed successfully.\n",
            "Processing row 389...\n",
            "Row 389 processed successfully.\n",
            "Processing row 390...\n",
            "Row 390 processed successfully.\n",
            "Processing row 397...\n",
            "Row 397 processed successfully.\n",
            "Processing row 398...\n",
            "Row 398 processed successfully.\n",
            "Processing row 411...\n",
            "Row 411 processed successfully.\n",
            "Processing row 412...\n",
            "Row 412 processed successfully.\n",
            "Processing row 413...\n",
            "Row 413 processed successfully.\n",
            "Processing row 414...\n",
            "Row 414 processed successfully.\n",
            "Processing row 416...\n",
            "Row 416 processed successfully.\n",
            "Processing row 417...\n",
            "Row 417 processed successfully.\n",
            "Processing row 428...\n",
            "Row 428 processed successfully.\n",
            "Processing row 491...\n",
            "Row 491 processed successfully.\n",
            "Processing row 492...\n",
            "Row 492 processed successfully.\n",
            "Processing row 493...\n",
            "Row 493 processed successfully.\n",
            "Processing row 495...\n",
            "Row 495 processed successfully.\n",
            "Processing row 497...\n",
            "Row 497 processed successfully.\n",
            "Processing row 501...\n",
            "Row 501 processed successfully.\n",
            "Processing row 502...\n",
            "Row 502 processed successfully.\n",
            "Processing row 507...\n",
            "Row 507 processed successfully.\n",
            "Processing row 508...\n",
            "Row 508 processed successfully.\n",
            "Processing row 509...\n",
            "Row 509 processed successfully.\n",
            "Processing row 510...\n",
            "Row 510 processed successfully.\n",
            "Processing row 511...\n",
            "Row 511 processed successfully.\n",
            "Processing row 512...\n",
            "Row 512 processed successfully.\n",
            "Processing row 513...\n",
            "Row 513 processed successfully.\n",
            "Processing row 514...\n",
            "Row 514 processed successfully.\n",
            "Processing row 517...\n",
            "Row 517 processed successfully.\n",
            "Processing row 518...\n",
            "Row 518 processed successfully.\n",
            "Processing row 519...\n",
            "Row 519 processed successfully.\n",
            "Processing row 520...\n",
            "Row 520 processed successfully.\n",
            "Processing row 523...\n",
            "Row 523 processed successfully.\n",
            "Processing row 524...\n",
            "Row 524 processed successfully.\n",
            "Processing row 527...\n",
            "Row 527 processed successfully.\n",
            "Processing row 528...\n",
            "Row 528 processed successfully.\n",
            "Processing row 553...\n",
            "Row 553 processed successfully.\n",
            "Processing row 554...\n",
            "Row 554 processed successfully.\n",
            "Processing row 559...\n",
            "Row 559 processed successfully.\n",
            "Processing row 560...\n",
            "Row 560 processed successfully.\n",
            "Processing row 563...\n",
            "Row 563 processed successfully.\n",
            "Processing row 564...\n",
            "Row 564 processed successfully.\n",
            "Processing row 567...\n",
            "Row 567 processed successfully.\n",
            "Processing row 568...\n",
            "Row 568 processed successfully.\n",
            "Processing row 577...\n",
            "Row 577 processed successfully.\n",
            "Processing row 578...\n",
            "Row 578 processed successfully.\n",
            "Processing row 579...\n",
            "Row 579 processed successfully.\n",
            "Processing row 580...\n",
            "Row 580 processed successfully.\n",
            "Processing row 581...\n",
            "Row 581 processed successfully.\n",
            "Processing row 582...\n",
            "Row 582 processed successfully.\n",
            "Processing row 585...\n",
            "Row 585 processed successfully.\n",
            "Processing row 586...\n",
            "Row 586 processed successfully.\n",
            "Processing row 587...\n",
            "Row 587 processed successfully.\n",
            "Processing row 588...\n",
            "Row 588 processed successfully.\n",
            "Processing row 589...\n",
            "Row 589 processed successfully.\n",
            "Processing row 590...\n",
            "Row 590 processed successfully.\n",
            "Processing row 591...\n",
            "Row 591 processed successfully.\n",
            "Processing row 592...\n",
            "Row 592 processed successfully.\n",
            "Processing row 593...\n",
            "Row 593 processed successfully.\n",
            "Processing row 594...\n",
            "Row 594 processed successfully.\n",
            "Processing row 599...\n",
            "Row 599 processed successfully.\n",
            "Processing row 600...\n",
            "Row 600 processed successfully.\n",
            "Processing row 601...\n",
            "Row 601 processed successfully.\n",
            "Processing row 602...\n",
            "Row 602 processed successfully.\n",
            "Processing row 603...\n",
            "Row 603 processed successfully.\n",
            "Processing row 604...\n",
            "Row 604 processed successfully.\n",
            "Processing row 613...\n",
            "Row 613 processed successfully.\n",
            "Processing row 614...\n",
            "Row 614 processed successfully.\n",
            "Processing row 619...\n",
            "Row 619 processed successfully.\n",
            "Processing row 620...\n",
            "Row 620 processed successfully.\n",
            "Processing row 621...\n",
            "Row 621 processed successfully.\n",
            "Processing row 622...\n",
            "Row 622 processed successfully.\n",
            "Processing row 631...\n",
            "Row 631 processed successfully.\n",
            "Processing row 632...\n",
            "Row 632 processed successfully.\n",
            "Processing row 639...\n",
            "Row 639 processed successfully.\n",
            "Processing row 640...\n",
            "Row 640 processed successfully.\n",
            "Processing row 641...\n",
            "Row 641 processed successfully.\n",
            "Processing row 642...\n",
            "Row 642 processed successfully.\n",
            "Processing row 647...\n",
            "Row 647 processed successfully.\n",
            "Processing row 648...\n",
            "Row 648 processed successfully.\n",
            "Processing row 649...\n",
            "Row 649 processed successfully.\n",
            "Processing row 650...\n",
            "Row 650 processed successfully.\n",
            "Processing row 651...\n",
            "Row 651 processed successfully.\n",
            "Processing row 652...\n",
            "Row 652 processed successfully.\n",
            "Processing row 653...\n",
            "Row 653 processed successfully.\n",
            "Processing row 654...\n",
            "Row 654 processed successfully.\n",
            "Processing row 657...\n",
            "Row 657 processed successfully.\n",
            "Processing row 658...\n",
            "Row 658 processed successfully.\n",
            "Processing row 677...\n",
            "Row 677 processed successfully.\n",
            "Processing row 678...\n",
            "Row 678 processed successfully.\n",
            "Processing row 679...\n",
            "Row 679 processed successfully.\n",
            "Processing row 680...\n",
            "Row 680 processed successfully.\n",
            "Processing row 681...\n",
            "Row 681 processed successfully.\n",
            "Processing row 682...\n",
            "Row 682 processed successfully.\n",
            "Processing row 685...\n",
            "Row 685 processed successfully.\n",
            "Processing row 686...\n",
            "Row 686 processed successfully.\n",
            "Processing row 688...\n",
            "Row 688 processed successfully.\n",
            "Processing row 689...\n",
            "Row 689 processed successfully.\n",
            "Processing row 691...\n",
            "Row 691 processed successfully.\n",
            "Processing row 692...\n",
            "Row 692 processed successfully.\n",
            "Processing row 693...\n",
            "Row 693 processed successfully.\n",
            "Processing row 696...\n",
            "Row 696 processed successfully.\n",
            "Processing row 822...\n",
            "Row 822 processed successfully.\n",
            "Processing row 823...\n",
            "Row 823 processed successfully.\n",
            "Processing row 824...\n",
            "Row 824 processed successfully.\n",
            "Processing row 825...\n",
            "Row 825 processed successfully.\n",
            "Processing row 826...\n",
            "Row 826 processed successfully.\n",
            "Processing row 827...\n",
            "Row 827 processed successfully.\n",
            "Processing row 828...\n",
            "Row 828 processed successfully.\n",
            "Processing row 829...\n",
            "Row 829 processed successfully.\n",
            "Processing row 830...\n",
            "Row 830 processed successfully.\n",
            "Processing row 831...\n",
            "Row 831 processed successfully.\n",
            "Processing row 834...\n",
            "Row 834 processed successfully.\n",
            "Processing row 835...\n",
            "Row 835 processed successfully.\n",
            "Processing row 836...\n",
            "Row 836 processed successfully.\n",
            "Processing row 837...\n",
            "Row 837 processed successfully.\n",
            "Processing row 850...\n",
            "Row 850 processed successfully.\n",
            "Processing row 851...\n",
            "Row 851 processed successfully.\n",
            "Processing row 858...\n",
            "Row 858 processed successfully.\n",
            "Processing row 859...\n",
            "Row 859 processed successfully.\n",
            "Processing row 962...\n",
            "Row 962 processed successfully.\n",
            "Processing row 963...\n",
            "Row 963 processed successfully.\n",
            "Processing row 964...\n",
            "Row 964 processed successfully.\n",
            "Processing row 965...\n",
            "Row 965 processed successfully.\n",
            "Processing row 966...\n",
            "Row 966 processed successfully.\n",
            "Processing row 967...\n",
            "Row 967 processed successfully.\n",
            "Processing row 968...\n",
            "Row 968 processed successfully.\n",
            "Processing row 969...\n",
            "Row 969 processed successfully.\n",
            "Processing row 984...\n",
            "Row 984 processed successfully.\n",
            "Processing row 985...\n",
            "Row 985 processed successfully.\n",
            "Processing row 986...\n",
            "Row 986 processed successfully.\n",
            "Processing row 987...\n",
            "Row 987 processed successfully.\n",
            "Processing row 988...\n",
            "Row 988 processed successfully.\n",
            "Processing row 989...\n",
            "Row 989 processed successfully.\n",
            "Processing row 994...\n",
            "Row 994 processed successfully.\n",
            "Processing row 995...\n",
            "Row 995 processed successfully.\n",
            "Processing row 996...\n",
            "Row 996 processed successfully.\n",
            "Processing row 997...\n",
            "Row 997 processed successfully.\n",
            "Processing row 1000...\n",
            "Row 1000 processed successfully.\n",
            "Processing row 1001...\n",
            "Row 1001 processed successfully.\n",
            "Processing row 1002...\n",
            "Row 1002 processed successfully.\n",
            "Processing row 1003...\n",
            "Row 1003 processed successfully.\n",
            "Processing row 1004...\n",
            "Row 1004 processed successfully.\n",
            "Processing row 1005...\n",
            "Row 1005 processed successfully.\n",
            "Processing row 1006...\n",
            "Row 1006 processed successfully.\n",
            "Processing row 1007...\n",
            "Row 1007 processed successfully.\n",
            "Processing row 1008...\n",
            "Row 1008 processed successfully.\n",
            "Processing row 1009...\n",
            "Row 1009 processed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tests_df_results = evaluator.evaluate_with_df(spider_valid_pd,\n",
        "                                      prediction_col_name=f'predictions_TAPAS',\n",
        "                                      task=\"QA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkoeU3p-z9lU",
        "outputId": "4efaea27-1ab6-4f30-b0aa-317d32adbd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating QA tests:   0%|          | 0/216 [00:00<?, ?it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:   1%|▏         | 3/216 [00:02<03:27,  1.02it/s]WARNING:root:No query result for this query: SELECT LOCATION ,  name FROM stadium WHERE capacity BETWEEN 5000 AND 10000\n",
            "WARNING:root:No query result for this query: SELECT LOCATION ,  name FROM stadium WHERE capacity BETWEEN 5000 AND 10000\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:   7%|▋         | 16/216 [00:04<00:41,  4.83it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  13%|█▎        | 28/216 [00:04<00:20,  8.99it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  20%|██        | 44/216 [00:05<00:12, 13.91it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  30%|██▉       | 64/216 [00:05<00:05, 25.40it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  34%|███▍      | 73/216 [00:05<00:06, 23.46it/s]WARNING:root:No query result for this query: SELECT Hometown FROM teacher GROUP BY Hometown HAVING COUNT(*)  >=  2\n",
            "WARNING:root:No query result for this query: SELECT Hometown FROM teacher GROUP BY Hometown HAVING COUNT(*)  >=  2\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  37%|███▋      | 80/216 [00:06<00:07, 19.27it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  39%|███▉      | 85/216 [00:06<00:07, 18.58it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  48%|████▊     | 103/216 [00:07<00:04, 23.37it/s]WARNING:root:No query result for this query: select cell_mobile_number from students where first_name  =  'timmothy' and last_name  =  'ward'\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  56%|█████▋    | 122/216 [00:08<00:03, 23.78it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  65%|██████▌   | 141/216 [00:08<00:01, 40.26it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  70%|██████▉   | 151/216 [00:09<00:02, 21.79it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  77%|███████▋  | 166/216 [00:10<00:02, 21.98it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  81%|████████  | 174/216 [00:11<00:02, 14.52it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  88%|████████▊ | 190/216 [00:11<00:01, 17.07it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests:  96%|█████████▋| 208/216 [00:12<00:00, 25.99it/s]WARNING:root:Table should be a list of list:  [[\"wales\", \"scotland\"], [\"england\"]]. Returning zero\n",
            "Evaluating QA tests: 100%|██████████| 216/216 [00:12<00:00, 17.49it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stats_df = tests_df_results[['cell_precision_predictions_TAPAS', 'cell_recall_predictions_TAPAS', 'tuple_cardinality_predictions_TAPAS', 'tuple_constraint_predictions_TAPAS', 'tuple_order_predictions_TAPAS']].describe()\n",
        "\n",
        "mean_cell_precision = tests_df_results['cell_precision_predictions_TAPAS'].mean()\n",
        "mean_cell_recall = tests_df_results['cell_recall_predictions_TAPAS'].mean()\n",
        "mean_tuple_cardinality = tests_df_results['tuple_cardinality_predictions_TAPAS'].mean()\n",
        "mean_tuple_constraint = tests_df_results['tuple_constraint_predictions_TAPAS'].mean()\n",
        "mean_tuple_order = tests_df_results['tuple_order_predictions_TAPAS'].mean()\n",
        "\n",
        "print(\"Model Performance Metrics:\")\n",
        "print(\"----------------------------\")\n",
        "print(\"Average Cell Precision:\", mean_cell_precision)\n",
        "print(\"Average Cell Recall:\", mean_cell_recall)\n",
        "print(\"Average Tuple Cardinality Accuracy:\", mean_tuple_cardinality)\n",
        "print(\"Average Tuple Constraint Accuracy:\", mean_tuple_constraint)\n",
        "print(\"Average Tuple Order Accuracy:\", mean_tuple_order)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgEJeIu407xY",
        "outputId": "81f2ec4a-9cba-47e3-92ba-5889ff06704b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Metrics:\n",
            "----------------------------\n",
            "Average Cell Precision: 0.5218703703703703\n",
            "Average Cell Recall: 0.48767129629629624\n",
            "Average Tuple Cardinality Accuracy: 0.5622499999999998\n",
            "Average Tuple Constraint Accuracy: 0.3778703703703704\n",
            "Average Tuple Order Accuracy: 0.21689473684210528\n"
          ]
        }
      ]
    }
  ]
}